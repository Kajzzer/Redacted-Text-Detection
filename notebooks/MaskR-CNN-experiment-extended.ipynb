{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc24cae7",
   "metadata": {},
   "source": [
    "# All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa11faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import os, json, cv2, random, shutil, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a42e96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmei\\anaconda3\\envs\\master\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96938172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables and constants\n",
    "datasets_dir = os.path.join('..', 'datasets')\n",
    "json_file = os.path.join('..', 'datasets', 'gold_standard_complete.json')\n",
    "with open(json_file) as f: data_json = json.load(f)\n",
    "TRAIN_SPLIT = 0.7\n",
    "RNG_SEED = 117"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be50719",
   "metadata": {},
   "source": [
    "# Load in our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94ad227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the functions to create the train and test split\n",
    "%run Data-split-functions.ipynb\n",
    "\n",
    "# create the data, set force_new_split to false so that we can skip \n",
    "# this phase if it has been done before and \n",
    "# extended to true to include the 'no_annotation' pages\n",
    "split_data(TRAIN_SPLIT, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47196e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redacted_dicts(img_dir):\n",
    "    '''\n",
    "    Get the annotations of the images in the provided directory in the format DatasetCatalog expects\n",
    "    @param  string    The name of the \n",
    "    @return list      The annotations of the files in DatasetCatalog format. Every record has the following properties:\n",
    "                          - filename:string      The name of the image\n",
    "                          - image_id:int         The id of the image\n",
    "                          - height:int           The height of the image\n",
    "                          - width:int            The width of the image\n",
    "                          - bbox_mode:string     The mode for the bounding box (BoxMode.XYWH_ABS or BoxMode.XYXY_ABS)\n",
    "                          - bbox:list            The values for the bounding box depending on the bbox_mode\n",
    "                          - semgentation:list    The separate semgentations that belong to the same instance\n",
    "                          - category_id:int      The id of the class the instance belongs to\n",
    "    '''\n",
    "\n",
    "    # initial list of segments for this image\n",
    "    dataset_dicts = []\n",
    "    \n",
    "    # iterate over all files/images in the porvided directory\n",
    "    for idx, filename in tqdm(enumerate(os.listdir(img_dir))):\n",
    "        \n",
    "        # the initial record for this file\n",
    "        record = {}\n",
    "        \n",
    "        # get the image\n",
    "        img_path = os.path.join(img_dir, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # skip this image if we can't load the file\n",
    "        if image is None: continue\n",
    "            \n",
    "        # get the height and width of the image\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # keep track of some image properties\n",
    "        record[\"file_name\"] = img_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        \n",
    "        # skip this file if we don't have annotations for it\n",
    "        if not filename in data_json: continue\n",
    "\n",
    "        # get all polygons of this file\n",
    "        polygons = [region['shape_attributes'] for region in data_json[filename]['regions']]\n",
    "        \n",
    "        # initial annotation of this file\n",
    "        annotations = []\n",
    "        \n",
    "        # iterate over all polygons of this file\n",
    "        for polygon in polygons:\n",
    "            \n",
    "            # handle rectangle polygons\n",
    "            if polygon['name'] == 'rect':\n",
    "                \n",
    "                # create the values needed for the rectangular polygon\n",
    "                # the values that the segmentation propery expect is:\n",
    "                # [x1, y1, x2, y2, ..., xn, yn]\n",
    "                segment = [polygon['x'], polygon['y']]\n",
    "                segment = segment + [polygon['x'] + polygon['width'], polygon['y']]\n",
    "                segment = segment + [polygon['x'] + polygon['width'], polygon['y'] + polygon['height']]\n",
    "                segment = segment + [polygon['x'], polygon['y'] + polygon['height']]\n",
    "\n",
    "                # create a bounding box for this segment\n",
    "                bbox = [polygon['x'], polygon['y'], polygon['width'], polygon['height']]\n",
    "                bbox_mode = BoxMode.XYWH_ABS\n",
    "                \n",
    "            # handle generic polygons\n",
    "            elif polygon['name'] == 'polygon':\n",
    "                \n",
    "                # create the segmentation from all x and y values of the polygon\n",
    "                # the values that the segmentation propery expect is:\n",
    "                # [x1, y1, x2, y2, ..., xn, yn]\n",
    "                px = polygon[\"all_points_x\"]\n",
    "                py = polygon[\"all_points_y\"]\n",
    "                segment = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "                segment = [p for x in segment for p in x]\n",
    "                \n",
    "                # create the bounding box for this segment\n",
    "                bbox = [np.min(px), np.min(py), np.max(px), np.max(py)]\n",
    "                bbox_mode = BoxMode.XYXY_ABS\n",
    "            \n",
    "            # skip unknown polygon types\n",
    "            else: continue\n",
    "            \n",
    "            # add the semgent specification \n",
    "            annotations.append({\n",
    "                \"bbox\": bbox,\n",
    "                \"bbox_mode\": bbox_mode,\n",
    "                \"segmentation\": [segment],\n",
    "                \"category_id\": 0,\n",
    "            })\n",
    "            \n",
    "        # add the annotations to the record\n",
    "        record[\"annotations\"] = annotations\n",
    "        \n",
    "        # add the record to the dataset\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ee05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset catalog and metadata for the train data\n",
    "DatasetCatalog.register('redacted_train_extended', lambda x='train':get_redacted_dicts(os.path.join(datasets_dir, x)))\n",
    "metadata = MetadataCatalog.get('redacted_train_extended').set(thing_classes=[\"redacted\"])\n",
    "metadata.set(thing_dataset_id_to_contiguous_id = {'0' : 'redacted'})\n",
    "metadata.set(stuff_dataset_id_to_contiguous_id = {})\n",
    "redacted_metadata = MetadataCatalog.get('redacted_train_extended')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6b5ee",
   "metadata": {},
   "source": [
    "# Create the config for the model\n",
    "This is a reference to the default config with all available options: https://detectron2.readthedocs.io/en/latest/modules/config.html#yaml-config-references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6c1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial config for the detectron2 model\n",
    "cfg = get_cfg() # the default config\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")) # the config of the coco dataset\n",
    "cfg.SEED = RNG_SEED \n",
    "\n",
    "# data config\n",
    "cfg.DATASETS.TRAIN = (\"redacted_train_extended\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2 # this will alter the speed of the training, my gpu could only handle 2\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False # we also want the model to train on documents without redactions\n",
    "cfg.INPUT.RANDOM_FLIP = \"none\" # we don't add any random flips as data augmentation\n",
    "\n",
    "# model config\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # initial weights from model zoo\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # The \"RoIHead batch size\". The default is 512, but a smaller size is faster\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class* ('redacted')\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # inference score threshold \n",
    "# *NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "# set a custom output directory for this model\n",
    "# so that we don't overwrite the model of the \n",
    "# other experiment\n",
    "cfg.OUTPUT_DIR = 'output_extended'\n",
    "\n",
    "# create the output dir\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd1c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver config that we need to use a gridsearch on\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 5000    \n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac95de1",
   "metadata": {},
   "source": [
    "# Train the model with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04109f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 13:33:06 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "664it [00:43, 15.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 13:33:49 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  redacted  | 7765         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/23 13:33:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/23 13:33:49 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/23 13:33:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/23 13:33:49 d2.data.common]: \u001b[0mSerializing 664 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/23 13:33:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n",
      "\u001b[32m[01/23 13:33:49 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 13:33:51 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmei\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 13:34:15 d2.utils.events]: \u001b[0m eta: 1:25:32  iter: 19  total_loss: 5.549  loss_cls: 0.6246  loss_box_reg: 0.2599  loss_mask: 0.6826  loss_rpn_cls: 3.455  loss_rpn_loc: 0.3258    time: 0.9944  last_time: 1.0429  data_time: 0.1888  last_data_time: 0.0012   lr: 1.9981e-05  max_mem: 5218M\n",
      "\u001b[32m[01/23 13:34:40 d2.utils.events]: \u001b[0m eta: 1:25:44  iter: 39  total_loss: 2.171  loss_cls: 0.5456  loss_box_reg: 0.3955  loss_mask: 0.5891  loss_rpn_cls: 0.3132  loss_rpn_loc: 0.2269    time: 1.0267  last_time: 1.0392  data_time: 0.0013  last_data_time: 0.0014   lr: 3.9961e-05  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:35:01 d2.utils.events]: \u001b[0m eta: 1:25:52  iter: 59  total_loss: 1.655  loss_cls: 0.3747  loss_box_reg: 0.3656  loss_mask: 0.4569  loss_rpn_cls: 0.1805  loss_rpn_loc: 0.2205    time: 1.0318  last_time: 1.1361  data_time: 0.0014  last_data_time: 0.0013   lr: 5.9941e-05  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:35:21 d2.utils.events]: \u001b[0m eta: 1:25:13  iter: 79  total_loss: 1.604  loss_cls: 0.3921  loss_box_reg: 0.5527  loss_mask: 0.3398  loss_rpn_cls: 0.09468  loss_rpn_loc: 0.2049    time: 1.0334  last_time: 1.1410  data_time: 0.0013  last_data_time: 0.0013   lr: 7.9921e-05  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:35:41 d2.utils.events]: \u001b[0m eta: 1:24:45  iter: 99  total_loss: 1.47  loss_cls: 0.3509  loss_box_reg: 0.4919  loss_mask: 0.3029  loss_rpn_cls: 0.07661  loss_rpn_loc: 0.1922    time: 1.0269  last_time: 0.8449  data_time: 0.0014  last_data_time: 0.0012   lr: 9.9901e-05  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:36:01 d2.utils.events]: \u001b[0m eta: 1:24:16  iter: 119  total_loss: 1.393  loss_cls: 0.2692  loss_box_reg: 0.453  loss_mask: 0.2994  loss_rpn_cls: 0.1015  loss_rpn_loc: 0.1708    time: 1.0207  last_time: 1.0532  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00011988  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:36:22 d2.utils.events]: \u001b[0m eta: 1:23:50  iter: 139  total_loss: 1.057  loss_cls: 0.224  loss_box_reg: 0.4585  loss_mask: 0.2507  loss_rpn_cls: 0.04852  loss_rpn_loc: 0.1126    time: 1.0220  last_time: 1.0022  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00013986  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:36:42 d2.utils.events]: \u001b[0m eta: 1:23:28  iter: 159  total_loss: 1.086  loss_cls: 0.1773  loss_box_reg: 0.4319  loss_mask: 0.2392  loss_rpn_cls: 0.0598  loss_rpn_loc: 0.1432    time: 1.0198  last_time: 1.0596  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00015984  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:37:03 d2.utils.events]: \u001b[0m eta: 1:23:14  iter: 179  total_loss: 1.055  loss_cls: 0.1934  loss_box_reg: 0.4736  loss_mask: 0.2136  loss_rpn_cls: 0.03972  loss_rpn_loc: 0.1404    time: 1.0250  last_time: 1.3411  data_time: 0.0014  last_data_time: 0.0011   lr: 0.00017982  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:37:24 d2.utils.events]: \u001b[0m eta: 1:23:01  iter: 199  total_loss: 1.008  loss_cls: 0.1691  loss_box_reg: 0.3992  loss_mask: 0.2128  loss_rpn_cls: 0.03311  loss_rpn_loc: 0.1441    time: 1.0263  last_time: 0.7797  data_time: 0.0013  last_data_time: 0.0014   lr: 0.0001998  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:37:45 d2.utils.events]: \u001b[0m eta: 1:22:40  iter: 219  total_loss: 1.099  loss_cls: 0.2036  loss_box_reg: 0.4607  loss_mask: 0.1977  loss_rpn_cls: 0.04529  loss_rpn_loc: 0.1445    time: 1.0261  last_time: 0.8439  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00021978  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:38:06 d2.utils.events]: \u001b[0m eta: 1:22:27  iter: 239  total_loss: 0.857  loss_cls: 0.1481  loss_box_reg: 0.3671  loss_mask: 0.176  loss_rpn_cls: 0.03441  loss_rpn_loc: 0.09698    time: 1.0286  last_time: 0.9877  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00023976  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:38:27 d2.utils.events]: \u001b[0m eta: 1:22:09  iter: 259  total_loss: 0.8856  loss_cls: 0.1729  loss_box_reg: 0.3903  loss_mask: 0.2  loss_rpn_cls: 0.02172  loss_rpn_loc: 0.1459    time: 1.0318  last_time: 1.1515  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00025974  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:38:47 d2.utils.events]: \u001b[0m eta: 1:21:50  iter: 279  total_loss: 0.7345  loss_cls: 0.1195  loss_box_reg: 0.2595  loss_mask: 0.1787  loss_rpn_cls: 0.02435  loss_rpn_loc: 0.1126    time: 1.0292  last_time: 1.0403  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00027972  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:39:07 d2.utils.events]: \u001b[0m eta: 1:21:25  iter: 299  total_loss: 0.8133  loss_cls: 0.1333  loss_box_reg: 0.3073  loss_mask: 0.1624  loss_rpn_cls: 0.04144  loss_rpn_loc: 0.1458    time: 1.0284  last_time: 0.9262  data_time: 0.0013  last_data_time: 0.0019   lr: 0.0002997  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:39:28 d2.utils.events]: \u001b[0m eta: 1:21:07  iter: 319  total_loss: 0.7867  loss_cls: 0.135  loss_box_reg: 0.311  loss_mask: 0.18  loss_rpn_cls: 0.04214  loss_rpn_loc: 0.1239    time: 1.0282  last_time: 1.0837  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00031968  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:39:48 d2.utils.events]: \u001b[0m eta: 1:20:42  iter: 339  total_loss: 0.7529  loss_cls: 0.1132  loss_box_reg: 0.2386  loss_mask: 0.1605  loss_rpn_cls: 0.03474  loss_rpn_loc: 0.1658    time: 1.0259  last_time: 0.9303  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00033966  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:40:08 d2.utils.events]: \u001b[0m eta: 1:20:23  iter: 359  total_loss: 0.709  loss_cls: 0.1317  loss_box_reg: 0.2401  loss_mask: 0.1504  loss_rpn_cls: 0.02498  loss_rpn_loc: 0.1437    time: 1.0261  last_time: 1.1437  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00035964  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:40:29 d2.utils.events]: \u001b[0m eta: 1:20:06  iter: 379  total_loss: 0.677  loss_cls: 0.1243  loss_box_reg: 0.2301  loss_mask: 0.1603  loss_rpn_cls: 0.02486  loss_rpn_loc: 0.1241    time: 1.0270  last_time: 0.9398  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00037962  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:40:50 d2.utils.events]: \u001b[0m eta: 1:19:57  iter: 399  total_loss: 0.705  loss_cls: 0.1189  loss_box_reg: 0.279  loss_mask: 0.1532  loss_rpn_cls: 0.02369  loss_rpn_loc: 0.1082    time: 1.0284  last_time: 1.1677  data_time: 0.0013  last_data_time: 0.0012   lr: 0.0003996  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:41:11 d2.utils.events]: \u001b[0m eta: 1:19:33  iter: 419  total_loss: 0.577  loss_cls: 0.1114  loss_box_reg: 0.2161  loss_mask: 0.1449  loss_rpn_cls: 0.01115  loss_rpn_loc: 0.09082    time: 1.0279  last_time: 0.9212  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00041958  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:41:31 d2.utils.events]: \u001b[0m eta: 1:19:07  iter: 439  total_loss: 0.6541  loss_cls: 0.1187  loss_box_reg: 0.234  loss_mask: 0.1362  loss_rpn_cls: 0.03203  loss_rpn_loc: 0.123    time: 1.0283  last_time: 0.8289  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00043956  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:41:52 d2.utils.events]: \u001b[0m eta: 1:18:46  iter: 459  total_loss: 0.7163  loss_cls: 0.1155  loss_box_reg: 0.2503  loss_mask: 0.1499  loss_rpn_cls: 0.02701  loss_rpn_loc: 0.1409    time: 1.0281  last_time: 1.1660  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00045954  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:42:11 d2.utils.events]: \u001b[0m eta: 1:18:17  iter: 479  total_loss: 0.5941  loss_cls: 0.1147  loss_box_reg: 0.2476  loss_mask: 0.1629  loss_rpn_cls: 0.01617  loss_rpn_loc: 0.111    time: 1.0258  last_time: 0.7541  data_time: 0.0067  last_data_time: 0.0013   lr: 0.00047952  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:42:32 d2.utils.events]: \u001b[0m eta: 1:17:57  iter: 499  total_loss: 0.6799  loss_cls: 0.1338  loss_box_reg: 0.2499  loss_mask: 0.1476  loss_rpn_cls: 0.01517  loss_rpn_loc: 0.08989    time: 1.0255  last_time: 1.1692  data_time: 0.0013  last_data_time: 0.0011   lr: 0.0004995  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:42:52 d2.utils.events]: \u001b[0m eta: 1:17:35  iter: 519  total_loss: 0.5257  loss_cls: 0.1011  loss_box_reg: 0.2013  loss_mask: 0.1463  loss_rpn_cls: 0.009831  loss_rpn_loc: 0.09539    time: 1.0257  last_time: 0.8382  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00051948  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:43:13 d2.utils.events]: \u001b[0m eta: 1:17:13  iter: 539  total_loss: 0.7513  loss_cls: 0.121  loss_box_reg: 0.2793  loss_mask: 0.133  loss_rpn_cls: 0.02485  loss_rpn_loc: 0.1627    time: 1.0253  last_time: 1.1465  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00053946  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:43:34 d2.utils.events]: \u001b[0m eta: 1:16:54  iter: 559  total_loss: 0.5534  loss_cls: 0.09965  loss_box_reg: 0.2014  loss_mask: 0.1281  loss_rpn_cls: 0.03522  loss_rpn_loc: 0.111    time: 1.0262  last_time: 1.1410  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00055944  max_mem: 5933M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 13:43:55 d2.utils.events]: \u001b[0m eta: 1:16:34  iter: 579  total_loss: 0.6485  loss_cls: 0.1076  loss_box_reg: 0.2301  loss_mask: 0.1226  loss_rpn_cls: 0.01978  loss_rpn_loc: 0.1317    time: 1.0273  last_time: 1.4220  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00057942  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:44:15 d2.utils.events]: \u001b[0m eta: 1:16:15  iter: 599  total_loss: 0.6788  loss_cls: 0.1092  loss_box_reg: 0.2523  loss_mask: 0.1579  loss_rpn_cls: 0.01855  loss_rpn_loc: 0.1276    time: 1.0268  last_time: 0.8335  data_time: 0.0013  last_data_time: 0.0015   lr: 0.0005994  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:44:35 d2.utils.events]: \u001b[0m eta: 1:15:53  iter: 619  total_loss: 0.6177  loss_cls: 0.1259  loss_box_reg: 0.2452  loss_mask: 0.1437  loss_rpn_cls: 0.01543  loss_rpn_loc: 0.1157    time: 1.0256  last_time: 0.9946  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00061938  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:44:56 d2.utils.events]: \u001b[0m eta: 1:15:35  iter: 639  total_loss: 0.5579  loss_cls: 0.1123  loss_box_reg: 0.2067  loss_mask: 0.1335  loss_rpn_cls: 0.01765  loss_rpn_loc: 0.1348    time: 1.0266  last_time: 1.0212  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00063936  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:45:17 d2.utils.events]: \u001b[0m eta: 1:15:13  iter: 659  total_loss: 0.759  loss_cls: 0.1347  loss_box_reg: 0.2786  loss_mask: 0.1512  loss_rpn_cls: 0.0211  loss_rpn_loc: 0.17    time: 1.0267  last_time: 1.3290  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00065934  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:45:38 d2.utils.events]: \u001b[0m eta: 1:14:52  iter: 679  total_loss: 0.594  loss_cls: 0.1116  loss_box_reg: 0.1855  loss_mask: 0.1317  loss_rpn_cls: 0.01572  loss_rpn_loc: 0.1335    time: 1.0272  last_time: 1.1839  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00067932  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:45:59 d2.utils.events]: \u001b[0m eta: 1:14:41  iter: 699  total_loss: 0.623  loss_cls: 0.1018  loss_box_reg: 0.2385  loss_mask: 0.1331  loss_rpn_cls: 0.0185  loss_rpn_loc: 0.1238    time: 1.0283  last_time: 1.0853  data_time: 0.0014  last_data_time: 0.0012   lr: 0.0006993  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:46:19 d2.utils.events]: \u001b[0m eta: 1:14:12  iter: 719  total_loss: 0.6508  loss_cls: 0.1172  loss_box_reg: 0.2198  loss_mask: 0.159  loss_rpn_cls: 0.02087  loss_rpn_loc: 0.1192    time: 1.0275  last_time: 1.0637  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00071928  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:46:40 d2.utils.events]: \u001b[0m eta: 1:14:02  iter: 739  total_loss: 0.4926  loss_cls: 0.07552  loss_box_reg: 0.1917  loss_mask: 0.118  loss_rpn_cls: 0.01237  loss_rpn_loc: 0.08863    time: 1.0289  last_time: 1.3559  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00073926  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:47:02 d2.utils.events]: \u001b[0m eta: 1:13:43  iter: 759  total_loss: 0.5752  loss_cls: 0.09657  loss_box_reg: 0.2096  loss_mask: 0.1161  loss_rpn_cls: 0.01323  loss_rpn_loc: 0.09222    time: 1.0300  last_time: 1.1823  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00075924  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:47:22 d2.utils.events]: \u001b[0m eta: 1:13:21  iter: 779  total_loss: 0.5606  loss_cls: 0.1058  loss_box_reg: 0.1955  loss_mask: 0.1228  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.1015    time: 1.0292  last_time: 1.3574  data_time: 0.0014  last_data_time: 0.0018   lr: 0.00077922  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:47:43 d2.utils.events]: \u001b[0m eta: 1:13:01  iter: 799  total_loss: 0.5632  loss_cls: 0.08982  loss_box_reg: 0.222  loss_mask: 0.1331  loss_rpn_cls: 0.009636  loss_rpn_loc: 0.0801    time: 1.0300  last_time: 1.0769  data_time: 0.0014  last_data_time: 0.0013   lr: 0.0007992  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:48:04 d2.utils.events]: \u001b[0m eta: 1:12:41  iter: 819  total_loss: 0.6584  loss_cls: 0.1164  loss_box_reg: 0.2595  loss_mask: 0.1413  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.1368    time: 1.0309  last_time: 1.0878  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00081918  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:48:25 d2.utils.events]: \u001b[0m eta: 1:12:24  iter: 839  total_loss: 0.58  loss_cls: 0.09678  loss_box_reg: 0.2364  loss_mask: 0.1373  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.09666    time: 1.0314  last_time: 1.1551  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00083916  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:48:46 d2.utils.events]: \u001b[0m eta: 1:12:01  iter: 859  total_loss: 0.6565  loss_cls: 0.1246  loss_box_reg: 0.2112  loss_mask: 0.1469  loss_rpn_cls: 0.03237  loss_rpn_loc: 0.1128    time: 1.0311  last_time: 1.0966  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00085914  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:49:06 d2.utils.events]: \u001b[0m eta: 1:11:38  iter: 879  total_loss: 0.6109  loss_cls: 0.113  loss_box_reg: 0.2252  loss_mask: 0.1212  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.1101    time: 1.0310  last_time: 1.0713  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00087912  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:49:28 d2.utils.events]: \u001b[0m eta: 1:11:30  iter: 899  total_loss: 0.6319  loss_cls: 0.1037  loss_box_reg: 0.2288  loss_mask: 0.1344  loss_rpn_cls: 0.01138  loss_rpn_loc: 0.1116    time: 1.0325  last_time: 0.9209  data_time: 0.0013  last_data_time: 0.0012   lr: 0.0008991  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:49:50 d2.utils.events]: \u001b[0m eta: 1:11:21  iter: 919  total_loss: 0.6371  loss_cls: 0.1049  loss_box_reg: 0.2265  loss_mask: 0.1475  loss_rpn_cls: 0.01718  loss_rpn_loc: 0.1104    time: 1.0341  last_time: 1.0134  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00091908  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:50:12 d2.utils.events]: \u001b[0m eta: 1:11:03  iter: 939  total_loss: 0.5555  loss_cls: 0.08341  loss_box_reg: 0.1828  loss_mask: 0.134  loss_rpn_cls: 0.0117  loss_rpn_loc: 0.07972    time: 1.0350  last_time: 1.1511  data_time: 0.0015  last_data_time: 0.0013   lr: 0.00093906  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:50:33 d2.utils.events]: \u001b[0m eta: 1:10:43  iter: 959  total_loss: 0.5269  loss_cls: 0.1032  loss_box_reg: 0.1804  loss_mask: 0.1418  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.07779    time: 1.0351  last_time: 1.0649  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00095904  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:50:53 d2.utils.events]: \u001b[0m eta: 1:10:21  iter: 979  total_loss: 0.6182  loss_cls: 0.09375  loss_box_reg: 0.243  loss_mask: 0.1367  loss_rpn_cls: 0.01356  loss_rpn_loc: 0.1107    time: 1.0349  last_time: 0.9300  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00097902  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:51:14 d2.utils.events]: \u001b[0m eta: 1:10:00  iter: 999  total_loss: 0.6334  loss_cls: 0.1045  loss_box_reg: 0.2724  loss_mask: 0.1408  loss_rpn_cls: 0.01297  loss_rpn_loc: 0.1002    time: 1.0345  last_time: 1.1808  data_time: 0.0013  last_data_time: 0.0014   lr: 0.000999  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:51:35 d2.utils.events]: \u001b[0m eta: 1:09:45  iter: 1019  total_loss: 0.6337  loss_cls: 0.09874  loss_box_reg: 0.2344  loss_mask: 0.1379  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.1228    time: 1.0350  last_time: 0.9340  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:51:55 d2.utils.events]: \u001b[0m eta: 1:09:27  iter: 1039  total_loss: 0.6466  loss_cls: 0.1141  loss_box_reg: 0.219  loss_mask: 0.152  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.1185    time: 1.0349  last_time: 1.0527  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:52:16 d2.utils.events]: \u001b[0m eta: 1:09:03  iter: 1059  total_loss: 0.6039  loss_cls: 0.1085  loss_box_reg: 0.2508  loss_mask: 0.1391  loss_rpn_cls: 0.01261  loss_rpn_loc: 0.1287    time: 1.0350  last_time: 1.1849  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:52:37 d2.utils.events]: \u001b[0m eta: 1:08:47  iter: 1079  total_loss: 0.4583  loss_cls: 0.07444  loss_box_reg: 0.1578  loss_mask: 0.1283  loss_rpn_cls: 0.01001  loss_rpn_loc: 0.08123    time: 1.0352  last_time: 1.0573  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:52:58 d2.utils.events]: \u001b[0m eta: 1:08:30  iter: 1099  total_loss: 0.509  loss_cls: 0.08529  loss_box_reg: 0.2017  loss_mask: 0.1312  loss_rpn_cls: 0.009583  loss_rpn_loc: 0.09639    time: 1.0358  last_time: 1.0713  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:53:19 d2.utils.events]: \u001b[0m eta: 1:08:10  iter: 1119  total_loss: 0.4961  loss_cls: 0.07503  loss_box_reg: 0.1929  loss_mask: 0.1282  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.08935    time: 1.0357  last_time: 1.0843  data_time: 0.0014  last_data_time: 0.0016   lr: 0.001  max_mem: 5933M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 13:53:40 d2.utils.events]: \u001b[0m eta: 1:07:50  iter: 1139  total_loss: 0.5755  loss_cls: 0.08811  loss_box_reg: 0.2152  loss_mask: 0.1367  loss_rpn_cls: 0.01162  loss_rpn_loc: 0.08812    time: 1.0357  last_time: 1.0301  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:54:01 d2.utils.events]: \u001b[0m eta: 1:07:32  iter: 1159  total_loss: 0.5604  loss_cls: 0.09086  loss_box_reg: 0.2066  loss_mask: 0.1378  loss_rpn_cls: 0.01097  loss_rpn_loc: 0.1071    time: 1.0360  last_time: 1.0049  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:54:21 d2.utils.events]: \u001b[0m eta: 1:07:07  iter: 1179  total_loss: 0.5026  loss_cls: 0.08866  loss_box_reg: 0.1743  loss_mask: 0.137  loss_rpn_cls: 0.009849  loss_rpn_loc: 0.06047    time: 1.0358  last_time: 0.9386  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:54:42 d2.utils.events]: \u001b[0m eta: 1:06:47  iter: 1199  total_loss: 0.6506  loss_cls: 0.101  loss_box_reg: 0.2592  loss_mask: 0.1459  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.1087    time: 1.0360  last_time: 1.1741  data_time: 0.0013  last_data_time: 0.0021   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:55:03 d2.utils.events]: \u001b[0m eta: 1:06:26  iter: 1219  total_loss: 0.5183  loss_cls: 0.08869  loss_box_reg: 0.1991  loss_mask: 0.1266  loss_rpn_cls: 0.01027  loss_rpn_loc: 0.08889    time: 1.0358  last_time: 1.1912  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:55:24 d2.utils.events]: \u001b[0m eta: 1:06:03  iter: 1239  total_loss: 0.4946  loss_cls: 0.06671  loss_box_reg: 0.1875  loss_mask: 0.1099  loss_rpn_cls: 0.008635  loss_rpn_loc: 0.07791    time: 1.0358  last_time: 0.8673  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5933M\n",
      "\u001b[32m[01/23 13:55:45 d2.utils.events]: \u001b[0m eta: 1:05:43  iter: 1259  total_loss: 0.5198  loss_cls: 0.09462  loss_box_reg: 0.2059  loss_mask: 0.1148  loss_rpn_cls: 0.006615  loss_rpn_loc: 0.09286    time: 1.0361  last_time: 1.0739  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:56:06 d2.utils.events]: \u001b[0m eta: 1:05:26  iter: 1279  total_loss: 0.5872  loss_cls: 0.08582  loss_box_reg: 0.2155  loss_mask: 0.1262  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.1109    time: 1.0365  last_time: 1.0794  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:56:27 d2.utils.events]: \u001b[0m eta: 1:05:09  iter: 1299  total_loss: 0.5295  loss_cls: 0.07901  loss_box_reg: 0.1971  loss_mask: 0.1299  loss_rpn_cls: 0.008834  loss_rpn_loc: 0.09108    time: 1.0370  last_time: 0.8169  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:56:49 d2.utils.events]: \u001b[0m eta: 1:04:49  iter: 1319  total_loss: 0.553  loss_cls: 0.08524  loss_box_reg: 0.2251  loss_mask: 0.1251  loss_rpn_cls: 0.007498  loss_rpn_loc: 0.1035    time: 1.0378  last_time: 0.9102  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:57:10 d2.utils.events]: \u001b[0m eta: 1:04:29  iter: 1339  total_loss: 0.4683  loss_cls: 0.07573  loss_box_reg: 0.1787  loss_mask: 0.1222  loss_rpn_cls: 0.008123  loss_rpn_loc: 0.0943    time: 1.0379  last_time: 0.9681  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:57:31 d2.utils.events]: \u001b[0m eta: 1:04:08  iter: 1359  total_loss: 0.4784  loss_cls: 0.0749  loss_box_reg: 0.1951  loss_mask: 0.1077  loss_rpn_cls: 0.007486  loss_rpn_loc: 0.1069    time: 1.0382  last_time: 1.0842  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:57:52 d2.utils.events]: \u001b[0m eta: 1:03:46  iter: 1379  total_loss: 0.5009  loss_cls: 0.07713  loss_box_reg: 0.1769  loss_mask: 0.1261  loss_rpn_cls: 0.009187  loss_rpn_loc: 0.1014    time: 1.0383  last_time: 0.9996  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:58:14 d2.utils.events]: \u001b[0m eta: 1:03:24  iter: 1399  total_loss: 0.5825  loss_cls: 0.0841  loss_box_reg: 0.2266  loss_mask: 0.1258  loss_rpn_cls: 0.008542  loss_rpn_loc: 0.1076    time: 1.0388  last_time: 0.8340  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:58:34 d2.utils.events]: \u001b[0m eta: 1:03:04  iter: 1419  total_loss: 0.5481  loss_cls: 0.08545  loss_box_reg: 0.1995  loss_mask: 0.1287  loss_rpn_cls: 0.008833  loss_rpn_loc: 0.07747    time: 1.0388  last_time: 0.9113  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:58:56 d2.utils.events]: \u001b[0m eta: 1:02:47  iter: 1439  total_loss: 0.5012  loss_cls: 0.08905  loss_box_reg: 0.1928  loss_mask: 0.125  loss_rpn_cls: 0.007448  loss_rpn_loc: 0.104    time: 1.0391  last_time: 1.1929  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:59:16 d2.utils.events]: \u001b[0m eta: 1:02:24  iter: 1459  total_loss: 0.4072  loss_cls: 0.05521  loss_box_reg: 0.1541  loss_mask: 0.1238  loss_rpn_cls: 0.002977  loss_rpn_loc: 0.07454    time: 1.0388  last_time: 1.0796  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:59:37 d2.utils.events]: \u001b[0m eta: 1:02:08  iter: 1479  total_loss: 0.5606  loss_cls: 0.07608  loss_box_reg: 0.2356  loss_mask: 0.132  loss_rpn_cls: 0.008337  loss_rpn_loc: 0.1229    time: 1.0390  last_time: 1.0762  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 13:59:58 d2.utils.events]: \u001b[0m eta: 1:01:48  iter: 1499  total_loss: 0.5589  loss_cls: 0.07893  loss_box_reg: 0.1915  loss_mask: 0.1249  loss_rpn_cls: 0.007015  loss_rpn_loc: 0.09591    time: 1.0394  last_time: 1.1904  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:00:19 d2.utils.events]: \u001b[0m eta: 1:01:28  iter: 1519  total_loss: 0.5285  loss_cls: 0.1028  loss_box_reg: 0.2294  loss_mask: 0.1288  loss_rpn_cls: 0.008906  loss_rpn_loc: 0.09855    time: 1.0394  last_time: 1.0143  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:00:40 d2.utils.events]: \u001b[0m eta: 1:01:08  iter: 1539  total_loss: 0.5089  loss_cls: 0.0858  loss_box_reg: 0.2101  loss_mask: 0.116  loss_rpn_cls: 0.008533  loss_rpn_loc: 0.0827    time: 1.0397  last_time: 1.1876  data_time: 0.0014  last_data_time: 0.0017   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:01:02 d2.utils.events]: \u001b[0m eta: 1:00:49  iter: 1559  total_loss: 0.4978  loss_cls: 0.07642  loss_box_reg: 0.212  loss_mask: 0.1342  loss_rpn_cls: 0.006616  loss_rpn_loc: 0.1046    time: 1.0403  last_time: 1.0839  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:01:22 d2.utils.events]: \u001b[0m eta: 1:00:24  iter: 1579  total_loss: 0.5029  loss_cls: 0.07247  loss_box_reg: 0.214  loss_mask: 0.1197  loss_rpn_cls: 0.007589  loss_rpn_loc: 0.08257    time: 1.0399  last_time: 1.1565  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:01:43 d2.utils.events]: \u001b[0m eta: 1:00:04  iter: 1599  total_loss: 0.5159  loss_cls: 0.08353  loss_box_reg: 0.1974  loss_mask: 0.142  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.08122    time: 1.0399  last_time: 1.0994  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:02:04 d2.utils.events]: \u001b[0m eta: 0:59:44  iter: 1619  total_loss: 0.52  loss_cls: 0.08512  loss_box_reg: 0.194  loss_mask: 0.1176  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.1015    time: 1.0397  last_time: 0.8732  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:02:26 d2.utils.events]: \u001b[0m eta: 0:59:29  iter: 1639  total_loss: 0.5612  loss_cls: 0.0814  loss_box_reg: 0.2065  loss_mask: 0.1267  loss_rpn_cls: 0.004943  loss_rpn_loc: 0.1015    time: 1.0404  last_time: 0.8379  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:02:46 d2.utils.events]: \u001b[0m eta: 0:59:04  iter: 1659  total_loss: 0.4782  loss_cls: 0.07426  loss_box_reg: 0.1811  loss_mask: 0.1374  loss_rpn_cls: 0.01096  loss_rpn_loc: 0.09123    time: 1.0399  last_time: 0.8161  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:03:05 d2.utils.events]: \u001b[0m eta: 0:58:41  iter: 1679  total_loss: 0.4677  loss_cls: 0.06596  loss_box_reg: 0.1973  loss_mask: 0.1204  loss_rpn_cls: 0.006912  loss_rpn_loc: 0.0734    time: 1.0393  last_time: 0.8608  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:03:27 d2.utils.events]: \u001b[0m eta: 0:58:18  iter: 1699  total_loss: 0.601  loss_cls: 0.08389  loss_box_reg: 0.2264  loss_mask: 0.1397  loss_rpn_cls: 0.006619  loss_rpn_loc: 0.1103    time: 1.0396  last_time: 1.0228  data_time: 0.0014  last_data_time: 0.0021   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:03:48 d2.utils.events]: \u001b[0m eta: 0:58:04  iter: 1719  total_loss: 0.4088  loss_cls: 0.0661  loss_box_reg: 0.1655  loss_mask: 0.1075  loss_rpn_cls: 0.004639  loss_rpn_loc: 0.07758    time: 1.0401  last_time: 1.1508  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:04:10 d2.utils.events]: \u001b[0m eta: 0:57:46  iter: 1739  total_loss: 0.5477  loss_cls: 0.08114  loss_box_reg: 0.2021  loss_mask: 0.1291  loss_rpn_cls: 0.009569  loss_rpn_loc: 0.1151    time: 1.0407  last_time: 1.0915  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:04:32 d2.utils.events]: \u001b[0m eta: 0:57:23  iter: 1759  total_loss: 0.4562  loss_cls: 0.0749  loss_box_reg: 0.1751  loss_mask: 0.1058  loss_rpn_cls: 0.006676  loss_rpn_loc: 0.08418    time: 1.0411  last_time: 1.0166  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:04:53 d2.utils.events]: \u001b[0m eta: 0:57:04  iter: 1779  total_loss: 0.4762  loss_cls: 0.07615  loss_box_reg: 0.1913  loss_mask: 0.1117  loss_rpn_cls: 0.004248  loss_rpn_loc: 0.07532    time: 1.0412  last_time: 1.0893  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:05:14 d2.utils.events]: \u001b[0m eta: 0:56:43  iter: 1799  total_loss: 0.4793  loss_cls: 0.06673  loss_box_reg: 0.1984  loss_mask: 0.1188  loss_rpn_cls: 0.00306  loss_rpn_loc: 0.05556    time: 1.0414  last_time: 1.1821  data_time: 0.0015  last_data_time: 0.0011   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:05:35 d2.utils.events]: \u001b[0m eta: 0:56:21  iter: 1819  total_loss: 0.5948  loss_cls: 0.08234  loss_box_reg: 0.2114  loss_mask: 0.133  loss_rpn_cls: 0.007609  loss_rpn_loc: 0.1367    time: 1.0415  last_time: 0.9375  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:05:57 d2.utils.events]: \u001b[0m eta: 0:56:00  iter: 1839  total_loss: 0.4375  loss_cls: 0.06689  loss_box_reg: 0.1785  loss_mask: 0.1188  loss_rpn_cls: 0.007969  loss_rpn_loc: 0.07476    time: 1.0420  last_time: 1.1805  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:06:18 d2.utils.events]: \u001b[0m eta: 0:55:39  iter: 1859  total_loss: 0.4492  loss_cls: 0.06335  loss_box_reg: 0.1963  loss_mask: 0.112  loss_rpn_cls: 0.008289  loss_rpn_loc: 0.07475    time: 1.0420  last_time: 1.0172  data_time: 0.0013  last_data_time: 0.0017   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:06:39 d2.utils.events]: \u001b[0m eta: 0:55:22  iter: 1879  total_loss: 0.5775  loss_cls: 0.09619  loss_box_reg: 0.2154  loss_mask: 0.1411  loss_rpn_cls: 0.009152  loss_rpn_loc: 0.1015    time: 1.0421  last_time: 1.1213  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:07:00 d2.utils.events]: \u001b[0m eta: 0:54:59  iter: 1899  total_loss: 0.5342  loss_cls: 0.07056  loss_box_reg: 0.2104  loss_mask: 0.1332  loss_rpn_cls: 0.006752  loss_rpn_loc: 0.09975    time: 1.0426  last_time: 1.0199  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:07:21 d2.utils.events]: \u001b[0m eta: 0:54:35  iter: 1919  total_loss: 0.4901  loss_cls: 0.07139  loss_box_reg: 0.1972  loss_mask: 0.125  loss_rpn_cls: 0.005956  loss_rpn_loc: 0.0862    time: 1.0424  last_time: 0.8544  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:07:41 d2.utils.events]: \u001b[0m eta: 0:54:12  iter: 1939  total_loss: 0.422  loss_cls: 0.07325  loss_box_reg: 0.1804  loss_mask: 0.125  loss_rpn_cls: 0.006311  loss_rpn_loc: 0.07722    time: 1.0419  last_time: 0.9394  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:08:02 d2.utils.events]: \u001b[0m eta: 0:53:50  iter: 1959  total_loss: 0.4703  loss_cls: 0.06857  loss_box_reg: 0.2012  loss_mask: 0.1129  loss_rpn_cls: 0.004977  loss_rpn_loc: 0.05684    time: 1.0420  last_time: 1.1832  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:08:23 d2.utils.events]: \u001b[0m eta: 0:53:33  iter: 1979  total_loss: 0.5134  loss_cls: 0.06771  loss_box_reg: 0.1841  loss_mask: 0.1202  loss_rpn_cls: 0.008081  loss_rpn_loc: 0.08208    time: 1.0424  last_time: 1.0777  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:08:45 d2.utils.events]: \u001b[0m eta: 0:53:13  iter: 1999  total_loss: 0.5234  loss_cls: 0.07597  loss_box_reg: 0.2065  loss_mask: 0.1257  loss_rpn_cls: 0.009688  loss_rpn_loc: 0.07341    time: 1.0425  last_time: 1.0929  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:09:05 d2.utils.events]: \u001b[0m eta: 0:52:50  iter: 2019  total_loss: 0.4147  loss_cls: 0.04988  loss_box_reg: 0.1554  loss_mask: 0.1082  loss_rpn_cls: 0.004324  loss_rpn_loc: 0.0608    time: 1.0425  last_time: 1.0947  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:09:27 d2.utils.events]: \u001b[0m eta: 0:52:31  iter: 2039  total_loss: 0.4988  loss_cls: 0.0808  loss_box_reg: 0.1925  loss_mask: 0.1224  loss_rpn_cls: 0.006113  loss_rpn_loc: 0.07519    time: 1.0427  last_time: 0.9374  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:09:48 d2.utils.events]: \u001b[0m eta: 0:52:11  iter: 2059  total_loss: 0.4925  loss_cls: 0.07152  loss_box_reg: 0.212  loss_mask: 0.1226  loss_rpn_cls: 0.00568  loss_rpn_loc: 0.09989    time: 1.0429  last_time: 0.8634  data_time: 0.0014  last_data_time: 0.0016   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:10:09 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 2079  total_loss: 0.5252  loss_cls: 0.06952  loss_box_reg: 0.2188  loss_mask: 0.1191  loss_rpn_cls: 0.006069  loss_rpn_loc: 0.09659    time: 1.0429  last_time: 1.0334  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:10:30 d2.utils.events]: \u001b[0m eta: 0:51:21  iter: 2099  total_loss: 0.4216  loss_cls: 0.06525  loss_box_reg: 0.1868  loss_mask: 0.1149  loss_rpn_cls: 0.00412  loss_rpn_loc: 0.06708    time: 1.0429  last_time: 0.9631  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:10:51 d2.utils.events]: \u001b[0m eta: 0:51:02  iter: 2119  total_loss: 0.4429  loss_cls: 0.07727  loss_box_reg: 0.1732  loss_mask: 0.1152  loss_rpn_cls: 0.006028  loss_rpn_loc: 0.08727    time: 1.0429  last_time: 1.1841  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:11:11 d2.utils.events]: \u001b[0m eta: 0:50:41  iter: 2139  total_loss: 0.4768  loss_cls: 0.07224  loss_box_reg: 0.1897  loss_mask: 0.11  loss_rpn_cls: 0.005241  loss_rpn_loc: 0.08574    time: 1.0429  last_time: 1.0068  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:11:33 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 2159  total_loss: 0.4926  loss_cls: 0.06009  loss_box_reg: 0.1921  loss_mask: 0.1237  loss_rpn_cls: 0.008  loss_rpn_loc: 0.08163    time: 1.0434  last_time: 1.0047  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:11:55 d2.utils.events]: \u001b[0m eta: 0:50:06  iter: 2179  total_loss: 0.4444  loss_cls: 0.05471  loss_box_reg: 0.1904  loss_mask: 0.1195  loss_rpn_cls: 0.006375  loss_rpn_loc: 0.05371    time: 1.0437  last_time: 0.9064  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:12:15 d2.utils.events]: \u001b[0m eta: 0:49:43  iter: 2199  total_loss: 0.4911  loss_cls: 0.06426  loss_box_reg: 0.2139  loss_mask: 0.129  loss_rpn_cls: 0.003859  loss_rpn_loc: 0.09243    time: 1.0436  last_time: 1.1723  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:12:36 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 2219  total_loss: 0.4093  loss_cls: 0.06923  loss_box_reg: 0.1693  loss_mask: 0.1079  loss_rpn_cls: 0.005574  loss_rpn_loc: 0.07441    time: 1.0436  last_time: 1.1535  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:12:58 d2.utils.events]: \u001b[0m eta: 0:49:02  iter: 2239  total_loss: 0.4591  loss_cls: 0.0657  loss_box_reg: 0.184  loss_mask: 0.1256  loss_rpn_cls: 0.009671  loss_rpn_loc: 0.09104    time: 1.0438  last_time: 1.0892  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:13:18 d2.utils.events]: \u001b[0m eta: 0:48:38  iter: 2259  total_loss: 0.6014  loss_cls: 0.07805  loss_box_reg: 0.2054  loss_mask: 0.1376  loss_rpn_cls: 0.01632  loss_rpn_loc: 0.1286    time: 1.0435  last_time: 1.0359  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:13:38 d2.utils.events]: \u001b[0m eta: 0:48:12  iter: 2279  total_loss: 0.5402  loss_cls: 0.07944  loss_box_reg: 0.2096  loss_mask: 0.1307  loss_rpn_cls: 0.009669  loss_rpn_loc: 0.09156    time: 1.0432  last_time: 0.8262  data_time: 0.0014  last_data_time: 0.0010   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:13:59 d2.utils.events]: \u001b[0m eta: 0:47:50  iter: 2299  total_loss: 0.4398  loss_cls: 0.05795  loss_box_reg: 0.1709  loss_mask: 0.1278  loss_rpn_cls: 0.003208  loss_rpn_loc: 0.07598    time: 1.0433  last_time: 1.0094  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:14:21 d2.utils.events]: \u001b[0m eta: 0:47:28  iter: 2319  total_loss: 0.5248  loss_cls: 0.08832  loss_box_reg: 0.1881  loss_mask: 0.1319  loss_rpn_cls: 0.009298  loss_rpn_loc: 0.1072    time: 1.0436  last_time: 1.0292  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:14:43 d2.utils.events]: \u001b[0m eta: 0:47:11  iter: 2339  total_loss: 0.4919  loss_cls: 0.06824  loss_box_reg: 0.2028  loss_mask: 0.1333  loss_rpn_cls: 0.008333  loss_rpn_loc: 0.08869    time: 1.0440  last_time: 1.1921  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:15:04 d2.utils.events]: \u001b[0m eta: 0:46:50  iter: 2359  total_loss: 0.454  loss_cls: 0.05474  loss_box_reg: 0.1909  loss_mask: 0.1159  loss_rpn_cls: 0.005178  loss_rpn_loc: 0.06263    time: 1.0443  last_time: 1.0981  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:15:25 d2.utils.events]: \u001b[0m eta: 0:46:30  iter: 2379  total_loss: 0.3944  loss_cls: 0.05614  loss_box_reg: 0.1721  loss_mask: 0.1213  loss_rpn_cls: 0.009423  loss_rpn_loc: 0.06542    time: 1.0443  last_time: 1.1831  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:15:46 d2.utils.events]: \u001b[0m eta: 0:46:07  iter: 2399  total_loss: 0.4592  loss_cls: 0.06075  loss_box_reg: 0.1881  loss_mask: 0.1198  loss_rpn_cls: 0.005051  loss_rpn_loc: 0.07302    time: 1.0444  last_time: 1.0819  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:16:07 d2.utils.events]: \u001b[0m eta: 0:45:48  iter: 2419  total_loss: 0.5291  loss_cls: 0.06763  loss_box_reg: 0.209  loss_mask: 0.1388  loss_rpn_cls: 0.005903  loss_rpn_loc: 0.08493    time: 1.0443  last_time: 0.9993  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:16:28 d2.utils.events]: \u001b[0m eta: 0:45:27  iter: 2439  total_loss: 0.4774  loss_cls: 0.06485  loss_box_reg: 0.2082  loss_mask: 0.1203  loss_rpn_cls: 0.004117  loss_rpn_loc: 0.0852    time: 1.0445  last_time: 1.1700  data_time: 0.0013  last_data_time: 0.0017   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:16:49 d2.utils.events]: \u001b[0m eta: 0:45:09  iter: 2459  total_loss: 0.4056  loss_cls: 0.05  loss_box_reg: 0.1652  loss_mask: 0.1106  loss_rpn_cls: 0.003132  loss_rpn_loc: 0.0697    time: 1.0444  last_time: 1.2074  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:17:10 d2.utils.events]: \u001b[0m eta: 0:44:49  iter: 2479  total_loss: 0.5544  loss_cls: 0.08193  loss_box_reg: 0.1891  loss_mask: 0.1226  loss_rpn_cls: 0.01523  loss_rpn_loc: 0.08909    time: 1.0446  last_time: 0.9456  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:17:31 d2.utils.events]: \u001b[0m eta: 0:44:25  iter: 2499  total_loss: 0.3893  loss_cls: 0.05213  loss_box_reg: 0.159  loss_mask: 0.1242  loss_rpn_cls: 0.005574  loss_rpn_loc: 0.06516    time: 1.0445  last_time: 1.1016  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:17:52 d2.utils.events]: \u001b[0m eta: 0:44:05  iter: 2519  total_loss: 0.5406  loss_cls: 0.07342  loss_box_reg: 0.2181  loss_mask: 0.1377  loss_rpn_cls: 0.01158  loss_rpn_loc: 0.119    time: 1.0444  last_time: 0.7971  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:18:12 d2.utils.events]: \u001b[0m eta: 0:43:41  iter: 2539  total_loss: 0.5232  loss_cls: 0.07659  loss_box_reg: 0.2225  loss_mask: 0.1307  loss_rpn_cls: 0.007724  loss_rpn_loc: 0.09975    time: 1.0444  last_time: 1.0355  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:18:34 d2.utils.events]: \u001b[0m eta: 0:43:24  iter: 2559  total_loss: 0.4327  loss_cls: 0.05349  loss_box_reg: 0.1861  loss_mask: 0.1123  loss_rpn_cls: 0.003768  loss_rpn_loc: 0.07266    time: 1.0448  last_time: 1.1716  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:18:55 d2.utils.events]: \u001b[0m eta: 0:43:07  iter: 2579  total_loss: 0.4845  loss_cls: 0.06473  loss_box_reg: 0.1854  loss_mask: 0.1239  loss_rpn_cls: 0.005593  loss_rpn_loc: 0.09187    time: 1.0448  last_time: 0.9180  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:19:16 d2.utils.events]: \u001b[0m eta: 0:42:45  iter: 2599  total_loss: 0.4291  loss_cls: 0.05951  loss_box_reg: 0.1706  loss_mask: 0.1141  loss_rpn_cls: 0.006288  loss_rpn_loc: 0.07564    time: 1.0447  last_time: 0.9437  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:19:37 d2.utils.events]: \u001b[0m eta: 0:42:26  iter: 2619  total_loss: 0.3996  loss_cls: 0.05665  loss_box_reg: 0.188  loss_mask: 0.1134  loss_rpn_cls: 0.003946  loss_rpn_loc: 0.05114    time: 1.0449  last_time: 0.9863  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:19:59 d2.utils.events]: \u001b[0m eta: 0:42:03  iter: 2639  total_loss: 0.5304  loss_cls: 0.05761  loss_box_reg: 0.2195  loss_mask: 0.1273  loss_rpn_cls: 0.007255  loss_rpn_loc: 0.09387    time: 1.0452  last_time: 1.1762  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:20:20 d2.utils.events]: \u001b[0m eta: 0:41:44  iter: 2659  total_loss: 0.5069  loss_cls: 0.0747  loss_box_reg: 0.1819  loss_mask: 0.125  loss_rpn_cls: 0.01022  loss_rpn_loc: 0.0935    time: 1.0452  last_time: 1.1359  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:20:41 d2.utils.events]: \u001b[0m eta: 0:41:23  iter: 2679  total_loss: 0.4959  loss_cls: 0.06052  loss_box_reg: 0.207  loss_mask: 0.1276  loss_rpn_cls: 0.002854  loss_rpn_loc: 0.08106    time: 1.0451  last_time: 1.0994  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:21:01 d2.utils.events]: \u001b[0m eta: 0:41:01  iter: 2699  total_loss: 0.4957  loss_cls: 0.06926  loss_box_reg: 0.1919  loss_mask: 0.1222  loss_rpn_cls: 0.00417  loss_rpn_loc: 0.09547    time: 1.0450  last_time: 1.0962  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:21:22 d2.utils.events]: \u001b[0m eta: 0:40:39  iter: 2719  total_loss: 0.5837  loss_cls: 0.08934  loss_box_reg: 0.2188  loss_mask: 0.1379  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.1189    time: 1.0449  last_time: 0.8365  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:21:43 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 2739  total_loss: 0.4605  loss_cls: 0.05163  loss_box_reg: 0.1933  loss_mask: 0.1124  loss_rpn_cls: 0.004813  loss_rpn_loc: 0.08353    time: 1.0449  last_time: 1.0195  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:22:04 d2.utils.events]: \u001b[0m eta: 0:39:54  iter: 2759  total_loss: 0.4167  loss_cls: 0.05139  loss_box_reg: 0.1518  loss_mask: 0.1168  loss_rpn_cls: 0.004763  loss_rpn_loc: 0.07319    time: 1.0451  last_time: 1.0710  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:22:25 d2.utils.events]: \u001b[0m eta: 0:39:33  iter: 2779  total_loss: 0.4121  loss_cls: 0.05524  loss_box_reg: 0.1724  loss_mask: 0.1156  loss_rpn_cls: 0.005592  loss_rpn_loc: 0.05873    time: 1.0451  last_time: 0.8386  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:22:45 d2.utils.events]: \u001b[0m eta: 0:39:09  iter: 2799  total_loss: 0.4944  loss_cls: 0.07432  loss_box_reg: 0.2039  loss_mask: 0.1341  loss_rpn_cls: 0.005539  loss_rpn_loc: 0.08267    time: 1.0448  last_time: 0.9360  data_time: 0.0014  last_data_time: 0.0017   lr: 0.001  max_mem: 5935M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:23:07 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 2819  total_loss: 0.5973  loss_cls: 0.08334  loss_box_reg: 0.2385  loss_mask: 0.1389  loss_rpn_cls: 0.006496  loss_rpn_loc: 0.126    time: 1.0450  last_time: 1.4065  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:23:27 d2.utils.events]: \u001b[0m eta: 0:38:23  iter: 2839  total_loss: 0.4968  loss_cls: 0.06179  loss_box_reg: 0.1857  loss_mask: 0.1337  loss_rpn_cls: 0.009087  loss_rpn_loc: 0.08377    time: 1.0449  last_time: 0.8556  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:23:49 d2.utils.events]: \u001b[0m eta: 0:38:04  iter: 2859  total_loss: 0.4737  loss_cls: 0.07415  loss_box_reg: 0.1855  loss_mask: 0.1285  loss_rpn_cls: 0.002847  loss_rpn_loc: 0.07279    time: 1.0451  last_time: 1.0230  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:24:10 d2.utils.events]: \u001b[0m eta: 0:37:41  iter: 2879  total_loss: 0.4198  loss_cls: 0.05234  loss_box_reg: 0.163  loss_mask: 0.108  loss_rpn_cls: 0.004089  loss_rpn_loc: 0.0707    time: 1.0451  last_time: 1.2249  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:24:31 d2.utils.events]: \u001b[0m eta: 0:37:20  iter: 2899  total_loss: 0.4759  loss_cls: 0.05883  loss_box_reg: 0.1927  loss_mask: 0.1183  loss_rpn_cls: 0.003122  loss_rpn_loc: 0.07089    time: 1.0453  last_time: 1.0399  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:24:53 d2.utils.events]: \u001b[0m eta: 0:36:59  iter: 2919  total_loss: 0.4533  loss_cls: 0.05929  loss_box_reg: 0.1703  loss_mask: 0.1257  loss_rpn_cls: 0.004543  loss_rpn_loc: 0.08119    time: 1.0455  last_time: 1.0931  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:25:12 d2.utils.events]: \u001b[0m eta: 0:36:35  iter: 2939  total_loss: 0.4367  loss_cls: 0.05602  loss_box_reg: 0.1642  loss_mask: 0.1169  loss_rpn_cls: 0.005418  loss_rpn_loc: 0.06895    time: 1.0450  last_time: 1.0233  data_time: 0.0013  last_data_time: 0.0010   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:25:33 d2.utils.events]: \u001b[0m eta: 0:36:15  iter: 2959  total_loss: 0.4475  loss_cls: 0.05173  loss_box_reg: 0.1734  loss_mask: 0.1241  loss_rpn_cls: 0.007998  loss_rpn_loc: 0.08764    time: 1.0450  last_time: 0.8789  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:25:55 d2.utils.events]: \u001b[0m eta: 0:35:54  iter: 2979  total_loss: 0.4232  loss_cls: 0.05013  loss_box_reg: 0.1678  loss_mask: 0.1256  loss_rpn_cls: 0.00403  loss_rpn_loc: 0.0725    time: 1.0452  last_time: 1.1688  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:26:16 d2.utils.events]: \u001b[0m eta: 0:35:34  iter: 2999  total_loss: 0.3864  loss_cls: 0.05113  loss_box_reg: 0.1688  loss_mask: 0.1061  loss_rpn_cls: 0.006842  loss_rpn_loc: 0.06285    time: 1.0453  last_time: 1.1822  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5935M\n",
      "\u001b[32m[01/23 14:26:37 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 3019  total_loss: 0.4459  loss_cls: 0.05819  loss_box_reg: 0.1782  loss_mask: 0.1245  loss_rpn_cls: 0.002539  loss_rpn_loc: 0.06539    time: 1.0455  last_time: 0.8596  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:26:58 d2.utils.events]: \u001b[0m eta: 0:34:51  iter: 3039  total_loss: 0.5052  loss_cls: 0.05706  loss_box_reg: 0.174  loss_mask: 0.131  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.08999    time: 1.0455  last_time: 1.0816  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:27:19 d2.utils.events]: \u001b[0m eta: 0:34:29  iter: 3059  total_loss: 0.4888  loss_cls: 0.05724  loss_box_reg: 0.21  loss_mask: 0.1221  loss_rpn_cls: 0.006671  loss_rpn_loc: 0.08353    time: 1.0453  last_time: 1.1981  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:27:40 d2.utils.events]: \u001b[0m eta: 0:34:09  iter: 3079  total_loss: 0.4328  loss_cls: 0.05412  loss_box_reg: 0.1914  loss_mask: 0.1218  loss_rpn_cls: 0.006786  loss_rpn_loc: 0.06902    time: 1.0456  last_time: 0.8421  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:28:01 d2.utils.events]: \u001b[0m eta: 0:33:49  iter: 3099  total_loss: 0.3546  loss_cls: 0.0432  loss_box_reg: 0.1308  loss_mask: 0.1027  loss_rpn_cls: 0.005046  loss_rpn_loc: 0.05159    time: 1.0455  last_time: 0.8564  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:28:21 d2.utils.events]: \u001b[0m eta: 0:33:27  iter: 3119  total_loss: 0.5221  loss_cls: 0.06172  loss_box_reg: 0.2006  loss_mask: 0.1377  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.0811    time: 1.0452  last_time: 1.0793  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:28:43 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 3139  total_loss: 0.5065  loss_cls: 0.06464  loss_box_reg: 0.2101  loss_mask: 0.1381  loss_rpn_cls: 0.006042  loss_rpn_loc: 0.08148    time: 1.0455  last_time: 1.2199  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:29:04 d2.utils.events]: \u001b[0m eta: 0:32:47  iter: 3159  total_loss: 0.4511  loss_cls: 0.05553  loss_box_reg: 0.1667  loss_mask: 0.1184  loss_rpn_cls: 0.002801  loss_rpn_loc: 0.06224    time: 1.0455  last_time: 1.1914  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:29:25 d2.utils.events]: \u001b[0m eta: 0:32:26  iter: 3179  total_loss: 0.4766  loss_cls: 0.05477  loss_box_reg: 0.1897  loss_mask: 0.1106  loss_rpn_cls: 0.00333  loss_rpn_loc: 0.06806    time: 1.0457  last_time: 1.1845  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:29:46 d2.utils.events]: \u001b[0m eta: 0:32:05  iter: 3199  total_loss: 0.3682  loss_cls: 0.04882  loss_box_reg: 0.154  loss_mask: 0.1048  loss_rpn_cls: 0.004035  loss_rpn_loc: 0.04301    time: 1.0458  last_time: 1.0829  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:30:07 d2.utils.events]: \u001b[0m eta: 0:31:43  iter: 3219  total_loss: 0.4891  loss_cls: 0.06599  loss_box_reg: 0.2011  loss_mask: 0.1194  loss_rpn_cls: 0.00758  loss_rpn_loc: 0.08994    time: 1.0456  last_time: 1.0622  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:30:28 d2.utils.events]: \u001b[0m eta: 0:31:23  iter: 3239  total_loss: 0.5212  loss_cls: 0.05886  loss_box_reg: 0.2082  loss_mask: 0.1273  loss_rpn_cls: 0.003505  loss_rpn_loc: 0.0827    time: 1.0458  last_time: 1.0310  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:30:50 d2.utils.events]: \u001b[0m eta: 0:31:02  iter: 3259  total_loss: 0.5105  loss_cls: 0.0696  loss_box_reg: 0.216  loss_mask: 0.1157  loss_rpn_cls: 0.004469  loss_rpn_loc: 0.09091    time: 1.0459  last_time: 1.0933  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:31:11 d2.utils.events]: \u001b[0m eta: 0:30:42  iter: 3279  total_loss: 0.5733  loss_cls: 0.07086  loss_box_reg: 0.2239  loss_mask: 0.1382  loss_rpn_cls: 0.005124  loss_rpn_loc: 0.09397    time: 1.0459  last_time: 1.2109  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:31:32 d2.utils.events]: \u001b[0m eta: 0:30:20  iter: 3299  total_loss: 0.5535  loss_cls: 0.07544  loss_box_reg: 0.2173  loss_mask: 0.1192  loss_rpn_cls: 0.006521  loss_rpn_loc: 0.1091    time: 1.0460  last_time: 0.9484  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:31:53 d2.utils.events]: \u001b[0m eta: 0:29:59  iter: 3319  total_loss: 0.3726  loss_cls: 0.05165  loss_box_reg: 0.1695  loss_mask: 0.1046  loss_rpn_cls: 0.004819  loss_rpn_loc: 0.04918    time: 1.0461  last_time: 1.1880  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:32:15 d2.utils.events]: \u001b[0m eta: 0:29:37  iter: 3339  total_loss: 0.3756  loss_cls: 0.05194  loss_box_reg: 0.1542  loss_mask: 0.1084  loss_rpn_cls: 0.005428  loss_rpn_loc: 0.07341    time: 1.0463  last_time: 1.1913  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:32:36 d2.utils.events]: \u001b[0m eta: 0:29:16  iter: 3359  total_loss: 0.4967  loss_cls: 0.06873  loss_box_reg: 0.1827  loss_mask: 0.134  loss_rpn_cls: 0.009556  loss_rpn_loc: 0.07193    time: 1.0463  last_time: 1.1794  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:32:57 d2.utils.events]: \u001b[0m eta: 0:28:55  iter: 3379  total_loss: 0.4654  loss_cls: 0.0633  loss_box_reg: 0.1874  loss_mask: 0.1306  loss_rpn_cls: 0.005715  loss_rpn_loc: 0.07671    time: 1.0465  last_time: 1.1764  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:33:18 d2.utils.events]: \u001b[0m eta: 0:28:34  iter: 3399  total_loss: 0.5101  loss_cls: 0.06715  loss_box_reg: 0.1908  loss_mask: 0.1265  loss_rpn_cls: 0.004665  loss_rpn_loc: 0.08827    time: 1.0465  last_time: 0.7996  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:33:39 d2.utils.events]: \u001b[0m eta: 0:28:12  iter: 3419  total_loss: 0.48  loss_cls: 0.05648  loss_box_reg: 0.1939  loss_mask: 0.1203  loss_rpn_cls: 0.005354  loss_rpn_loc: 0.07502    time: 1.0465  last_time: 1.0610  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:34:01 d2.utils.events]: \u001b[0m eta: 0:27:52  iter: 3439  total_loss: 0.4236  loss_cls: 0.06827  loss_box_reg: 0.166  loss_mask: 0.125  loss_rpn_cls: 0.003285  loss_rpn_loc: 0.08212    time: 1.0468  last_time: 1.0699  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:34:22 d2.utils.events]: \u001b[0m eta: 0:27:30  iter: 3459  total_loss: 0.4994  loss_cls: 0.06748  loss_box_reg: 0.1996  loss_mask: 0.1328  loss_rpn_cls: 0.009903  loss_rpn_loc: 0.08774    time: 1.0468  last_time: 0.9875  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:34:42 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 3479  total_loss: 0.446  loss_cls: 0.06068  loss_box_reg: 0.2049  loss_mask: 0.1041  loss_rpn_cls: 0.004334  loss_rpn_loc: 0.06817    time: 1.0467  last_time: 1.0472  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:35:03 d2.utils.events]: \u001b[0m eta: 0:26:48  iter: 3499  total_loss: 0.4691  loss_cls: 0.05765  loss_box_reg: 0.2006  loss_mask: 0.1233  loss_rpn_cls: 0.005233  loss_rpn_loc: 0.06253    time: 1.0466  last_time: 1.0811  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:35:24 d2.utils.events]: \u001b[0m eta: 0:26:26  iter: 3519  total_loss: 0.4489  loss_cls: 0.07107  loss_box_reg: 0.1794  loss_mask: 0.1212  loss_rpn_cls: 0.005379  loss_rpn_loc: 0.07396    time: 1.0465  last_time: 1.1653  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:35:45 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 3539  total_loss: 0.4042  loss_cls: 0.04326  loss_box_reg: 0.1692  loss_mask: 0.1048  loss_rpn_cls: 0.006455  loss_rpn_loc: 0.07861    time: 1.0465  last_time: 1.1841  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:36:06 d2.utils.events]: \u001b[0m eta: 0:25:43  iter: 3559  total_loss: 0.5597  loss_cls: 0.05954  loss_box_reg: 0.2118  loss_mask: 0.1281  loss_rpn_cls: 0.005417  loss_rpn_loc: 0.1    time: 1.0466  last_time: 0.9247  data_time: 0.0014  last_data_time: 0.0022   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:36:27 d2.utils.events]: \u001b[0m eta: 0:25:22  iter: 3579  total_loss: 0.4132  loss_cls: 0.05791  loss_box_reg: 0.1658  loss_mask: 0.1083  loss_rpn_cls: 0.006898  loss_rpn_loc: 0.0717    time: 1.0467  last_time: 0.9836  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:36:48 d2.utils.events]: \u001b[0m eta: 0:25:01  iter: 3599  total_loss: 0.4559  loss_cls: 0.05511  loss_box_reg: 0.1669  loss_mask: 0.1141  loss_rpn_cls: 0.006414  loss_rpn_loc: 0.07876    time: 1.0467  last_time: 1.1656  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:37:09 d2.utils.events]: \u001b[0m eta: 0:24:39  iter: 3619  total_loss: 0.4231  loss_cls: 0.05467  loss_box_reg: 0.1618  loss_mask: 0.09778  loss_rpn_cls: 0.006145  loss_rpn_loc: 0.06749    time: 1.0466  last_time: 0.8484  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:37:31 d2.utils.events]: \u001b[0m eta: 0:24:16  iter: 3639  total_loss: 0.3947  loss_cls: 0.05357  loss_box_reg: 0.1699  loss_mask: 0.111  loss_rpn_cls: 0.003757  loss_rpn_loc: 0.0599    time: 1.0469  last_time: 1.1813  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:37:51 d2.utils.events]: \u001b[0m eta: 0:23:54  iter: 3659  total_loss: 0.3877  loss_cls: 0.0588  loss_box_reg: 0.1593  loss_mask: 0.1131  loss_rpn_cls: 0.00351  loss_rpn_loc: 0.05449    time: 1.0467  last_time: 1.0022  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:38:11 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 3679  total_loss: 0.5279  loss_cls: 0.07051  loss_box_reg: 0.2087  loss_mask: 0.1418  loss_rpn_cls: 0.01105  loss_rpn_loc: 0.106    time: 1.0465  last_time: 1.0222  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:38:32 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 3699  total_loss: 0.398  loss_cls: 0.05264  loss_box_reg: 0.155  loss_mask: 0.111  loss_rpn_cls: 0.005655  loss_rpn_loc: 0.0828    time: 1.0464  last_time: 0.9204  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:38:54 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 3719  total_loss: 0.42  loss_cls: 0.05632  loss_box_reg: 0.1609  loss_mask: 0.1121  loss_rpn_cls: 0.003973  loss_rpn_loc: 0.06714    time: 1.0467  last_time: 1.0104  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:39:15 d2.utils.events]: \u001b[0m eta: 0:22:27  iter: 3739  total_loss: 0.4643  loss_cls: 0.06415  loss_box_reg: 0.1988  loss_mask: 0.1338  loss_rpn_cls: 0.006121  loss_rpn_loc: 0.101    time: 1.0469  last_time: 1.0211  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:39:35 d2.utils.events]: \u001b[0m eta: 0:22:05  iter: 3759  total_loss: 0.476  loss_cls: 0.05377  loss_box_reg: 0.1914  loss_mask: 0.1177  loss_rpn_cls: 0.005426  loss_rpn_loc: 0.08903    time: 1.0465  last_time: 1.0873  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:39:56 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 3779  total_loss: 0.442  loss_cls: 0.06716  loss_box_reg: 0.1996  loss_mask: 0.1114  loss_rpn_cls: 0.005816  loss_rpn_loc: 0.06361    time: 1.0466  last_time: 0.8034  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:40:15 d2.utils.events]: \u001b[0m eta: 0:21:21  iter: 3799  total_loss: 0.4437  loss_cls: 0.05203  loss_box_reg: 0.1738  loss_mask: 0.1207  loss_rpn_cls: 0.006565  loss_rpn_loc: 0.07636    time: 1.0461  last_time: 0.8229  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:40:37 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 3819  total_loss: 0.434  loss_cls: 0.06504  loss_box_reg: 0.1881  loss_mask: 0.1214  loss_rpn_cls: 0.003462  loss_rpn_loc: 0.0829    time: 1.0462  last_time: 1.0095  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:40:58 d2.utils.events]: \u001b[0m eta: 0:20:39  iter: 3839  total_loss: 0.4452  loss_cls: 0.05673  loss_box_reg: 0.1963  loss_mask: 0.1141  loss_rpn_cls: 0.005017  loss_rpn_loc: 0.06961    time: 1.0463  last_time: 1.0493  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:41:19 d2.utils.events]: \u001b[0m eta: 0:20:18  iter: 3859  total_loss: 0.449  loss_cls: 0.06712  loss_box_reg: 0.1758  loss_mask: 0.1105  loss_rpn_cls: 0.00444  loss_rpn_loc: 0.07732    time: 1.0464  last_time: 1.1722  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:41:41 d2.utils.events]: \u001b[0m eta: 0:19:56  iter: 3879  total_loss: 0.4431  loss_cls: 0.05552  loss_box_reg: 0.1683  loss_mask: 0.1169  loss_rpn_cls: 0.003485  loss_rpn_loc: 0.0888    time: 1.0465  last_time: 1.1550  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:42:01 d2.utils.events]: \u001b[0m eta: 0:19:33  iter: 3899  total_loss: 0.4749  loss_cls: 0.06964  loss_box_reg: 0.1861  loss_mask: 0.127  loss_rpn_cls: 0.006236  loss_rpn_loc: 0.08501    time: 1.0462  last_time: 0.9205  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:42:21 d2.utils.events]: \u001b[0m eta: 0:19:10  iter: 3919  total_loss: 0.3612  loss_cls: 0.04591  loss_box_reg: 0.1351  loss_mask: 0.1037  loss_rpn_cls: 0.001649  loss_rpn_loc: 0.05392    time: 1.0461  last_time: 0.9177  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:42:42 d2.utils.events]: \u001b[0m eta: 0:18:50  iter: 3939  total_loss: 0.4751  loss_cls: 0.06236  loss_box_reg: 0.1841  loss_mask: 0.117  loss_rpn_cls: 0.003487  loss_rpn_loc: 0.07753    time: 1.0460  last_time: 1.0110  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:43:02 d2.utils.events]: \u001b[0m eta: 0:18:27  iter: 3959  total_loss: 0.3963  loss_cls: 0.05173  loss_box_reg: 0.1675  loss_mask: 0.1146  loss_rpn_cls: 0.00319  loss_rpn_loc: 0.07555    time: 1.0459  last_time: 0.8116  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:43:22 d2.utils.events]: \u001b[0m eta: 0:18:03  iter: 3979  total_loss: 0.4349  loss_cls: 0.05588  loss_box_reg: 0.1774  loss_mask: 0.1039  loss_rpn_cls: 0.004789  loss_rpn_loc: 0.07004    time: 1.0457  last_time: 0.8315  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:43:43 d2.utils.events]: \u001b[0m eta: 0:17:41  iter: 3999  total_loss: 0.422  loss_cls: 0.05535  loss_box_reg: 0.1654  loss_mask: 0.09036  loss_rpn_cls: 0.002528  loss_rpn_loc: 0.07809    time: 1.0458  last_time: 1.0666  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:44:05 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 4019  total_loss: 0.3967  loss_cls: 0.05378  loss_box_reg: 0.1763  loss_mask: 0.1104  loss_rpn_cls: 0.004394  loss_rpn_loc: 0.0728    time: 1.0458  last_time: 1.1369  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:44:24 d2.utils.events]: \u001b[0m eta: 0:16:58  iter: 4039  total_loss: 0.4342  loss_cls: 0.05066  loss_box_reg: 0.1658  loss_mask: 0.1151  loss_rpn_cls: 0.004685  loss_rpn_loc: 0.09028    time: 1.0456  last_time: 0.8358  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:44:46 d2.utils.events]: \u001b[0m eta: 0:16:37  iter: 4059  total_loss: 0.3739  loss_cls: 0.0463  loss_box_reg: 0.1422  loss_mask: 0.1216  loss_rpn_cls: 0.001853  loss_rpn_loc: 0.05537    time: 1.0456  last_time: 1.1431  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:45:07 d2.utils.events]: \u001b[0m eta: 0:16:16  iter: 4079  total_loss: 0.4056  loss_cls: 0.06136  loss_box_reg: 0.1653  loss_mask: 0.1128  loss_rpn_cls: 0.003741  loss_rpn_loc: 0.06987    time: 1.0457  last_time: 1.1394  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:45:32 d2.utils.events]: \u001b[0m eta: 0:15:55  iter: 4099  total_loss: 0.3805  loss_cls: 0.04919  loss_box_reg: 0.1493  loss_mask: 0.1031  loss_rpn_cls: 0.00747  loss_rpn_loc: 0.07132    time: 1.0469  last_time: 1.9221  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:46:15 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 4119  total_loss: 0.4907  loss_cls: 0.05966  loss_box_reg: 0.1946  loss_mask: 0.1252  loss_rpn_cls: 0.004039  loss_rpn_loc: 0.07988    time: 1.0522  last_time: 1.5482  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:46:45 d2.utils.events]: \u001b[0m eta: 0:15:16  iter: 4139  total_loss: 0.473  loss_cls: 0.06748  loss_box_reg: 0.1813  loss_mask: 0.1228  loss_rpn_cls: 0.006548  loss_rpn_loc: 0.08922    time: 1.0543  last_time: 1.7210  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:47:15 d2.utils.events]: \u001b[0m eta: 0:14:56  iter: 4159  total_loss: 0.4495  loss_cls: 0.05453  loss_box_reg: 0.1891  loss_mask: 0.1197  loss_rpn_cls: 0.003324  loss_rpn_loc: 0.07996    time: 1.0563  last_time: 1.4133  data_time: 0.0014  last_data_time: 0.0016   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:47:45 d2.utils.events]: \u001b[0m eta: 0:14:36  iter: 4179  total_loss: 0.4278  loss_cls: 0.05131  loss_box_reg: 0.1712  loss_mask: 0.1165  loss_rpn_cls: 0.002678  loss_rpn_loc: 0.06666    time: 1.0586  last_time: 1.7147  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:48:16 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 4199  total_loss: 0.3933  loss_cls: 0.051  loss_box_reg: 0.1622  loss_mask: 0.1181  loss_rpn_cls: 0.002926  loss_rpn_loc: 0.05983    time: 1.0609  last_time: 1.5221  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:48:46 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 4219  total_loss: 0.4845  loss_cls: 0.06398  loss_box_reg: 0.2062  loss_mask: 0.1277  loss_rpn_cls: 0.005967  loss_rpn_loc: 0.09631    time: 1.0630  last_time: 1.7290  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:49:17 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 4239  total_loss: 0.4469  loss_cls: 0.0519  loss_box_reg: 0.1868  loss_mask: 0.1145  loss_rpn_cls: 0.008112  loss_rpn_loc: 0.0765    time: 1.0653  last_time: 1.7567  data_time: 0.0014  last_data_time: 0.0017   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:49:47 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 4259  total_loss: 0.4408  loss_cls: 0.054  loss_box_reg: 0.1863  loss_mask: 0.1081  loss_rpn_cls: 0.0043  loss_rpn_loc: 0.102    time: 1.0674  last_time: 1.3222  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:50:19 d2.utils.events]: \u001b[0m eta: 0:12:56  iter: 4279  total_loss: 0.4074  loss_cls: 0.05929  loss_box_reg: 0.1743  loss_mask: 0.1072  loss_rpn_cls: 0.005555  loss_rpn_loc: 0.05228    time: 1.0698  last_time: 1.6982  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:50:49 d2.utils.events]: \u001b[0m eta: 0:12:36  iter: 4299  total_loss: 0.4722  loss_cls: 0.06343  loss_box_reg: 0.186  loss_mask: 0.11  loss_rpn_cls: 0.007312  loss_rpn_loc: 0.07961    time: 1.0719  last_time: 1.6400  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:51:20 d2.utils.events]: \u001b[0m eta: 0:12:16  iter: 4319  total_loss: 0.5057  loss_cls: 0.07317  loss_box_reg: 0.2039  loss_mask: 0.1174  loss_rpn_cls: 0.006583  loss_rpn_loc: 0.1033    time: 1.0741  last_time: 1.7475  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:51:51 d2.utils.events]: \u001b[0m eta: 0:11:57  iter: 4339  total_loss: 0.4206  loss_cls: 0.04552  loss_box_reg: 0.1659  loss_mask: 0.1213  loss_rpn_cls: 0.002799  loss_rpn_loc: 0.06708    time: 1.0761  last_time: 1.7179  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:52:19 d2.utils.events]: \u001b[0m eta: 0:11:38  iter: 4359  total_loss: 0.4955  loss_cls: 0.06415  loss_box_reg: 0.1717  loss_mask: 0.1342  loss_rpn_cls: 0.005498  loss_rpn_loc: 0.1002    time: 1.0778  last_time: 1.1519  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:52:49 d2.utils.events]: \u001b[0m eta: 0:11:20  iter: 4379  total_loss: 0.401  loss_cls: 0.04586  loss_box_reg: 0.1469  loss_mask: 0.118  loss_rpn_cls: 0.00269  loss_rpn_loc: 0.06528    time: 1.0797  last_time: 1.6716  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:53:18 d2.utils.events]: \u001b[0m eta: 0:11:12  iter: 4399  total_loss: 0.3873  loss_cls: 0.0456  loss_box_reg: 0.1504  loss_mask: 0.1007  loss_rpn_cls: 0.002451  loss_rpn_loc: 0.07325    time: 1.0814  last_time: 1.4833  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:53:50 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 4419  total_loss: 0.4073  loss_cls: 0.04788  loss_box_reg: 0.1702  loss_mask: 0.1144  loss_rpn_cls: 0.003854  loss_rpn_loc: 0.068    time: 1.0837  last_time: 1.4613  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:54:21 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 4439  total_loss: 0.4164  loss_cls: 0.05983  loss_box_reg: 0.1804  loss_mask: 0.1161  loss_rpn_cls: 0.003271  loss_rpn_loc: 0.07349    time: 1.0857  last_time: 1.5314  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:54:52 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 4459  total_loss: 0.3771  loss_cls: 0.05483  loss_box_reg: 0.1508  loss_mask: 0.1086  loss_rpn_cls: 0.002563  loss_rpn_loc: 0.06479    time: 1.0878  last_time: 1.4676  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:55:23 d2.utils.events]: \u001b[0m eta: 0:10:03  iter: 4479  total_loss: 0.373  loss_cls: 0.05202  loss_box_reg: 0.1447  loss_mask: 0.1165  loss_rpn_cls: 0.003051  loss_rpn_loc: 0.06313    time: 1.0898  last_time: 1.4979  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 14:55:54 d2.utils.events]: \u001b[0m eta: 0:09:42  iter: 4499  total_loss: 0.4488  loss_cls: 0.05667  loss_box_reg: 0.1946  loss_mask: 0.1174  loss_rpn_cls: 0.005818  loss_rpn_loc: 0.08123    time: 1.0919  last_time: 1.5703  data_time: 0.0015  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:56:22 d2.utils.events]: \u001b[0m eta: 0:09:21  iter: 4519  total_loss: 0.4227  loss_cls: 0.05748  loss_box_reg: 0.17  loss_mask: 0.1044  loss_rpn_cls: 0.005073  loss_rpn_loc: 0.06068    time: 1.0933  last_time: 1.4704  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:56:53 d2.utils.events]: \u001b[0m eta: 0:08:59  iter: 4539  total_loss: 0.4747  loss_cls: 0.06114  loss_box_reg: 0.1847  loss_mask: 0.1174  loss_rpn_cls: 0.008778  loss_rpn_loc: 0.08698    time: 1.0953  last_time: 1.4835  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:57:23 d2.utils.events]: \u001b[0m eta: 0:08:37  iter: 4559  total_loss: 0.3665  loss_cls: 0.05016  loss_box_reg: 0.14  loss_mask: 0.09992  loss_rpn_cls: 0.001628  loss_rpn_loc: 0.06416    time: 1.0971  last_time: 1.4971  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:57:54 d2.utils.events]: \u001b[0m eta: 0:08:15  iter: 4579  total_loss: 0.4371  loss_cls: 0.04583  loss_box_reg: 0.1675  loss_mask: 0.117  loss_rpn_cls: 0.00315  loss_rpn_loc: 0.06308    time: 1.0991  last_time: 1.4951  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:58:26 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 4599  total_loss: 0.4252  loss_cls: 0.05356  loss_box_reg: 0.1617  loss_mask: 0.1105  loss_rpn_cls: 0.002701  loss_rpn_loc: 0.08203    time: 1.1012  last_time: 1.7206  data_time: 0.0014  last_data_time: 0.0017   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:58:56 d2.utils.events]: \u001b[0m eta: 0:07:40  iter: 4619  total_loss: 0.459  loss_cls: 0.05373  loss_box_reg: 0.1893  loss_mask: 0.1296  loss_rpn_cls: 0.004051  loss_rpn_loc: 0.08542    time: 1.1029  last_time: 1.7406  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 14:59:27 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 4639  total_loss: 0.4316  loss_cls: 0.05378  loss_box_reg: 0.1773  loss_mask: 0.116  loss_rpn_cls: 0.003616  loss_rpn_loc: 0.08731    time: 1.1049  last_time: 1.1488  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:00:03 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 4659  total_loss: 0.4334  loss_cls: 0.05139  loss_box_reg: 0.1832  loss_mask: 0.1099  loss_rpn_cls: 0.005037  loss_rpn_loc: 0.07013    time: 1.1079  last_time: 1.8150  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:00:36 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 4679  total_loss: 0.4017  loss_cls: 0.05365  loss_box_reg: 0.1653  loss_mask: 0.1209  loss_rpn_cls: 0.005108  loss_rpn_loc: 0.05817    time: 1.1102  last_time: 1.2792  data_time: 0.0014  last_data_time: 0.0015   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:01:09 d2.utils.events]: \u001b[0m eta: 0:06:41  iter: 4699  total_loss: 0.4258  loss_cls: 0.05478  loss_box_reg: 0.1772  loss_mask: 0.1071  loss_rpn_cls: 0.004324  loss_rpn_loc: 0.05623    time: 1.1124  last_time: 1.6249  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:01:41 d2.utils.events]: \u001b[0m eta: 0:06:24  iter: 4719  total_loss: 0.4059  loss_cls: 0.05569  loss_box_reg: 0.1543  loss_mask: 0.1049  loss_rpn_cls: 0.005898  loss_rpn_loc: 0.08059    time: 1.1145  last_time: 1.7233  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:02:13 d2.utils.events]: \u001b[0m eta: 0:06:10  iter: 4739  total_loss: 0.433  loss_cls: 0.06666  loss_box_reg: 0.1753  loss_mask: 0.1114  loss_rpn_cls: 0.007095  loss_rpn_loc: 0.06344    time: 1.1167  last_time: 1.4085  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:02:46 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 4759  total_loss: 0.4079  loss_cls: 0.05751  loss_box_reg: 0.1707  loss_mask: 0.1101  loss_rpn_cls: 0.002728  loss_rpn_loc: 0.07485    time: 1.1188  last_time: 1.6392  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:03:20 d2.utils.events]: \u001b[0m eta: 0:05:20  iter: 4779  total_loss: 0.4459  loss_cls: 0.06073  loss_box_reg: 0.1624  loss_mask: 0.1138  loss_rpn_cls: 0.007197  loss_rpn_loc: 0.07134    time: 1.1213  last_time: 1.6706  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:03:58 d2.utils.events]: \u001b[0m eta: 0:04:53  iter: 4799  total_loss: 0.3907  loss_cls: 0.04575  loss_box_reg: 0.1516  loss_mask: 0.1154  loss_rpn_cls: 0.004107  loss_rpn_loc: 0.06333    time: 1.1245  last_time: 1.6117  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:04:30 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 4819  total_loss: 0.3665  loss_cls: 0.04413  loss_box_reg: 0.1477  loss_mask: 0.1077  loss_rpn_cls: 0.002627  loss_rpn_loc: 0.05695    time: 1.1265  last_time: 1.6541  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:05:03 d2.utils.events]: \u001b[0m eta: 0:03:57  iter: 4839  total_loss: 0.4391  loss_cls: 0.05568  loss_box_reg: 0.1662  loss_mask: 0.1175  loss_rpn_cls: 0.004934  loss_rpn_loc: 0.07169    time: 1.1287  last_time: 1.6187  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:05:37 d2.utils.events]: \u001b[0m eta: 0:03:28  iter: 4859  total_loss: 0.5069  loss_cls: 0.06472  loss_box_reg: 0.1878  loss_mask: 0.1348  loss_rpn_cls: 0.005728  loss_rpn_loc: 0.08633    time: 1.1310  last_time: 1.3137  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:06:12 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 4879  total_loss: 0.378  loss_cls: 0.05008  loss_box_reg: 0.1652  loss_mask: 0.1033  loss_rpn_cls: 0.002747  loss_rpn_loc: 0.06849    time: 1.1336  last_time: 1.6223  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:06:46 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 4899  total_loss: 0.3222  loss_cls: 0.03905  loss_box_reg: 0.1296  loss_mask: 0.1016  loss_rpn_cls: 0.003219  loss_rpn_loc: 0.05342    time: 1.1358  last_time: 1.6643  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:07:19 d2.utils.events]: \u001b[0m eta: 0:02:00  iter: 4919  total_loss: 0.3934  loss_cls: 0.04765  loss_box_reg: 0.1582  loss_mask: 0.09524  loss_rpn_cls: 0.002473  loss_rpn_loc: 0.06321    time: 1.1380  last_time: 1.7091  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:07:53 d2.utils.events]: \u001b[0m eta: 0:01:30  iter: 4939  total_loss: 0.4559  loss_cls: 0.06659  loss_box_reg: 0.1839  loss_mask: 0.1182  loss_rpn_cls: 0.002535  loss_rpn_loc: 0.06294    time: 1.1402  last_time: 1.4592  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:08:27 d2.utils.events]: \u001b[0m eta: 0:01:00  iter: 4959  total_loss: 0.4626  loss_cls: 0.0606  loss_box_reg: 0.1721  loss_mask: 0.1161  loss_rpn_cls: 0.01276  loss_rpn_loc: 0.09051    time: 1.1424  last_time: 1.3441  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:09:00 d2.utils.events]: \u001b[0m eta: 0:00:30  iter: 4979  total_loss: 0.3731  loss_cls: 0.04316  loss_box_reg: 0.1621  loss_mask: 0.1136  loss_rpn_cls: 0.003303  loss_rpn_loc: 0.06452    time: 1.1444  last_time: 1.7149  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:09:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4999  total_loss: 0.4549  loss_cls: 0.06539  loss_box_reg: 0.1917  loss_mask: 0.1213  loss_rpn_cls: 0.006189  loss_rpn_loc: 0.06763    time: 1.1469  last_time: 2.8222  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5937M\n",
      "\u001b[32m[01/23 15:09:38 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 1:35:32 (1.1469 s / it)\n",
      "\u001b[32m[01/23 15:09:38 d2.engine.hooks]: \u001b[0mTotal training time: 1:35:40 (0:00:08 on hooks)\n"
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07780b4f",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "I personally restart the kernel here to empty the memory and rerun everything except the trainer cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98e1f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables and constants for the evaluation\n",
    "IOU_THRESHOLD = 0.5\n",
    "data_csv = pd.read_csv(os.path.join(datasets_dir, 'data_complete.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78edc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 18:09:27 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from output_extended\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold (in this case the same as the training threshold)\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d647ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_standard_masks(input_image_path):\n",
    "    '''\n",
    "    Create a separate mask for every annotated region of an image\n",
    "    @param  string      The path to the image\n",
    "    @return np.array    The numpy array representation of the masks with the \n",
    "                        dimensions of the image and the golden \n",
    "                        standard region drawn on it. Only the golden standard\n",
    "                        region coordinates have the value True, the rest \n",
    "                        is False.\n",
    "    '''\n",
    "    \n",
    "    # load the image\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    \n",
    "    # get the golden standard for the image\n",
    "    gold_standard_image = data_json[os.path.split(input_image_path)[-1]]\n",
    "    \n",
    "    # make sure that we have the golden standard for the image\n",
    "    if not gold_standard_image: return None\n",
    "    \n",
    "    # get the golden standard regions for the image\n",
    "    gold_standard_regions = gold_standard_image['regions']\n",
    "    \n",
    "    # extract the polygons from the regions\n",
    "    polygons = [r['shape_attributes'] for r in gold_standard_regions]\n",
    "    \n",
    "    # array holding all masks\n",
    "    masks = []\n",
    "    \n",
    "    # construct the polygon arrays and add them to the mask\n",
    "    for polygon in polygons:\n",
    "        \n",
    "        # create the initial mask (black) with the dimensions of the original image\n",
    "        mask = np.zeros(np.array(input_image).shape, dtype = \"uint8\")\n",
    "        \n",
    "        if polygon['name'] == 'rect':\n",
    "            bottom_left = [polygon['x'], polygon['y']]\n",
    "            bottom_right = [polygon['x']+polygon['width'], polygon['y']]\n",
    "            top_right = [polygon['x']+polygon['width'], polygon['y']+polygon['height']]\n",
    "            top_left = [polygon['x'], polygon['y']+polygon['height']]\n",
    "            \n",
    "            gold_standard_polygon_xy = [bottom_left, bottom_right, top_right, top_left]\n",
    "        else:\n",
    "            # If not a rectangle we have a more complex shape and we just add all points to it\n",
    "            gold_standard_polygon_xy  = [[polygon['all_points_x'][i], polygon['all_points_y'][i]] for i in range(0, len(polygon['all_points_x']))]\n",
    "\n",
    "        # add the polygon (white) to the mask\n",
    "        mask = cv2.fillPoly(mask, [np.array(gold_standard_polygon_xy, np.int32)], (255,255,255))   \n",
    "        \n",
    "        # save the mask with a single channel with boolean values\n",
    "        masks.append(np.array(mask).astype(bool)[:, :, 0])\n",
    "\n",
    "    # return the masks\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c267170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_calculation(dataframe):\n",
    "    '''\n",
    "    The metric calculations as done in https://github.com/irlabamsterdam/TPDLTextRedaction/blob/main/notebooks/Experiments.ipynb\n",
    "    @param  pd.DataFrame    The dataframe for one class with the following columns { IOU, TP, FN, FP }\n",
    "                            where the IOU is the sum of IOU scores and the others a total count.\n",
    "    @return dict            The metric scores for this class\n",
    "    '''\n",
    "    \n",
    "    SQ = dataframe['IOU'].sum() / dataframe['TP'].sum() if dataframe['TP'].sum() > 0 else 0\n",
    "    RQ = dataframe['TP'].sum() / (dataframe['TP'].sum() + 0.5*dataframe['FN'].sum() + 0.5*dataframe['FP'].sum())\n",
    "    PQ = SQ*RQ\n",
    "    P = dataframe['TP'].sum() / (dataframe['TP'].sum() + dataframe['FP'].sum()) if (dataframe['TP'].sum() + dataframe['FP'].sum()) > 0 else 0\n",
    "    R = dataframe['TP'].sum() / (dataframe['TP'].sum() + dataframe['FN'].sum()) if (dataframe['TP'].sum() + dataframe['FN'].sum()) > 0 else 0\n",
    "    \n",
    "    return { 'PQ': round(PQ, 2), 'SQ': round(SQ, 2), 'RQ': round(RQ, 2), 'P': round(P, 2), 'R': round(R, 2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3132f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the overlap between predicted masks\n",
    "# this should also speed up the calculation of the overall PQ score\n",
    "def remove_box_overlap(predicted_masks, scores, score_t: float=0.5, iou_t: float= 0.5):\n",
    "    '''\n",
    "    Remove the overlap between predicted masks\n",
    "    @param  list    The predicted masks\n",
    "    @param  list    The confidence scores of the predicted masks\n",
    "    @param  float   The prediction confidence score threshold\n",
    "    @param  float   The interval-over-intersection threshold to consider\n",
    "                    an annotated region and predicted region a true positive\n",
    "    @return\n",
    "    '''\n",
    "    \n",
    "    # Filter out boxes with a low confidence score\n",
    "    filtered_masks = [predicted_masks[i].numpy() for i in range(len(predicted_masks)) if scores[i] > score_t]\n",
    "    filtered_scores = [scores[i] for i in range(len(scores)) if scores[i] > score_t]\n",
    "    \n",
    "    # Sort boxes based on their confidence scores\n",
    "    sorted_masks = np.array(filtered_masks)[np.argsort(filtered_scores)]\n",
    "    \n",
    "    # The list was sorted from worst to best score so we have to reverse the list\n",
    "    sorted_masks = sorted_masks[::-1]\n",
    "    \n",
    "    # after the first step, we have to remove overlaps by looping through and calculating iou\n",
    "    if not len(sorted_masks):\n",
    "        return None\n",
    "    \n",
    "    # By definition we always include the first mask in the output\n",
    "    output_masks = [sorted_masks[0]]\n",
    "    mask_overlap = np.copy(sorted_masks[0])\n",
    "    \n",
    "    # evaluate all masks\n",
    "    for i in range(1, len(sorted_masks)):\n",
    "        \n",
    "        # get the mask and copy it to make sure we don't overwrite it\n",
    "        mask = np.copy(sorted_masks[i])\n",
    "        \n",
    "        # get the mask size\n",
    "        mask_size = (mask > 0).sum()\n",
    "        \n",
    "        # check if the current mask has any overlap with previously evaluated masks\n",
    "        only_mask = np.logical_and((mask == 1), (mask_overlap == 0))\n",
    "        \n",
    "        # only keep masks that do not overlap for more\n",
    "        # than the given IoU threshold with the previous masks\n",
    "        if (only_mask.sum() / mask_size) > iou_t:\n",
    "            output_masks.append(np.copy(only_mask))\n",
    "            mask_overlap += only_mask\n",
    "            mask_overlap = mask_overlap > 0\n",
    "            \n",
    "    # only return the masks if we have them\n",
    "    if len(output_masks): return np.stack(output_masks)\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb11c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PQ_score(ground_truth, prediction):\n",
    "    '''\n",
    "    Get the values that are needed to calculate the PQ-score\n",
    "    @param  np.array    The ground truth masks\n",
    "    @param  np.array    The predicted masks\n",
    "    @return dict        The values needed for the PQ-score (TP, FP, FN, IOU)\n",
    "    '''\n",
    "    \n",
    "    # make sure that the prediction\n",
    "    # is always numpy array by default\n",
    "    if prediction is None: prediction = np.array([])\n",
    "        \n",
    "    # get the initial values\n",
    "    TP = []\n",
    "    IOU = []\n",
    "    \n",
    "    # get the indices of the ground truth and prediction masks\n",
    "    gt_indices = list(range(ground_truth.shape[0]))\n",
    "    pred_indices = list(range(prediction.shape[0]))\n",
    "\n",
    "    # iterate over the ground truth and prediction \n",
    "    # masks to calculate the iou between all combinations\n",
    "    for i in range(ground_truth.shape[0]):\n",
    "        for j in range(prediction.shape[0]):\n",
    "            \n",
    "            # calculate the iou between this ground truth\n",
    "            # and predicted mask\n",
    "            ground_truth_mask = ground_truth[i, :, :]\n",
    "            predicted_mask = prediction[j, :, :]\n",
    "            union = ((ground_truth_mask + predicted_mask) > 0).sum()\n",
    "            intersection = (predicted_mask * ground_truth_mask).sum()\n",
    "            iou = intersection / union\n",
    "            \n",
    "            # add this combination of masks as a true positive if\n",
    "            # the iou exceeds the threshold and keep track of the\n",
    "            # iou score for the segmentation quality metric\n",
    "            if iou > 0.5:\n",
    "                TP.append((i, j))\n",
    "                IOU.append(iou)\n",
    "                    \n",
    "    # every unused predicted mask is a false positive\n",
    "    FP = set(pred_indices)-set([item[1] for item in TP])\n",
    "    \n",
    "    # every unused ground truth maks is a false negative\n",
    "    FN = set(gt_indices)-set([item[0] for item in TP])\n",
    "    \n",
    "    # return the values needed for the panoptic quality metric\n",
    "    return {'TP': len(TP), 'FP': len(FP), 'FN': len(FN), 'IOU': sum(IOU)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6073ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_panoptic_evaluation_values(image_path, score_t: float=0.5, iou_t: float= 0.5):\n",
    "    '''\n",
    "    Function to evaluate how well the detection is for an image\n",
    "    @param  string  The path to the image\n",
    "    @param  float   The prediction confidence score threshold\n",
    "    @param  float   The interval-over-intersection threshold to consider\n",
    "                    an annotated region and predicted region a true positive\n",
    "    @return dict    The dict with the evaluation scores:\n",
    "                        - iou:float  The sum of the intersection over union values of all true positive regions\n",
    "                        - tp:int     The number of true positives\n",
    "                        - fp:int     The number of false positives\n",
    "                        - fn:int     The number of false negatives\n",
    "    '''\n",
    "    \n",
    "    # get the golden standard masks for the image\n",
    "    im = cv2.imread(image_path)\n",
    "    g_masks = create_gold_standard_masks(image_path)\n",
    "    \n",
    "    # get the filename from the path\n",
    "    filename = os.path.split(image_path)[-1]\n",
    "    \n",
    "    # get the label\n",
    "    label = data_csv[data_csv['File'] == filename].type.item()\n",
    "    \n",
    "    # get the prediction masks for the image\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    p_masks = outputs['instances'].pred_masks.cpu()\n",
    "    scores = outputs['instances'].scores.cpu()\n",
    "    \n",
    "    # filter the prediction masks by removing the overlap between them\n",
    "    filtered_p_masks = remove_box_overlap(p_masks, scores, score_t, iou_t)\n",
    "    \n",
    "    # get the PQ score\n",
    "    pq = get_PQ_score(np.array(g_masks), filtered_p_masks)\n",
    "    \n",
    "    # add the redacted area of the predictions\n",
    "    # and the total size of the image \n",
    "    pq['area'] = np.sum(filtered_p_masks)\n",
    "    w, h, _ = im.shape\n",
    "    pq['size'] = w*h\n",
    "    \n",
    "    # add the label to the score\n",
    "    pq['Label'] = label\n",
    "    \n",
    "    #return the pq score\n",
    "    return pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a4862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataframe(dataset: list, score_t: float=0.5, iou_t: float= 0.5):\n",
    "    '''\n",
    "    Function to get the panoptic quality\n",
    "    @param  list    A dataset in the DatasetCatalog format \n",
    "    @param  float   The prediction confidence score threshold\n",
    "    @param  float   The interval-over-intersection threshold to consider\n",
    "                    an annotated region and predicted region a true positive\n",
    "    '''\n",
    "    \n",
    "    # create a dataframe to store the panoptic quality values in\n",
    "    values = {}\n",
    "    \n",
    "    # iterate over the samples\n",
    "    for sample in tqdm(dataset):\n",
    "        \n",
    "        # get the values for the panoptic quality evaluation for this sample\n",
    "        values[sample['file_name']] = extract_panoptic_evaluation_values(sample['file_name'], score_t, iou_t)\n",
    "\n",
    "    # return put all values in a dataframe \n",
    "    # with the file_name as the index\n",
    "    return pd.DataFrame(values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eef6b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "439it [00:31, 13.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the validation dicts\n",
    "test_dir = os.path.join(datasets_dir, 'test_extended')\n",
    "test_dicts = get_redacted_dicts(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d228cb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/439 [00:00<?, ?it/s]C:\\Users\\kdmei\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|| 439/439 [53:30<00:00,  7.31s/it]  \n"
     ]
    }
   ],
   "source": [
    "# get the dataframe with the evaluation scores\n",
    "test_df = evaluate_dataframe(test_dicts, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806c3a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "test_df.to_csv(os.path.join('results', 'maskrcnn_extended_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "849c8cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PQ</th>\n",
       "      <th>SQ</th>\n",
       "      <th>RQ</th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>border</th>\n",
       "      <td>0.77</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gray</th>\n",
       "      <td>0.74</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PQ    SQ    RQ     P     R\n",
       "black   0.78  0.82  0.94  0.95  0.93\n",
       "border  0.77  0.84  0.92  0.96  0.88\n",
       "color   0.81  0.84  0.96  0.97  0.95\n",
       "gray    0.74  0.82  0.90  0.93  0.87\n",
       "total   0.75  0.83  0.90  0.90  0.91"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculates the panoptic quality metrics\n",
    "results = {}\n",
    "for label, label_df in test_df.groupby('Label'):\n",
    "    \n",
    "    # no_annotation has not true positives, so \n",
    "    # all metrics will be 0\n",
    "    if label == 'no_annotation': continue\n",
    "    \n",
    "    results[label] = metric_calculation(label_df)\n",
    "    \n",
    "# also add the PQ score of the complete dataset\n",
    "results['total'] = metric_calculation(test_df)\n",
    "    \n",
    "# show the metrics in a pandas dataframe\n",
    "pd.DataFrame.from_dict(results).T[['PQ', 'SQ', 'RQ', 'P', 'R']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46bce700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "# total number of pages without annotations and the sum of false positives\n",
    "print(len(test_df[test_df['Label'] == 'no_annotation']))\n",
    "print(test_df[test_df['Label'] == 'no_annotation']['FP'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a1f842",
   "metadata": {},
   "source": [
    "# Time the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22b7d1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 16:05:56 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from output_extended\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "# the test dir\n",
    "test_dir = os.path.join(datasets_dir, 'test_extended')\n",
    "\n",
    "# load the trained model\n",
    "# !NOTE!: Make sure that the cfg is loaded in a previous cell\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold (in this case the same as the training threshold)\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9aca1409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_algorithm(input_image_path):\n",
    "    '''\n",
    "    Time the image loading and model prediction\n",
    "    @param  string    The path to the image\n",
    "    @return dict      The times of the individual parts and total time\n",
    "    '''\n",
    "    \n",
    "    # time the image loading\n",
    "    load_start = time.time()\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    load_end = time.time()\n",
    "    \n",
    "    # time the prediction\n",
    "    predict_start = time.time()\n",
    "    outputs = predictor(input_image)\n",
    "    predict_end = time.time()\n",
    "    \n",
    "    # add the separate time differences\n",
    "    times = {\n",
    "        'loading': load_end-load_start,\n",
    "        'predicting': predict_end-predict_start\n",
    "    }\n",
    "    \n",
    "    # add the total time (sum of the individual parts)\n",
    "    times['total'] = sum(times.values())\n",
    "    \n",
    "    # return the times\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08551e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 439/439 [02:13<00:00,  3.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# do this over all the images and average\n",
    "load_times = []\n",
    "predicting_times = []\n",
    "total_times = []\n",
    "\n",
    "# time the model for all test images\n",
    "for filename in tqdm(os.listdir(test_dir)):\n",
    "    image_path = os.path.join(test_dir, filename)\n",
    "    times = time_algorithm(image_path)\n",
    "    load_times.append(times['loading'])\n",
    "    predicting_times.append(times['predicting'])\n",
    "    total_times.append(times['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2afea7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loading time is 0.070 seconds\n",
      "Average predicting time is 0.231 seconds\n",
      "Average total time is 0.301 seconds\n"
     ]
    }
   ],
   "source": [
    "# print the average times\n",
    "print(\"Average loading time is %.3f seconds\" % np.mean(load_times))\n",
    "print(\"Average predicting time is %.3f seconds\" % np.mean(predicting_times))\n",
    "print(\"Average total time is %.3f seconds\" % np.mean(total_times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
