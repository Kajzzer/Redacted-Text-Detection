{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc24cae7",
   "metadata": {},
   "source": [
    "# All imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa11faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common libraries\n",
    "import os, json, cv2, random, shutil, time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a42e96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmei\\anaconda3\\envs\\master\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.structures import BoxMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96938172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables and constants\n",
    "datasets_dir = os.path.join('..', 'datasets')\n",
    "json_file = os.path.join('..', 'datasets', 'gold_standard_complete.json')\n",
    "with open(json_file) as f: data_json = json.load(f)\n",
    "TRAIN_SPLIT = 0.7\n",
    "RNG_SEED = 117"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be50719",
   "metadata": {},
   "source": [
    "# Load in our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbd7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the functions to create the train and test split\n",
    "%run Data-split-functions.ipynb\n",
    "\n",
    "# create the data, set force_new_split to false so that we can skip \n",
    "# this phase if it has been done before and \n",
    "# extended to false to skip the 'no_annotation' pages\n",
    "split_data(TRAIN_SPLIT, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47196e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_redacted_dicts(img_dir):\n",
    "    '''\n",
    "    Get the annotations of the images in the provided directory in the format DatasetCatalog expects\n",
    "    @param  string    The name of the \n",
    "    @return list      The annotations of the files in DatasetCatalog format. Every record has the following properties:\n",
    "                          - filename:string      The name of the image\n",
    "                          - image_id:int         The id of the image\n",
    "                          - height:int           The height of the image\n",
    "                          - width:int            The width of the image\n",
    "                          - bbox_mode:string     The mode for the bounding box (BoxMode.XYWH_ABS or BoxMode.XYXY_ABS)\n",
    "                          - bbox:list            The values for the bounding box depending on the bbox_mode\n",
    "                          - semgentation:list    The separate semgentations that belong to the same instance\n",
    "                          - category_id:int      The id of the class the instance belongs to\n",
    "    '''\n",
    "\n",
    "    # initial list of segments for this image\n",
    "    dataset_dicts = []\n",
    "    \n",
    "    # iterate over all files/images in the porvided directory\n",
    "    for idx, filename in tqdm(enumerate(os.listdir(img_dir))):\n",
    "        \n",
    "        # the initial record for this file\n",
    "        record = {}\n",
    "        \n",
    "        # get the image\n",
    "        img_path = os.path.join(img_dir, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # skip this image if we can't load the file\n",
    "        if image is None: continue\n",
    "            \n",
    "        # get the height and width of the image\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        # keep track of some image properties\n",
    "        record[\"file_name\"] = img_path\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        \n",
    "        # skip this file if we don't have annotations for it\n",
    "        if not filename in data_json: continue\n",
    "\n",
    "        # get all polygons of this file\n",
    "        polygons = [region['shape_attributes'] for region in data_json[filename]['regions']]\n",
    "        \n",
    "        # initial annotation of this file\n",
    "        annotations = []\n",
    "        \n",
    "        # iterate over all polygons of this file\n",
    "        for polygon in polygons:\n",
    "            \n",
    "            # handle rectangle polygons\n",
    "            if polygon['name'] == 'rect':\n",
    "                \n",
    "                # create the values needed for the rectangular polygon\n",
    "                # the values that the segmentation propery expect is:\n",
    "                # [x1, y1, x2, y2, ..., xn, yn]\n",
    "                segment = [polygon['x'], polygon['y']]\n",
    "                segment = segment + [polygon['x'] + polygon['width'], polygon['y']]\n",
    "                segment = segment + [polygon['x'] + polygon['width'], polygon['y'] + polygon['height']]\n",
    "                segment = segment + [polygon['x'], polygon['y'] + polygon['height']]\n",
    "\n",
    "                # create a bounding box for this segment\n",
    "                bbox = [polygon['x'], polygon['y'], polygon['width'], polygon['height']]\n",
    "                bbox_mode = BoxMode.XYWH_ABS\n",
    "                \n",
    "            # handle generic polygons\n",
    "            elif polygon['name'] == 'polygon':\n",
    "                \n",
    "                # create the segmentation from all x and y values of the polygon\n",
    "                # the values that the segmentation propery expect is:\n",
    "                # [x1, y1, x2, y2, ..., xn, yn]\n",
    "                px = polygon[\"all_points_x\"]\n",
    "                py = polygon[\"all_points_y\"]\n",
    "                segment = [(x + 0.5, y + 0.5) for x, y in zip(px, py)]\n",
    "                segment = [p for x in segment for p in x]\n",
    "                \n",
    "                # create the bounding box for this segment\n",
    "                bbox = [np.min(px), np.min(py), np.max(px), np.max(py)]\n",
    "                bbox_mode = BoxMode.XYXY_ABS\n",
    "            \n",
    "            # skip unknown polygon types\n",
    "            else: continue\n",
    "            \n",
    "            # add the semgent specification \n",
    "            annotations.append({\n",
    "                \"bbox\": bbox,\n",
    "                \"bbox_mode\": bbox_mode,\n",
    "                \"segmentation\": [segment],\n",
    "                \"category_id\": 0,\n",
    "            })\n",
    "            \n",
    "        # add the annotations to the record\n",
    "        record[\"annotations\"] = annotations\n",
    "        \n",
    "        # add the record to the dataset\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52ee05c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataset catalog and metadata for the train data\n",
    "DatasetCatalog.register('redacted_train', lambda x='train':get_redacted_dicts(os.path.join(datasets_dir, x)))\n",
    "metadata = MetadataCatalog.get('redacted_train').set(thing_classes=[\"redacted\"])\n",
    "metadata.set(thing_dataset_id_to_contiguous_id = {'0' : 'redacted'})\n",
    "metadata.set(stuff_dataset_id_to_contiguous_id = {})\n",
    "redacted_metadata = MetadataCatalog.get('redacted_train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6b5ee",
   "metadata": {},
   "source": [
    "# Create the config for the model\n",
    "This is a reference to the default config with all available options: https://detectron2.readthedocs.io/en/latest/modules/config.html#yaml-config-references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6c1e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial config for the detectron2 model\n",
    "cfg = get_cfg() # the default config\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")) # the config of the coco dataset\n",
    "cfg.SEED = RNG_SEED \n",
    "\n",
    "# data config\n",
    "cfg.DATASETS.TRAIN = (\"redacted_train\",)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2 # this will alter the speed of the training, my gpu could only handle 2\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False # we also want the model to train on documents without redactions\n",
    "cfg.INPUT.RANDOM_FLIP = \"none\" # we don't add any random flips as data augmentation\n",
    "\n",
    "# model config\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")  # initial weights from model zoo\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # The \"RoIHead batch size\". The default is 512, but a smaller size is faster\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class* ('redacted')\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5 # inference score threshold \n",
    "# *NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n",
    "\n",
    "# create the output dir\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd1c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver config that we need to use a gridsearch on\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.001  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 5000    \n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac95de1",
   "metadata": {},
   "source": [
    "# Train the model with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04109f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 08:36:25 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "664it [00:42, 15.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 08:37:08 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n",
      "\u001b[36m|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  redacted  | 7765         |\n",
      "|            |              |\u001b[0m\n",
      "\u001b[32m[01/23 08:37:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/23 08:37:08 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/23 08:37:08 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[01/23 08:37:08 d2.data.common]: \u001b[0mSerializing 664 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/23 08:37:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n",
      "\u001b[32m[01/23 08:37:08 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x/139653917/model_final_2d9806.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (2, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (2,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (1, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (1,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 08:37:09 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kdmei\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 08:37:36 d2.utils.events]: \u001b[0m eta: 1:31:41  iter: 19  total_loss: 5.029  loss_cls: 0.5129  loss_box_reg: 0.275  loss_mask: 0.6933  loss_rpn_cls: 3.111  loss_rpn_loc: 0.2997    time: 1.0790  last_time: 1.1500  data_time: 0.1956  last_data_time: 0.0014   lr: 1.9981e-05  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:38:01 d2.utils.events]: \u001b[0m eta: 1:26:09  iter: 39  total_loss: 1.916  loss_cls: 0.4652  loss_box_reg: 0.3814  loss_mask: 0.6051  loss_rpn_cls: 0.2667  loss_rpn_loc: 0.1898    time: 1.0434  last_time: 0.9599  data_time: 0.0014  last_data_time: 0.0014   lr: 3.9961e-05  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:38:21 d2.utils.events]: \u001b[0m eta: 1:25:19  iter: 59  total_loss: 1.78  loss_cls: 0.362  loss_box_reg: 0.3742  loss_mask: 0.4648  loss_rpn_cls: 0.1986  loss_rpn_loc: 0.1823    time: 1.0271  last_time: 0.8165  data_time: 0.0013  last_data_time: 0.0014   lr: 5.9941e-05  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:38:42 d2.utils.events]: \u001b[0m eta: 1:24:06  iter: 79  total_loss: 1.707  loss_cls: 0.4017  loss_box_reg: 0.6147  loss_mask: 0.3516  loss_rpn_cls: 0.1054  loss_rpn_loc: 0.2401    time: 1.0266  last_time: 1.0580  data_time: 0.0014  last_data_time: 0.0014   lr: 7.9921e-05  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:39:01 d2.utils.events]: \u001b[0m eta: 1:23:33  iter: 99  total_loss: 1.382  loss_cls: 0.3063  loss_box_reg: 0.5303  loss_mask: 0.3013  loss_rpn_cls: 0.04829  loss_rpn_loc: 0.1689    time: 1.0160  last_time: 0.8925  data_time: 0.0013  last_data_time: 0.0010   lr: 9.9901e-05  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:39:22 d2.utils.events]: \u001b[0m eta: 1:23:22  iter: 119  total_loss: 1.466  loss_cls: 0.2767  loss_box_reg: 0.4847  loss_mask: 0.2865  loss_rpn_cls: 0.08192  loss_rpn_loc: 0.2264    time: 1.0175  last_time: 0.8897  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00011988  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:39:41 d2.utils.events]: \u001b[0m eta: 1:22:47  iter: 139  total_loss: 1.126  loss_cls: 0.229  loss_box_reg: 0.4425  loss_mask: 0.2433  loss_rpn_cls: 0.05592  loss_rpn_loc: 0.1127    time: 1.0121  last_time: 0.9003  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00013986  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:40:02 d2.utils.events]: \u001b[0m eta: 1:23:12  iter: 159  total_loss: 1.214  loss_cls: 0.2167  loss_box_reg: 0.51  loss_mask: 0.231  loss_rpn_cls: 0.05444  loss_rpn_loc: 0.1532    time: 1.0171  last_time: 1.0008  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00015984  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:40:23 d2.utils.events]: \u001b[0m eta: 1:22:24  iter: 179  total_loss: 1.203  loss_cls: 0.2137  loss_box_reg: 0.5267  loss_mask: 0.2212  loss_rpn_cls: 0.03609  loss_rpn_loc: 0.1492    time: 1.0170  last_time: 0.9888  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00017982  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:40:44 d2.utils.events]: \u001b[0m eta: 1:22:39  iter: 199  total_loss: 1.037  loss_cls: 0.1861  loss_box_reg: 0.4812  loss_mask: 0.1937  loss_rpn_cls: 0.04562  loss_rpn_loc: 0.1571    time: 1.0201  last_time: 0.8354  data_time: 0.0013  last_data_time: 0.0013   lr: 0.0001998  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:41:05 d2.utils.events]: \u001b[0m eta: 1:22:29  iter: 219  total_loss: 0.9197  loss_cls: 0.1693  loss_box_reg: 0.3769  loss_mask: 0.1779  loss_rpn_cls: 0.04241  loss_rpn_loc: 0.1251    time: 1.0236  last_time: 0.9690  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00021978  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:41:26 d2.utils.events]: \u001b[0m eta: 1:22:17  iter: 239  total_loss: 0.8538  loss_cls: 0.1562  loss_box_reg: 0.3485  loss_mask: 0.1811  loss_rpn_cls: 0.02958  loss_rpn_loc: 0.1367    time: 1.0244  last_time: 1.1235  data_time: 0.0014  last_data_time: 0.0013   lr: 0.00023976  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:41:46 d2.utils.events]: \u001b[0m eta: 1:21:56  iter: 259  total_loss: 0.8712  loss_cls: 0.1697  loss_box_reg: 0.3162  loss_mask: 0.1913  loss_rpn_cls: 0.03778  loss_rpn_loc: 0.1435    time: 1.0238  last_time: 1.0520  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00025974  max_mem: 5533M\n",
      "\u001b[32m[01/23 08:42:06 d2.utils.events]: \u001b[0m eta: 1:21:35  iter: 279  total_loss: 0.8286  loss_cls: 0.1393  loss_box_reg: 0.3118  loss_mask: 0.1592  loss_rpn_cls: 0.03616  loss_rpn_loc: 0.1349    time: 1.0230  last_time: 0.7704  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00027972  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:42:26 d2.utils.events]: \u001b[0m eta: 1:20:58  iter: 299  total_loss: 0.748  loss_cls: 0.1352  loss_box_reg: 0.2868  loss_mask: 0.1731  loss_rpn_cls: 0.02749  loss_rpn_loc: 0.141    time: 1.0195  last_time: 1.1504  data_time: 0.0013  last_data_time: 0.0013   lr: 0.0002997  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:42:45 d2.utils.events]: \u001b[0m eta: 1:20:31  iter: 319  total_loss: 0.7242  loss_cls: 0.1195  loss_box_reg: 0.2669  loss_mask: 0.1606  loss_rpn_cls: 0.0245  loss_rpn_loc: 0.121    time: 1.0171  last_time: 0.8845  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00031968  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:43:05 d2.utils.events]: \u001b[0m eta: 1:20:08  iter: 339  total_loss: 0.6706  loss_cls: 0.1225  loss_box_reg: 0.2692  loss_mask: 0.1565  loss_rpn_cls: 0.03614  loss_rpn_loc: 0.1171    time: 1.0156  last_time: 0.8953  data_time: 0.0013  last_data_time: 0.0015   lr: 0.00033966  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:43:25 d2.utils.events]: \u001b[0m eta: 1:19:46  iter: 359  total_loss: 0.6917  loss_cls: 0.1221  loss_box_reg: 0.2454  loss_mask: 0.1636  loss_rpn_cls: 0.03141  loss_rpn_loc: 0.1195    time: 1.0141  last_time: 1.1301  data_time: 0.0012  last_data_time: 0.0012   lr: 0.00035964  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:43:46 d2.utils.events]: \u001b[0m eta: 1:19:27  iter: 379  total_loss: 0.5354  loss_cls: 0.09341  loss_box_reg: 0.177  loss_mask: 0.1403  loss_rpn_cls: 0.01633  loss_rpn_loc: 0.08992    time: 1.0165  last_time: 1.1503  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00037962  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:44:06 d2.utils.events]: \u001b[0m eta: 1:19:07  iter: 399  total_loss: 0.7079  loss_cls: 0.1349  loss_box_reg: 0.2891  loss_mask: 0.1594  loss_rpn_cls: 0.01711  loss_rpn_loc: 0.1153    time: 1.0165  last_time: 1.0248  data_time: 0.0013  last_data_time: 0.0013   lr: 0.0003996  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:44:26 d2.utils.events]: \u001b[0m eta: 1:18:45  iter: 419  total_loss: 0.7502  loss_cls: 0.1351  loss_box_reg: 0.2855  loss_mask: 0.1551  loss_rpn_cls: 0.02663  loss_rpn_loc: 0.1116    time: 1.0158  last_time: 0.9939  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00041958  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:44:47 d2.utils.events]: \u001b[0m eta: 1:18:23  iter: 439  total_loss: 0.7712  loss_cls: 0.1556  loss_box_reg: 0.2943  loss_mask: 0.1558  loss_rpn_cls: 0.02067  loss_rpn_loc: 0.1438    time: 1.0156  last_time: 0.8107  data_time: 0.0061  last_data_time: 0.0015   lr: 0.00043956  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:45:07 d2.utils.events]: \u001b[0m eta: 1:18:02  iter: 459  total_loss: 0.6826  loss_cls: 0.1336  loss_box_reg: 0.2452  loss_mask: 0.1691  loss_rpn_cls: 0.02288  loss_rpn_loc: 0.1297    time: 1.0150  last_time: 0.8020  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00045954  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:45:27 d2.utils.events]: \u001b[0m eta: 1:17:43  iter: 479  total_loss: 0.7073  loss_cls: 0.11  loss_box_reg: 0.2341  loss_mask: 0.1346  loss_rpn_cls: 0.02538  loss_rpn_loc: 0.147    time: 1.0157  last_time: 0.9731  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00047952  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:45:47 d2.utils.events]: \u001b[0m eta: 1:17:09  iter: 499  total_loss: 0.669  loss_cls: 0.1457  loss_box_reg: 0.234  loss_mask: 0.1562  loss_rpn_cls: 0.01309  loss_rpn_loc: 0.1073    time: 1.0139  last_time: 1.0466  data_time: 0.0013  last_data_time: 0.0015   lr: 0.0004995  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:46:07 d2.utils.events]: \u001b[0m eta: 1:16:35  iter: 519  total_loss: 0.6791  loss_cls: 0.1285  loss_box_reg: 0.2743  loss_mask: 0.1468  loss_rpn_cls: 0.01116  loss_rpn_loc: 0.1129    time: 1.0131  last_time: 1.1416  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00051948  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:46:27 d2.utils.events]: \u001b[0m eta: 1:16:14  iter: 539  total_loss: 0.5958  loss_cls: 0.1207  loss_box_reg: 0.2143  loss_mask: 0.1425  loss_rpn_cls: 0.02414  loss_rpn_loc: 0.1127    time: 1.0126  last_time: 0.8348  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00053946  max_mem: 5731M\n",
      "\u001b[32m[01/23 08:46:47 d2.utils.events]: \u001b[0m eta: 1:16:04  iter: 559  total_loss: 0.5906  loss_cls: 0.134  loss_box_reg: 0.1927  loss_mask: 0.1331  loss_rpn_cls: 0.02966  loss_rpn_loc: 0.09404    time: 1.0136  last_time: 1.1429  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00055944  max_mem: 5732M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 08:47:08 d2.utils.events]: \u001b[0m eta: 1:15:58  iter: 579  total_loss: 0.6715  loss_cls: 0.1313  loss_box_reg: 0.2485  loss_mask: 0.1526  loss_rpn_cls: 0.01876  loss_rpn_loc: 0.1308    time: 1.0143  last_time: 1.0925  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00057942  max_mem: 5732M\n",
      "\u001b[32m[01/23 08:47:28 d2.utils.events]: \u001b[0m eta: 1:15:23  iter: 599  total_loss: 0.6235  loss_cls: 0.1098  loss_box_reg: 0.2335  loss_mask: 0.1498  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.09375    time: 1.0132  last_time: 0.9529  data_time: 0.0013  last_data_time: 0.0012   lr: 0.0005994  max_mem: 5732M\n",
      "\u001b[32m[01/23 08:47:49 d2.utils.events]: \u001b[0m eta: 1:15:18  iter: 619  total_loss: 0.6943  loss_cls: 0.136  loss_box_reg: 0.2749  loss_mask: 0.1446  loss_rpn_cls: 0.01926  loss_rpn_loc: 0.1332    time: 1.0148  last_time: 1.1614  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00061938  max_mem: 5732M\n",
      "\u001b[32m[01/23 08:48:09 d2.utils.events]: \u001b[0m eta: 1:14:51  iter: 639  total_loss: 0.5827  loss_cls: 0.1043  loss_box_reg: 0.2113  loss_mask: 0.1273  loss_rpn_cls: 0.01469  loss_rpn_loc: 0.09867    time: 1.0145  last_time: 0.9927  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00063936  max_mem: 5732M\n",
      "\u001b[32m[01/23 08:48:30 d2.utils.events]: \u001b[0m eta: 1:14:35  iter: 659  total_loss: 0.646  loss_cls: 0.113  loss_box_reg: 0.2402  loss_mask: 0.149  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.1122    time: 1.0149  last_time: 1.0639  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00065934  max_mem: 5937M\n",
      "\u001b[32m[01/23 08:48:50 d2.utils.events]: \u001b[0m eta: 1:14:15  iter: 679  total_loss: 0.5057  loss_cls: 0.09977  loss_box_reg: 0.1779  loss_mask: 0.1382  loss_rpn_cls: 0.01681  loss_rpn_loc: 0.09537    time: 1.0151  last_time: 1.0222  data_time: 0.0014  last_data_time: 0.0014   lr: 0.00067932  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:49:11 d2.utils.events]: \u001b[0m eta: 1:13:55  iter: 699  total_loss: 0.621  loss_cls: 0.1134  loss_box_reg: 0.2473  loss_mask: 0.1403  loss_rpn_cls: 0.01754  loss_rpn_loc: 0.09961    time: 1.0152  last_time: 0.9943  data_time: 0.0013  last_data_time: 0.0012   lr: 0.0006993  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:49:31 d2.utils.events]: \u001b[0m eta: 1:13:34  iter: 719  total_loss: 0.6365  loss_cls: 0.1152  loss_box_reg: 0.2261  loss_mask: 0.1482  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.1245    time: 1.0151  last_time: 1.0687  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00071928  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:49:51 d2.utils.events]: \u001b[0m eta: 1:13:15  iter: 739  total_loss: 0.5782  loss_cls: 0.09135  loss_box_reg: 0.207  loss_mask: 0.136  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.09734    time: 1.0156  last_time: 1.0514  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00073926  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:50:11 d2.utils.events]: \u001b[0m eta: 1:12:55  iter: 759  total_loss: 0.5913  loss_cls: 0.1151  loss_box_reg: 0.222  loss_mask: 0.1565  loss_rpn_cls: 0.01798  loss_rpn_loc: 0.1105    time: 1.0152  last_time: 0.7953  data_time: 0.0013  last_data_time: 0.0014   lr: 0.00075924  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:50:33 d2.utils.events]: \u001b[0m eta: 1:12:42  iter: 779  total_loss: 0.5947  loss_cls: 0.08853  loss_box_reg: 0.2095  loss_mask: 0.1207  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.1106    time: 1.0165  last_time: 1.1434  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00077922  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:50:55 d2.utils.events]: \u001b[0m eta: 1:12:26  iter: 799  total_loss: 0.5989  loss_cls: 0.08138  loss_box_reg: 0.2055  loss_mask: 0.1484  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.09793    time: 1.0183  last_time: 0.9804  data_time: 0.0013  last_data_time: 0.0012   lr: 0.0007992  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:51:16 d2.utils.events]: \u001b[0m eta: 1:12:05  iter: 819  total_loss: 0.5145  loss_cls: 0.09266  loss_box_reg: 0.1777  loss_mask: 0.1313  loss_rpn_cls: 0.007765  loss_rpn_loc: 0.08909    time: 1.0191  last_time: 0.9703  data_time: 0.0014  last_data_time: 0.0019   lr: 0.00081918  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:51:36 d2.utils.events]: \u001b[0m eta: 1:11:47  iter: 839  total_loss: 0.5837  loss_cls: 0.1007  loss_box_reg: 0.2289  loss_mask: 0.1275  loss_rpn_cls: 0.01322  loss_rpn_loc: 0.09783    time: 1.0197  last_time: 0.9332  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00083916  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:51:56 d2.utils.events]: \u001b[0m eta: 1:11:26  iter: 859  total_loss: 0.4867  loss_cls: 0.09462  loss_box_reg: 0.2016  loss_mask: 0.136  loss_rpn_cls: 0.01241  loss_rpn_loc: 0.08676    time: 1.0189  last_time: 1.0560  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00085914  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:52:17 d2.utils.events]: \u001b[0m eta: 1:11:08  iter: 879  total_loss: 0.7084  loss_cls: 0.101  loss_box_reg: 0.253  loss_mask: 0.14  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.1161    time: 1.0195  last_time: 1.1574  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00087912  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:52:38 d2.utils.events]: \u001b[0m eta: 1:10:49  iter: 899  total_loss: 0.6643  loss_cls: 0.1168  loss_box_reg: 0.2252  loss_mask: 0.1395  loss_rpn_cls: 0.01212  loss_rpn_loc: 0.1209    time: 1.0202  last_time: 0.9961  data_time: 0.0014  last_data_time: 0.0012   lr: 0.0008991  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:52:58 d2.utils.events]: \u001b[0m eta: 1:10:29  iter: 919  total_loss: 0.6354  loss_cls: 0.08452  loss_box_reg: 0.2224  loss_mask: 0.1447  loss_rpn_cls: 0.01929  loss_rpn_loc: 0.1477    time: 1.0201  last_time: 0.9847  data_time: 0.0014  last_data_time: 0.0012   lr: 0.00091908  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:53:19 d2.utils.events]: \u001b[0m eta: 1:10:08  iter: 939  total_loss: 0.6331  loss_cls: 0.09114  loss_box_reg: 0.2108  loss_mask: 0.1488  loss_rpn_cls: 0.01059  loss_rpn_loc: 0.0977    time: 1.0200  last_time: 0.8311  data_time: 0.0013  last_data_time: 0.0011   lr: 0.00093906  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:53:39 d2.utils.events]: \u001b[0m eta: 1:09:42  iter: 959  total_loss: 0.6504  loss_cls: 0.1047  loss_box_reg: 0.2648  loss_mask: 0.1447  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.137    time: 1.0195  last_time: 1.0043  data_time: 0.0013  last_data_time: 0.0012   lr: 0.00095904  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:53:59 d2.utils.events]: \u001b[0m eta: 1:09:26  iter: 979  total_loss: 0.6178  loss_cls: 0.0933  loss_box_reg: 0.2399  loss_mask: 0.1342  loss_rpn_cls: 0.01028  loss_rpn_loc: 0.1267    time: 1.0199  last_time: 1.1458  data_time: 0.0013  last_data_time: 0.0013   lr: 0.00097902  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:54:20 d2.utils.events]: \u001b[0m eta: 1:09:05  iter: 999  total_loss: 0.4379  loss_cls: 0.06874  loss_box_reg: 0.1665  loss_mask: 0.1247  loss_rpn_cls: 0.005853  loss_rpn_loc: 0.07161    time: 1.0196  last_time: 1.1814  data_time: 0.0013  last_data_time: 0.0012   lr: 0.000999  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:54:40 d2.utils.events]: \u001b[0m eta: 1:08:38  iter: 1019  total_loss: 0.5365  loss_cls: 0.07756  loss_box_reg: 0.198  loss_mask: 0.1202  loss_rpn_cls: 0.007416  loss_rpn_loc: 0.1191    time: 1.0196  last_time: 1.0535  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:55:00 d2.utils.events]: \u001b[0m eta: 1:08:17  iter: 1039  total_loss: 0.5828  loss_cls: 0.08853  loss_box_reg: 0.2175  loss_mask: 0.1435  loss_rpn_cls: 0.01444  loss_rpn_loc: 0.1078    time: 1.0193  last_time: 1.1209  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:55:20 d2.utils.events]: \u001b[0m eta: 1:07:57  iter: 1059  total_loss: 0.5507  loss_cls: 0.08885  loss_box_reg: 0.2215  loss_mask: 0.1507  loss_rpn_cls: 0.005523  loss_rpn_loc: 0.07506    time: 1.0190  last_time: 0.9197  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:55:40 d2.utils.events]: \u001b[0m eta: 1:07:41  iter: 1079  total_loss: 0.6724  loss_cls: 0.0997  loss_box_reg: 0.2463  loss_mask: 0.1505  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.1093    time: 1.0189  last_time: 0.9225  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:56:01 d2.utils.events]: \u001b[0m eta: 1:07:22  iter: 1099  total_loss: 0.4855  loss_cls: 0.07714  loss_box_reg: 0.189  loss_mask: 0.1335  loss_rpn_cls: 0.01126  loss_rpn_loc: 0.07973    time: 1.0191  last_time: 0.9737  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:56:22 d2.utils.events]: \u001b[0m eta: 1:07:04  iter: 1119  total_loss: 0.5143  loss_cls: 0.07846  loss_box_reg: 0.2094  loss_mask: 0.1267  loss_rpn_cls: 0.006937  loss_rpn_loc: 0.08053    time: 1.0198  last_time: 1.0614  data_time: 0.0014  last_data_time: 0.0017   lr: 0.001  max_mem: 5938M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 08:56:42 d2.utils.events]: \u001b[0m eta: 1:06:45  iter: 1139  total_loss: 0.4899  loss_cls: 0.0889  loss_box_reg: 0.1828  loss_mask: 0.1384  loss_rpn_cls: 0.008418  loss_rpn_loc: 0.07131    time: 1.0195  last_time: 1.1685  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:57:03 d2.utils.events]: \u001b[0m eta: 1:06:21  iter: 1159  total_loss: 0.5495  loss_cls: 0.09103  loss_box_reg: 0.1931  loss_mask: 0.1351  loss_rpn_cls: 0.0164  loss_rpn_loc: 0.1192    time: 1.0196  last_time: 0.9917  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:57:23 d2.utils.events]: \u001b[0m eta: 1:06:01  iter: 1179  total_loss: 0.6067  loss_cls: 0.08955  loss_box_reg: 0.2411  loss_mask: 0.1319  loss_rpn_cls: 0.01433  loss_rpn_loc: 0.1109    time: 1.0194  last_time: 1.0354  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:57:43 d2.utils.events]: \u001b[0m eta: 1:05:38  iter: 1199  total_loss: 0.5156  loss_cls: 0.08236  loss_box_reg: 0.1805  loss_mask: 0.1287  loss_rpn_cls: 0.007235  loss_rpn_loc: 0.08888    time: 1.0192  last_time: 0.9271  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:58:03 d2.utils.events]: \u001b[0m eta: 1:05:08  iter: 1219  total_loss: 0.4864  loss_cls: 0.0683  loss_box_reg: 0.176  loss_mask: 0.1229  loss_rpn_cls: 0.007514  loss_rpn_loc: 0.1089    time: 1.0190  last_time: 0.9193  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:58:23 d2.utils.events]: \u001b[0m eta: 1:04:45  iter: 1239  total_loss: 0.4941  loss_cls: 0.08948  loss_box_reg: 0.1938  loss_mask: 0.1367  loss_rpn_cls: 0.006181  loss_rpn_loc: 0.07614    time: 1.0188  last_time: 0.9925  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:58:44 d2.utils.events]: \u001b[0m eta: 1:04:27  iter: 1259  total_loss: 0.5551  loss_cls: 0.09587  loss_box_reg: 0.2085  loss_mask: 0.1341  loss_rpn_cls: 0.01247  loss_rpn_loc: 0.1078    time: 1.0192  last_time: 1.0489  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:59:05 d2.utils.events]: \u001b[0m eta: 1:04:06  iter: 1279  total_loss: 0.6225  loss_cls: 0.08759  loss_box_reg: 0.2516  loss_mask: 0.1377  loss_rpn_cls: 0.008801  loss_rpn_loc: 0.09187    time: 1.0192  last_time: 1.0690  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:59:25 d2.utils.events]: \u001b[0m eta: 1:03:55  iter: 1299  total_loss: 0.6157  loss_cls: 0.09434  loss_box_reg: 0.2284  loss_mask: 0.1439  loss_rpn_cls: 0.01074  loss_rpn_loc: 0.1304    time: 1.0194  last_time: 1.0761  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 08:59:45 d2.utils.events]: \u001b[0m eta: 1:03:35  iter: 1319  total_loss: 0.5111  loss_cls: 0.08344  loss_box_reg: 0.1935  loss_mask: 0.1266  loss_rpn_cls: 0.008865  loss_rpn_loc: 0.07887    time: 1.0189  last_time: 1.0828  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:00:06 d2.utils.events]: \u001b[0m eta: 1:03:14  iter: 1339  total_loss: 0.5208  loss_cls: 0.0805  loss_box_reg: 0.1967  loss_mask: 0.116  loss_rpn_cls: 0.009067  loss_rpn_loc: 0.08815    time: 1.0190  last_time: 0.8356  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:00:26 d2.utils.events]: \u001b[0m eta: 1:02:54  iter: 1359  total_loss: 0.6256  loss_cls: 0.08422  loss_box_reg: 0.2205  loss_mask: 0.1416  loss_rpn_cls: 0.01635  loss_rpn_loc: 0.1297    time: 1.0188  last_time: 1.0610  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:00:46 d2.utils.events]: \u001b[0m eta: 1:02:32  iter: 1379  total_loss: 0.5203  loss_cls: 0.08562  loss_box_reg: 0.1966  loss_mask: 0.1425  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.09946    time: 1.0187  last_time: 0.9756  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:01:06 d2.utils.events]: \u001b[0m eta: 1:02:07  iter: 1399  total_loss: 0.5016  loss_cls: 0.07527  loss_box_reg: 0.191  loss_mask: 0.141  loss_rpn_cls: 0.003926  loss_rpn_loc: 0.08819    time: 1.0186  last_time: 0.9864  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:01:26 d2.utils.events]: \u001b[0m eta: 1:01:51  iter: 1419  total_loss: 0.4437  loss_cls: 0.07704  loss_box_reg: 0.175  loss_mask: 0.1251  loss_rpn_cls: 0.00738  loss_rpn_loc: 0.07862    time: 1.0185  last_time: 1.0695  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:01:47 d2.utils.events]: \u001b[0m eta: 1:01:31  iter: 1439  total_loss: 0.4289  loss_cls: 0.06567  loss_box_reg: 0.1633  loss_mask: 0.1213  loss_rpn_cls: 0.005711  loss_rpn_loc: 0.0767    time: 1.0183  last_time: 1.0500  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:02:07 d2.utils.events]: \u001b[0m eta: 1:01:10  iter: 1459  total_loss: 0.5112  loss_cls: 0.07781  loss_box_reg: 0.1974  loss_mask: 0.1357  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.09275    time: 1.0184  last_time: 0.7989  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:02:27 d2.utils.events]: \u001b[0m eta: 1:00:47  iter: 1479  total_loss: 0.512  loss_cls: 0.0789  loss_box_reg: 0.1791  loss_mask: 0.1442  loss_rpn_cls: 0.01045  loss_rpn_loc: 0.09144    time: 1.0182  last_time: 1.0527  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5938M\n",
      "\u001b[32m[01/23 09:02:48 d2.utils.events]: \u001b[0m eta: 1:00:29  iter: 1499  total_loss: 0.4542  loss_cls: 0.06972  loss_box_reg: 0.1834  loss_mask: 0.1124  loss_rpn_cls: 0.005456  loss_rpn_loc: 0.07548    time: 1.0186  last_time: 1.1530  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:03:08 d2.utils.events]: \u001b[0m eta: 1:00:10  iter: 1519  total_loss: 0.4848  loss_cls: 0.06379  loss_box_reg: 0.191  loss_mask: 0.1206  loss_rpn_cls: 0.007479  loss_rpn_loc: 0.1364    time: 1.0183  last_time: 0.9300  data_time: 0.0014  last_data_time: 0.0018   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:03:28 d2.utils.events]: \u001b[0m eta: 0:59:49  iter: 1539  total_loss: 0.5396  loss_cls: 0.09013  loss_box_reg: 0.2232  loss_mask: 0.1375  loss_rpn_cls: 0.008254  loss_rpn_loc: 0.0974    time: 1.0184  last_time: 1.0755  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:03:50 d2.utils.events]: \u001b[0m eta: 0:59:28  iter: 1559  total_loss: 0.4525  loss_cls: 0.0706  loss_box_reg: 0.1705  loss_mask: 0.1267  loss_rpn_cls: 0.006127  loss_rpn_loc: 0.08092    time: 1.0190  last_time: 1.1465  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:04:11 d2.utils.events]: \u001b[0m eta: 0:59:07  iter: 1579  total_loss: 0.5573  loss_cls: 0.07671  loss_box_reg: 0.211  loss_mask: 0.1249  loss_rpn_cls: 0.006408  loss_rpn_loc: 0.1109    time: 1.0193  last_time: 1.0782  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:04:31 d2.utils.events]: \u001b[0m eta: 0:58:49  iter: 1599  total_loss: 0.5278  loss_cls: 0.06933  loss_box_reg: 0.2003  loss_mask: 0.1485  loss_rpn_cls: 0.009894  loss_rpn_loc: 0.1033    time: 1.0195  last_time: 1.1542  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:04:52 d2.utils.events]: \u001b[0m eta: 0:58:24  iter: 1619  total_loss: 0.5367  loss_cls: 0.08257  loss_box_reg: 0.2153  loss_mask: 0.1288  loss_rpn_cls: 0.013  loss_rpn_loc: 0.0863    time: 1.0193  last_time: 1.0709  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:05:12 d2.utils.events]: \u001b[0m eta: 0:58:08  iter: 1639  total_loss: 0.5626  loss_cls: 0.08168  loss_box_reg: 0.2063  loss_mask: 0.1407  loss_rpn_cls: 0.01168  loss_rpn_loc: 0.1219    time: 1.0195  last_time: 0.8398  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:05:34 d2.utils.events]: \u001b[0m eta: 0:57:51  iter: 1659  total_loss: 0.5933  loss_cls: 0.08609  loss_box_reg: 0.2249  loss_mask: 0.1227  loss_rpn_cls: 0.009574  loss_rpn_loc: 0.1184    time: 1.0201  last_time: 1.1603  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:05:55 d2.utils.events]: \u001b[0m eta: 0:57:43  iter: 1679  total_loss: 0.5167  loss_cls: 0.08933  loss_box_reg: 0.1739  loss_mask: 0.1412  loss_rpn_cls: 0.01225  loss_rpn_loc: 0.1025    time: 1.0204  last_time: 1.1755  data_time: 0.0014  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 09:06:15 d2.utils.events]: \u001b[0m eta: 0:57:26  iter: 1699  total_loss: 0.4145  loss_cls: 0.06122  loss_box_reg: 0.1662  loss_mask: 0.1206  loss_rpn_cls: 0.004448  loss_rpn_loc: 0.06602    time: 1.0206  last_time: 1.1446  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:06:36 d2.utils.events]: \u001b[0m eta: 0:57:07  iter: 1719  total_loss: 0.5221  loss_cls: 0.07126  loss_box_reg: 0.1986  loss_mask: 0.1255  loss_rpn_cls: 0.007276  loss_rpn_loc: 0.09874    time: 1.0206  last_time: 0.9232  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:06:56 d2.utils.events]: \u001b[0m eta: 0:56:41  iter: 1739  total_loss: 0.4802  loss_cls: 0.06875  loss_box_reg: 0.1991  loss_mask: 0.1201  loss_rpn_cls: 0.007559  loss_rpn_loc: 0.07586    time: 1.0206  last_time: 1.0062  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:07:17 d2.utils.events]: \u001b[0m eta: 0:56:26  iter: 1759  total_loss: 0.4746  loss_cls: 0.07908  loss_box_reg: 0.1909  loss_mask: 0.1218  loss_rpn_cls: 0.00769  loss_rpn_loc: 0.07893    time: 1.0211  last_time: 1.1818  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:07:38 d2.utils.events]: \u001b[0m eta: 0:55:59  iter: 1779  total_loss: 0.4673  loss_cls: 0.07473  loss_box_reg: 0.17  loss_mask: 0.1086  loss_rpn_cls: 0.01143  loss_rpn_loc: 0.1024    time: 1.0214  last_time: 1.1770  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:07:58 d2.utils.events]: \u001b[0m eta: 0:55:20  iter: 1799  total_loss: 0.5152  loss_cls: 0.0735  loss_box_reg: 0.1882  loss_mask: 0.1379  loss_rpn_cls: 0.008795  loss_rpn_loc: 0.08228    time: 1.0210  last_time: 1.1685  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:08:20 d2.utils.events]: \u001b[0m eta: 0:55:15  iter: 1819  total_loss: 0.4943  loss_cls: 0.06809  loss_box_reg: 0.1813  loss_mask: 0.1272  loss_rpn_cls: 0.006704  loss_rpn_loc: 0.07997    time: 1.0217  last_time: 1.0653  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:08:40 d2.utils.events]: \u001b[0m eta: 0:54:39  iter: 1839  total_loss: 0.5569  loss_cls: 0.07815  loss_box_reg: 0.2146  loss_mask: 0.1339  loss_rpn_cls: 0.005901  loss_rpn_loc: 0.1121    time: 1.0215  last_time: 1.1466  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:09:00 d2.utils.events]: \u001b[0m eta: 0:54:17  iter: 1859  total_loss: 0.5789  loss_cls: 0.09421  loss_box_reg: 0.2196  loss_mask: 0.138  loss_rpn_cls: 0.008514  loss_rpn_loc: 0.1051    time: 1.0215  last_time: 0.9961  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:09:21 d2.utils.events]: \u001b[0m eta: 0:53:56  iter: 1879  total_loss: 0.4786  loss_cls: 0.06823  loss_box_reg: 0.1869  loss_mask: 0.1268  loss_rpn_cls: 0.004529  loss_rpn_loc: 0.06868    time: 1.0215  last_time: 1.0566  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:09:42 d2.utils.events]: \u001b[0m eta: 0:53:37  iter: 1899  total_loss: 0.4316  loss_cls: 0.05884  loss_box_reg: 0.1694  loss_mask: 0.1236  loss_rpn_cls: 0.007067  loss_rpn_loc: 0.06109    time: 1.0217  last_time: 0.8184  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:10:02 d2.utils.events]: \u001b[0m eta: 0:53:11  iter: 1919  total_loss: 0.4734  loss_cls: 0.05637  loss_box_reg: 0.1883  loss_mask: 0.1344  loss_rpn_cls: 0.006353  loss_rpn_loc: 0.07019    time: 1.0216  last_time: 1.0618  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:10:22 d2.utils.events]: \u001b[0m eta: 0:52:54  iter: 1939  total_loss: 0.5038  loss_cls: 0.07125  loss_box_reg: 0.2114  loss_mask: 0.1335  loss_rpn_cls: 0.006144  loss_rpn_loc: 0.09709    time: 1.0215  last_time: 0.9400  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:10:42 d2.utils.events]: \u001b[0m eta: 0:52:30  iter: 1959  total_loss: 0.4567  loss_cls: 0.06885  loss_box_reg: 0.1939  loss_mask: 0.1328  loss_rpn_cls: 0.005593  loss_rpn_loc: 0.09002    time: 1.0213  last_time: 0.9907  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:11:03 d2.utils.events]: \u001b[0m eta: 0:52:01  iter: 1979  total_loss: 0.5211  loss_cls: 0.07344  loss_box_reg: 0.2117  loss_mask: 0.1368  loss_rpn_cls: 0.008033  loss_rpn_loc: 0.08368    time: 1.0214  last_time: 0.8210  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:11:24 d2.utils.events]: \u001b[0m eta: 0:51:45  iter: 1999  total_loss: 0.6019  loss_cls: 0.08797  loss_box_reg: 0.23  loss_mask: 0.1373  loss_rpn_cls: 0.008735  loss_rpn_loc: 0.08755    time: 1.0216  last_time: 1.1299  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:11:43 d2.utils.events]: \u001b[0m eta: 0:51:20  iter: 2019  total_loss: 0.5177  loss_cls: 0.07304  loss_box_reg: 0.2146  loss_mask: 0.1194  loss_rpn_cls: 0.00627  loss_rpn_loc: 0.1056    time: 1.0213  last_time: 1.1384  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:12:04 d2.utils.events]: \u001b[0m eta: 0:51:10  iter: 2039  total_loss: 0.5552  loss_cls: 0.07953  loss_box_reg: 0.2234  loss_mask: 0.1159  loss_rpn_cls: 0.004873  loss_rpn_loc: 0.1125    time: 1.0216  last_time: 1.0710  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:12:25 d2.utils.events]: \u001b[0m eta: 0:50:38  iter: 2059  total_loss: 0.5188  loss_cls: 0.07782  loss_box_reg: 0.2079  loss_mask: 0.1265  loss_rpn_cls: 0.004631  loss_rpn_loc: 0.08511    time: 1.0214  last_time: 0.9338  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:12:45 d2.utils.events]: \u001b[0m eta: 0:50:18  iter: 2079  total_loss: 0.4674  loss_cls: 0.06659  loss_box_reg: 0.1845  loss_mask: 0.1087  loss_rpn_cls: 0.005842  loss_rpn_loc: 0.08683    time: 1.0215  last_time: 1.1729  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:13:06 d2.utils.events]: \u001b[0m eta: 0:49:54  iter: 2099  total_loss: 0.4453  loss_cls: 0.06533  loss_box_reg: 0.1886  loss_mask: 0.1227  loss_rpn_cls: 0.004438  loss_rpn_loc: 0.07394    time: 1.0216  last_time: 1.1446  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:13:26 d2.utils.events]: \u001b[0m eta: 0:49:00  iter: 2119  total_loss: 0.5269  loss_cls: 0.08293  loss_box_reg: 0.1881  loss_mask: 0.1313  loss_rpn_cls: 0.006116  loss_rpn_loc: 0.114    time: 1.0215  last_time: 1.1751  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:13:46 d2.utils.events]: \u001b[0m eta: 0:48:51  iter: 2139  total_loss: 0.4506  loss_cls: 0.06044  loss_box_reg: 0.1602  loss_mask: 0.1186  loss_rpn_cls: 0.005423  loss_rpn_loc: 0.07593    time: 1.0214  last_time: 1.1671  data_time: 0.0013  last_data_time: 0.0019   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:14:06 d2.utils.events]: \u001b[0m eta: 0:48:31  iter: 2159  total_loss: 0.5221  loss_cls: 0.07079  loss_box_reg: 0.1858  loss_mask: 0.1396  loss_rpn_cls: 0.00716  loss_rpn_loc: 0.09475    time: 1.0213  last_time: 0.9991  data_time: 0.0013  last_data_time: 0.0017   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:14:27 d2.utils.events]: \u001b[0m eta: 0:48:20  iter: 2179  total_loss: 0.512  loss_cls: 0.08447  loss_box_reg: 0.2109  loss_mask: 0.1331  loss_rpn_cls: 0.01393  loss_rpn_loc: 0.1044    time: 1.0214  last_time: 1.0674  data_time: 0.0013  last_data_time: 0.0017   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:14:47 d2.utils.events]: \u001b[0m eta: 0:47:28  iter: 2199  total_loss: 0.5974  loss_cls: 0.0742  loss_box_reg: 0.2217  loss_mask: 0.1437  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.1056    time: 1.0211  last_time: 1.1759  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:15:08 d2.utils.events]: \u001b[0m eta: 0:47:43  iter: 2219  total_loss: 0.4167  loss_cls: 0.05963  loss_box_reg: 0.1756  loss_mask: 0.121  loss_rpn_cls: 0.004905  loss_rpn_loc: 0.06734    time: 1.0213  last_time: 1.0720  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:15:28 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 2239  total_loss: 0.4399  loss_cls: 0.06337  loss_box_reg: 0.1764  loss_mask: 0.1228  loss_rpn_cls: 0.004704  loss_rpn_loc: 0.06808    time: 1.0214  last_time: 0.9933  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 09:15:48 d2.utils.events]: \u001b[0m eta: 0:46:41  iter: 2259  total_loss: 0.5648  loss_cls: 0.07555  loss_box_reg: 0.2236  loss_mask: 0.1407  loss_rpn_cls: 0.007402  loss_rpn_loc: 0.09689    time: 1.0212  last_time: 0.9170  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:16:09 d2.utils.events]: \u001b[0m eta: 0:46:31  iter: 2279  total_loss: 0.4679  loss_cls: 0.06964  loss_box_reg: 0.1861  loss_mask: 0.1221  loss_rpn_cls: 0.003093  loss_rpn_loc: 0.07204    time: 1.0213  last_time: 0.9904  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:16:30 d2.utils.events]: \u001b[0m eta: 0:46:11  iter: 2299  total_loss: 0.4644  loss_cls: 0.06712  loss_box_reg: 0.1936  loss_mask: 0.1235  loss_rpn_cls: 0.005984  loss_rpn_loc: 0.08812    time: 1.0215  last_time: 0.9398  data_time: 0.0014  last_data_time: 0.0010   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:16:51 d2.utils.events]: \u001b[0m eta: 0:45:48  iter: 2319  total_loss: 0.3873  loss_cls: 0.04663  loss_box_reg: 0.1612  loss_mask: 0.1217  loss_rpn_cls: 0.009957  loss_rpn_loc: 0.06539    time: 1.0216  last_time: 1.0140  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:17:11 d2.utils.events]: \u001b[0m eta: 0:45:11  iter: 2339  total_loss: 0.4304  loss_cls: 0.06029  loss_box_reg: 0.1541  loss_mask: 0.1099  loss_rpn_cls: 0.003256  loss_rpn_loc: 0.07873    time: 1.0217  last_time: 0.9880  data_time: 0.0014  last_data_time: 0.0020   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:17:32 d2.utils.events]: \u001b[0m eta: 0:45:19  iter: 2359  total_loss: 0.5245  loss_cls: 0.07556  loss_box_reg: 0.2264  loss_mask: 0.1259  loss_rpn_cls: 0.006854  loss_rpn_loc: 0.09814    time: 1.0220  last_time: 1.1938  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:17:53 d2.utils.events]: \u001b[0m eta: 0:44:53  iter: 2379  total_loss: 0.4347  loss_cls: 0.04997  loss_box_reg: 0.1723  loss_mask: 0.1075  loss_rpn_cls: 0.003211  loss_rpn_loc: 0.07105    time: 1.0221  last_time: 1.3461  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:18:14 d2.utils.events]: \u001b[0m eta: 0:44:57  iter: 2399  total_loss: 0.4445  loss_cls: 0.06382  loss_box_reg: 0.1901  loss_mask: 0.1109  loss_rpn_cls: 0.005943  loss_rpn_loc: 0.07332    time: 1.0222  last_time: 1.1789  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:18:34 d2.utils.events]: \u001b[0m eta: 0:44:30  iter: 2419  total_loss: 0.4511  loss_cls: 0.05904  loss_box_reg: 0.1872  loss_mask: 0.1261  loss_rpn_cls: 0.008458  loss_rpn_loc: 0.07485    time: 1.0220  last_time: 0.9409  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:18:54 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 2439  total_loss: 0.5019  loss_cls: 0.06947  loss_box_reg: 0.1914  loss_mask: 0.1411  loss_rpn_cls: 0.00868  loss_rpn_loc: 0.09058    time: 1.0219  last_time: 1.1569  data_time: 0.0012  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:19:14 d2.utils.events]: \u001b[0m eta: 0:43:16  iter: 2459  total_loss: 0.507  loss_cls: 0.07643  loss_box_reg: 0.2022  loss_mask: 0.126  loss_rpn_cls: 0.005752  loss_rpn_loc: 0.07713    time: 1.0219  last_time: 1.0018  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:19:35 d2.utils.events]: \u001b[0m eta: 0:43:22  iter: 2479  total_loss: 0.5168  loss_cls: 0.06376  loss_box_reg: 0.2001  loss_mask: 0.1327  loss_rpn_cls: 0.005029  loss_rpn_loc: 0.08553    time: 1.0221  last_time: 1.1668  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:19:56 d2.utils.events]: \u001b[0m eta: 0:42:59  iter: 2499  total_loss: 0.4209  loss_cls: 0.05711  loss_box_reg: 0.1673  loss_mask: 0.1327  loss_rpn_cls: 0.006699  loss_rpn_loc: 0.06932    time: 1.0222  last_time: 0.9233  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:20:17 d2.utils.events]: \u001b[0m eta: 0:42:57  iter: 2519  total_loss: 0.5286  loss_cls: 0.07225  loss_box_reg: 0.212  loss_mask: 0.1318  loss_rpn_cls: 0.003993  loss_rpn_loc: 0.08792    time: 1.0224  last_time: 1.1703  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:20:38 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 2539  total_loss: 0.5256  loss_cls: 0.06997  loss_box_reg: 0.2029  loss_mask: 0.1272  loss_rpn_cls: 0.005402  loss_rpn_loc: 0.08937    time: 1.0225  last_time: 1.0683  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:20:58 d2.utils.events]: \u001b[0m eta: 0:42:17  iter: 2559  total_loss: 0.3825  loss_cls: 0.04814  loss_box_reg: 0.1393  loss_mask: 0.114  loss_rpn_cls: 0.004577  loss_rpn_loc: 0.06062    time: 1.0224  last_time: 0.9168  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:21:19 d2.utils.events]: \u001b[0m eta: 0:42:00  iter: 2579  total_loss: 0.556  loss_cls: 0.07706  loss_box_reg: 0.2075  loss_mask: 0.1267  loss_rpn_cls: 0.008309  loss_rpn_loc: 0.1273    time: 1.0227  last_time: 1.0769  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:21:40 d2.utils.events]: \u001b[0m eta: 0:41:43  iter: 2599  total_loss: 0.5322  loss_cls: 0.07077  loss_box_reg: 0.1954  loss_mask: 0.127  loss_rpn_cls: 0.005869  loss_rpn_loc: 0.09964    time: 1.0229  last_time: 0.8003  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:22:01 d2.utils.events]: \u001b[0m eta: 0:41:23  iter: 2619  total_loss: 0.5445  loss_cls: 0.06391  loss_box_reg: 0.2077  loss_mask: 0.1364  loss_rpn_cls: 0.009694  loss_rpn_loc: 0.104    time: 1.0230  last_time: 0.9914  data_time: 0.0014  last_data_time: 0.0008   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:22:21 d2.utils.events]: \u001b[0m eta: 0:41:01  iter: 2639  total_loss: 0.4095  loss_cls: 0.0698  loss_box_reg: 0.1651  loss_mask: 0.1065  loss_rpn_cls: 0.005299  loss_rpn_loc: 0.05848    time: 1.0230  last_time: 1.0569  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:22:42 d2.utils.events]: \u001b[0m eta: 0:40:37  iter: 2659  total_loss: 0.5786  loss_cls: 0.09049  loss_box_reg: 0.2221  loss_mask: 0.142  loss_rpn_cls: 0.005976  loss_rpn_loc: 0.07908    time: 1.0231  last_time: 1.0598  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:23:02 d2.utils.events]: \u001b[0m eta: 0:40:14  iter: 2679  total_loss: 0.5189  loss_cls: 0.07071  loss_box_reg: 0.2117  loss_mask: 0.1214  loss_rpn_cls: 0.006886  loss_rpn_loc: 0.07589    time: 1.0230  last_time: 1.0001  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:23:22 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 2699  total_loss: 0.4781  loss_cls: 0.06485  loss_box_reg: 0.2017  loss_mask: 0.1325  loss_rpn_cls: 0.008037  loss_rpn_loc: 0.08187    time: 1.0227  last_time: 0.9960  data_time: 0.0013  last_data_time: 0.0010   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:23:42 d2.utils.events]: \u001b[0m eta: 0:39:30  iter: 2719  total_loss: 0.5109  loss_cls: 0.06581  loss_box_reg: 0.1874  loss_mask: 0.1264  loss_rpn_cls: 0.005637  loss_rpn_loc: 0.109    time: 1.0226  last_time: 1.1705  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:24:03 d2.utils.events]: \u001b[0m eta: 0:39:09  iter: 2739  total_loss: 0.5229  loss_cls: 0.07062  loss_box_reg: 0.2198  loss_mask: 0.1332  loss_rpn_cls: 0.004095  loss_rpn_loc: 0.07282    time: 1.0227  last_time: 1.0730  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:24:23 d2.utils.events]: \u001b[0m eta: 0:38:49  iter: 2759  total_loss: 0.3879  loss_cls: 0.06151  loss_box_reg: 0.157  loss_mask: 0.1031  loss_rpn_cls: 0.003856  loss_rpn_loc: 0.09446    time: 1.0227  last_time: 1.0384  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:24:44 d2.utils.events]: \u001b[0m eta: 0:38:28  iter: 2779  total_loss: 0.4608  loss_cls: 0.06715  loss_box_reg: 0.2028  loss_mask: 0.1355  loss_rpn_cls: 0.004671  loss_rpn_loc: 0.05982    time: 1.0227  last_time: 0.8461  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:25:05 d2.utils.events]: \u001b[0m eta: 0:38:11  iter: 2799  total_loss: 0.4664  loss_cls: 0.06045  loss_box_reg: 0.1921  loss_mask: 0.112  loss_rpn_cls: 0.00605  loss_rpn_loc: 0.08708    time: 1.0231  last_time: 0.9419  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 09:25:26 d2.utils.events]: \u001b[0m eta: 0:37:47  iter: 2819  total_loss: 0.3745  loss_cls: 0.04876  loss_box_reg: 0.1495  loss_mask: 0.1219  loss_rpn_cls: 0.007273  loss_rpn_loc: 0.0525    time: 1.0232  last_time: 1.0679  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:25:48 d2.utils.events]: \u001b[0m eta: 0:37:35  iter: 2839  total_loss: 0.401  loss_cls: 0.05025  loss_box_reg: 0.1684  loss_mask: 0.1352  loss_rpn_cls: 0.002841  loss_rpn_loc: 0.06498    time: 1.0235  last_time: 0.8539  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:26:08 d2.utils.events]: \u001b[0m eta: 0:37:12  iter: 2859  total_loss: 0.3659  loss_cls: 0.047  loss_box_reg: 0.1507  loss_mask: 0.09837  loss_rpn_cls: 0.005247  loss_rpn_loc: 0.06415    time: 1.0234  last_time: 1.0427  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:26:28 d2.utils.events]: \u001b[0m eta: 0:36:49  iter: 2879  total_loss: 0.552  loss_cls: 0.07267  loss_box_reg: 0.2128  loss_mask: 0.1335  loss_rpn_cls: 0.008578  loss_rpn_loc: 0.1109    time: 1.0235  last_time: 1.0086  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:26:48 d2.utils.events]: \u001b[0m eta: 0:36:22  iter: 2899  total_loss: 0.5786  loss_cls: 0.0732  loss_box_reg: 0.2229  loss_mask: 0.129  loss_rpn_cls: 0.00673  loss_rpn_loc: 0.1132    time: 1.0232  last_time: 1.0204  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:27:09 d2.utils.events]: \u001b[0m eta: 0:36:03  iter: 2919  total_loss: 0.4568  loss_cls: 0.06001  loss_box_reg: 0.1971  loss_mask: 0.1094  loss_rpn_cls: 0.004754  loss_rpn_loc: 0.06556    time: 1.0234  last_time: 1.0768  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:27:30 d2.utils.events]: \u001b[0m eta: 0:35:42  iter: 2939  total_loss: 0.416  loss_cls: 0.05966  loss_box_reg: 0.1699  loss_mask: 0.1222  loss_rpn_cls: 0.005431  loss_rpn_loc: 0.07135    time: 1.0235  last_time: 0.8210  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:27:50 d2.utils.events]: \u001b[0m eta: 0:35:27  iter: 2959  total_loss: 0.4801  loss_cls: 0.0652  loss_box_reg: 0.1658  loss_mask: 0.1249  loss_rpn_cls: 0.009196  loss_rpn_loc: 0.09601    time: 1.0234  last_time: 0.8352  data_time: 0.0061  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:28:10 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 2979  total_loss: 0.4894  loss_cls: 0.05856  loss_box_reg: 0.1715  loss_mask: 0.1198  loss_rpn_cls: 0.005362  loss_rpn_loc: 0.08092    time: 1.0233  last_time: 1.0066  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:28:31 d2.utils.events]: \u001b[0m eta: 0:34:40  iter: 2999  total_loss: 0.4087  loss_cls: 0.05748  loss_box_reg: 0.1622  loss_mask: 0.1109  loss_rpn_cls: 0.007766  loss_rpn_loc: 0.06015    time: 1.0233  last_time: 0.8996  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:28:51 d2.utils.events]: \u001b[0m eta: 0:34:24  iter: 3019  total_loss: 0.4026  loss_cls: 0.05914  loss_box_reg: 0.1785  loss_mask: 0.1136  loss_rpn_cls: 0.01047  loss_rpn_loc: 0.08631    time: 1.0233  last_time: 0.9387  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:29:11 d2.utils.events]: \u001b[0m eta: 0:34:02  iter: 3039  total_loss: 0.3767  loss_cls: 0.05111  loss_box_reg: 0.1512  loss_mask: 0.1081  loss_rpn_cls: 0.006004  loss_rpn_loc: 0.06601    time: 1.0232  last_time: 0.8237  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:29:33 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 3059  total_loss: 0.4308  loss_cls: 0.06048  loss_box_reg: 0.1728  loss_mask: 0.1253  loss_rpn_cls: 0.004559  loss_rpn_loc: 0.07017    time: 1.0235  last_time: 1.0075  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:29:55 d2.utils.events]: \u001b[0m eta: 0:33:37  iter: 3079  total_loss: 0.4671  loss_cls: 0.06185  loss_box_reg: 0.1823  loss_mask: 0.1173  loss_rpn_cls: 0.006372  loss_rpn_loc: 0.082    time: 1.0240  last_time: 1.1690  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:30:16 d2.utils.events]: \u001b[0m eta: 0:33:16  iter: 3099  total_loss: 0.5082  loss_cls: 0.07696  loss_box_reg: 0.171  loss_mask: 0.1374  loss_rpn_cls: 0.005156  loss_rpn_loc: 0.09636    time: 1.0242  last_time: 1.0670  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:30:35 d2.utils.events]: \u001b[0m eta: 0:32:55  iter: 3119  total_loss: 0.4247  loss_cls: 0.06285  loss_box_reg: 0.1694  loss_mask: 0.1236  loss_rpn_cls: 0.004653  loss_rpn_loc: 0.07499    time: 1.0239  last_time: 0.9956  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:30:57 d2.utils.events]: \u001b[0m eta: 0:32:35  iter: 3139  total_loss: 0.449  loss_cls: 0.05535  loss_box_reg: 0.1717  loss_mask: 0.1104  loss_rpn_cls: 0.002818  loss_rpn_loc: 0.06463    time: 1.0242  last_time: 1.0776  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:31:17 d2.utils.events]: \u001b[0m eta: 0:32:14  iter: 3159  total_loss: 0.471  loss_cls: 0.0551  loss_box_reg: 0.1709  loss_mask: 0.1096  loss_rpn_cls: 0.007764  loss_rpn_loc: 0.09107    time: 1.0241  last_time: 0.9271  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:31:38 d2.utils.events]: \u001b[0m eta: 0:31:53  iter: 3179  total_loss: 0.4327  loss_cls: 0.05908  loss_box_reg: 0.1652  loss_mask: 0.1207  loss_rpn_cls: 0.003896  loss_rpn_loc: 0.07543    time: 1.0242  last_time: 1.0680  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:31:59 d2.utils.events]: \u001b[0m eta: 0:31:35  iter: 3199  total_loss: 0.4734  loss_cls: 0.06823  loss_box_reg: 0.1862  loss_mask: 0.1192  loss_rpn_cls: 0.005554  loss_rpn_loc: 0.07829    time: 1.0243  last_time: 1.1535  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:32:19 d2.utils.events]: \u001b[0m eta: 0:31:14  iter: 3219  total_loss: 0.5337  loss_cls: 0.05582  loss_box_reg: 0.2086  loss_mask: 0.1356  loss_rpn_cls: 0.005088  loss_rpn_loc: 0.08937    time: 1.0244  last_time: 1.0514  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:32:41 d2.utils.events]: \u001b[0m eta: 0:30:55  iter: 3239  total_loss: 0.4517  loss_cls: 0.05746  loss_box_reg: 0.1776  loss_mask: 0.1348  loss_rpn_cls: 0.003554  loss_rpn_loc: 0.06774    time: 1.0247  last_time: 0.9409  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:33:01 d2.utils.events]: \u001b[0m eta: 0:30:34  iter: 3259  total_loss: 0.4714  loss_cls: 0.06409  loss_box_reg: 0.1895  loss_mask: 0.122  loss_rpn_cls: 0.004751  loss_rpn_loc: 0.0743    time: 1.0247  last_time: 1.1758  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:33:21 d2.utils.events]: \u001b[0m eta: 0:30:13  iter: 3279  total_loss: 0.4538  loss_cls: 0.05458  loss_box_reg: 0.1852  loss_mask: 0.1131  loss_rpn_cls: 0.003988  loss_rpn_loc: 0.08633    time: 1.0245  last_time: 0.8231  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:33:42 d2.utils.events]: \u001b[0m eta: 0:29:52  iter: 3299  total_loss: 0.4623  loss_cls: 0.06582  loss_box_reg: 0.1999  loss_mask: 0.1209  loss_rpn_cls: 0.005428  loss_rpn_loc: 0.0638    time: 1.0246  last_time: 0.9269  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:34:03 d2.utils.events]: \u001b[0m eta: 0:29:31  iter: 3319  total_loss: 0.4524  loss_cls: 0.05396  loss_box_reg: 0.153  loss_mask: 0.1242  loss_rpn_cls: 0.004534  loss_rpn_loc: 0.06108    time: 1.0246  last_time: 1.0537  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:34:23 d2.utils.events]: \u001b[0m eta: 0:29:10  iter: 3339  total_loss: 0.4248  loss_cls: 0.05281  loss_box_reg: 0.1749  loss_mask: 0.122  loss_rpn_cls: 0.005033  loss_rpn_loc: 0.07291    time: 1.0244  last_time: 0.9163  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:34:43 d2.utils.events]: \u001b[0m eta: 0:28:49  iter: 3359  total_loss: 0.4536  loss_cls: 0.06308  loss_box_reg: 0.1834  loss_mask: 0.1106  loss_rpn_cls: 0.005351  loss_rpn_loc: 0.06562    time: 1.0244  last_time: 0.8813  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 09:35:03 d2.utils.events]: \u001b[0m eta: 0:28:28  iter: 3379  total_loss: 0.4904  loss_cls: 0.05862  loss_box_reg: 0.1973  loss_mask: 0.1214  loss_rpn_cls: 0.009245  loss_rpn_loc: 0.08389    time: 1.0244  last_time: 1.0760  data_time: 0.0014  last_data_time: 0.0010   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:35:23 d2.utils.events]: \u001b[0m eta: 0:28:06  iter: 3399  total_loss: 0.4052  loss_cls: 0.04848  loss_box_reg: 0.1546  loss_mask: 0.1278  loss_rpn_cls: 0.005024  loss_rpn_loc: 0.08823    time: 1.0243  last_time: 1.0672  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:35:44 d2.utils.events]: \u001b[0m eta: 0:27:44  iter: 3419  total_loss: 0.3604  loss_cls: 0.04163  loss_box_reg: 0.1318  loss_mask: 0.1177  loss_rpn_cls: 0.003892  loss_rpn_loc: 0.05425    time: 1.0242  last_time: 1.0643  data_time: 0.0013  last_data_time: 0.0020   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:36:04 d2.utils.events]: \u001b[0m eta: 0:27:24  iter: 3439  total_loss: 0.3991  loss_cls: 0.04857  loss_box_reg: 0.1302  loss_mask: 0.1071  loss_rpn_cls: 0.00538  loss_rpn_loc: 0.06202    time: 1.0242  last_time: 1.0124  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:36:25 d2.utils.events]: \u001b[0m eta: 0:27:04  iter: 3459  total_loss: 0.3772  loss_cls: 0.04856  loss_box_reg: 0.1695  loss_mask: 0.1114  loss_rpn_cls: 0.003624  loss_rpn_loc: 0.07516    time: 1.0243  last_time: 1.1606  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:36:46 d2.utils.events]: \u001b[0m eta: 0:26:42  iter: 3479  total_loss: 0.4367  loss_cls: 0.06056  loss_box_reg: 0.17  loss_mask: 0.1225  loss_rpn_cls: 0.006957  loss_rpn_loc: 0.08235    time: 1.0243  last_time: 0.9937  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:37:06 d2.utils.events]: \u001b[0m eta: 0:26:21  iter: 3499  total_loss: 0.427  loss_cls: 0.0635  loss_box_reg: 0.1725  loss_mask: 0.117  loss_rpn_cls: 0.005504  loss_rpn_loc: 0.07138    time: 1.0243  last_time: 0.9365  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:37:28 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 3519  total_loss: 0.479  loss_cls: 0.0563  loss_box_reg: 0.1859  loss_mask: 0.1252  loss_rpn_cls: 0.006787  loss_rpn_loc: 0.06669    time: 1.0246  last_time: 1.2694  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:37:48 d2.utils.events]: \u001b[0m eta: 0:25:37  iter: 3539  total_loss: 0.4016  loss_cls: 0.04175  loss_box_reg: 0.1539  loss_mask: 0.1103  loss_rpn_cls: 0.007257  loss_rpn_loc: 0.07309    time: 1.0245  last_time: 0.9276  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:38:08 d2.utils.events]: \u001b[0m eta: 0:25:15  iter: 3559  total_loss: 0.5102  loss_cls: 0.07242  loss_box_reg: 0.2091  loss_mask: 0.1164  loss_rpn_cls: 0.00817  loss_rpn_loc: 0.1009    time: 1.0244  last_time: 1.0791  data_time: 0.0013  last_data_time: 0.0010   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:38:29 d2.utils.events]: \u001b[0m eta: 0:24:54  iter: 3579  total_loss: 0.4716  loss_cls: 0.06489  loss_box_reg: 0.1722  loss_mask: 0.1404  loss_rpn_cls: 0.01136  loss_rpn_loc: 0.1032    time: 1.0247  last_time: 1.0682  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:38:51 d2.utils.events]: \u001b[0m eta: 0:24:34  iter: 3599  total_loss: 0.5072  loss_cls: 0.05795  loss_box_reg: 0.2066  loss_mask: 0.1176  loss_rpn_cls: 0.007763  loss_rpn_loc: 0.1009    time: 1.0250  last_time: 1.1663  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:39:11 d2.utils.events]: \u001b[0m eta: 0:24:13  iter: 3619  total_loss: 0.4189  loss_cls: 0.05436  loss_box_reg: 0.1838  loss_mask: 0.1092  loss_rpn_cls: 0.003418  loss_rpn_loc: 0.05928    time: 1.0250  last_time: 0.9871  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:39:31 d2.utils.events]: \u001b[0m eta: 0:23:49  iter: 3639  total_loss: 0.4379  loss_cls: 0.04544  loss_box_reg: 0.1822  loss_mask: 0.1058  loss_rpn_cls: 0.004568  loss_rpn_loc: 0.07241    time: 1.0248  last_time: 0.7880  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:39:53 d2.utils.events]: \u001b[0m eta: 0:23:29  iter: 3659  total_loss: 0.4492  loss_cls: 0.05601  loss_box_reg: 0.1503  loss_mask: 0.1174  loss_rpn_cls: 0.004391  loss_rpn_loc: 0.07227    time: 1.0250  last_time: 0.8928  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:40:13 d2.utils.events]: \u001b[0m eta: 0:23:09  iter: 3679  total_loss: 0.4799  loss_cls: 0.06327  loss_box_reg: 0.1839  loss_mask: 0.138  loss_rpn_cls: 0.006364  loss_rpn_loc: 0.0809    time: 1.0251  last_time: 1.0093  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:40:34 d2.utils.events]: \u001b[0m eta: 0:22:48  iter: 3699  total_loss: 0.4682  loss_cls: 0.06133  loss_box_reg: 0.1823  loss_mask: 0.106  loss_rpn_cls: 0.003822  loss_rpn_loc: 0.08437    time: 1.0251  last_time: 1.0032  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:40:54 d2.utils.events]: \u001b[0m eta: 0:22:28  iter: 3719  total_loss: 0.4143  loss_cls: 0.0473  loss_box_reg: 0.1698  loss_mask: 0.1205  loss_rpn_cls: 0.007377  loss_rpn_loc: 0.07457    time: 1.0251  last_time: 1.1540  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:41:16 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 3739  total_loss: 0.3766  loss_cls: 0.05468  loss_box_reg: 0.1486  loss_mask: 0.102  loss_rpn_cls: 0.004346  loss_rpn_loc: 0.05668    time: 1.0253  last_time: 1.1503  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:41:36 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 3759  total_loss: 0.371  loss_cls: 0.0521  loss_box_reg: 0.1598  loss_mask: 0.1115  loss_rpn_cls: 0.002233  loss_rpn_loc: 0.05644    time: 1.0253  last_time: 0.9808  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:41:57 d2.utils.events]: \u001b[0m eta: 0:21:23  iter: 3779  total_loss: 0.5061  loss_cls: 0.06113  loss_box_reg: 0.209  loss_mask: 0.1279  loss_rpn_cls: 0.002156  loss_rpn_loc: 0.07978    time: 1.0253  last_time: 1.0465  data_time: 0.0013  last_data_time: 0.0018   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:42:17 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 3799  total_loss: 0.3749  loss_cls: 0.04356  loss_box_reg: 0.1491  loss_mask: 0.1109  loss_rpn_cls: 0.00422  loss_rpn_loc: 0.05887    time: 1.0252  last_time: 0.9651  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:42:37 d2.utils.events]: \u001b[0m eta: 0:20:36  iter: 3819  total_loss: 0.4233  loss_cls: 0.05114  loss_box_reg: 0.1778  loss_mask: 0.1361  loss_rpn_cls: 0.003474  loss_rpn_loc: 0.07229    time: 1.0252  last_time: 1.1560  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:42:58 d2.utils.events]: \u001b[0m eta: 0:20:13  iter: 3839  total_loss: 0.4653  loss_cls: 0.05942  loss_box_reg: 0.1866  loss_mask: 0.1176  loss_rpn_cls: 0.003852  loss_rpn_loc: 0.08081    time: 1.0251  last_time: 1.1324  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:43:17 d2.utils.events]: \u001b[0m eta: 0:19:52  iter: 3859  total_loss: 0.518  loss_cls: 0.06776  loss_box_reg: 0.2003  loss_mask: 0.1378  loss_rpn_cls: 0.005195  loss_rpn_loc: 0.08355    time: 1.0248  last_time: 1.0564  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:43:37 d2.utils.events]: \u001b[0m eta: 0:19:32  iter: 3879  total_loss: 0.479  loss_cls: 0.06214  loss_box_reg: 0.1922  loss_mask: 0.1125  loss_rpn_cls: 0.004081  loss_rpn_loc: 0.0896    time: 1.0248  last_time: 0.9825  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:43:59 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 3899  total_loss: 0.4523  loss_cls: 0.04463  loss_box_reg: 0.1936  loss_mask: 0.1227  loss_rpn_cls: 0.004614  loss_rpn_loc: 0.07555    time: 1.0250  last_time: 0.9785  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:44:19 d2.utils.events]: \u001b[0m eta: 0:18:52  iter: 3919  total_loss: 0.4161  loss_cls: 0.0447  loss_box_reg: 0.1683  loss_mask: 0.1044  loss_rpn_cls: 0.004684  loss_rpn_loc: 0.08545    time: 1.0250  last_time: 1.1435  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 09:44:39 d2.utils.events]: \u001b[0m eta: 0:18:30  iter: 3939  total_loss: 0.4286  loss_cls: 0.05536  loss_box_reg: 0.1777  loss_mask: 0.1104  loss_rpn_cls: 0.005602  loss_rpn_loc: 0.06712    time: 1.0249  last_time: 1.0390  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:44:59 d2.utils.events]: \u001b[0m eta: 0:18:09  iter: 3959  total_loss: 0.4676  loss_cls: 0.06006  loss_box_reg: 0.2047  loss_mask: 0.1161  loss_rpn_cls: 0.004457  loss_rpn_loc: 0.08473    time: 1.0247  last_time: 1.0433  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:45:19 d2.utils.events]: \u001b[0m eta: 0:17:48  iter: 3979  total_loss: 0.3458  loss_cls: 0.043  loss_box_reg: 0.158  loss_mask: 0.09556  loss_rpn_cls: 0.003496  loss_rpn_loc: 0.03558    time: 1.0246  last_time: 1.0480  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:45:39 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 3999  total_loss: 0.3849  loss_cls: 0.05455  loss_box_reg: 0.1649  loss_mask: 0.1021  loss_rpn_cls: 0.002715  loss_rpn_loc: 0.06882    time: 1.0245  last_time: 0.9812  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:46:00 d2.utils.events]: \u001b[0m eta: 0:17:05  iter: 4019  total_loss: 0.4629  loss_cls: 0.05754  loss_box_reg: 0.1693  loss_mask: 0.1227  loss_rpn_cls: 0.005479  loss_rpn_loc: 0.07296    time: 1.0245  last_time: 1.1587  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:46:20 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 4039  total_loss: 0.4355  loss_cls: 0.05981  loss_box_reg: 0.1834  loss_mask: 0.1171  loss_rpn_cls: 0.003733  loss_rpn_loc: 0.06172    time: 1.0246  last_time: 0.8280  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:46:40 d2.utils.events]: \u001b[0m eta: 0:16:23  iter: 4059  total_loss: 0.4536  loss_cls: 0.06267  loss_box_reg: 0.1637  loss_mask: 0.1215  loss_rpn_cls: 0.005264  loss_rpn_loc: 0.08563    time: 1.0243  last_time: 0.8967  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:46:59 d2.utils.events]: \u001b[0m eta: 0:15:59  iter: 4079  total_loss: 0.3097  loss_cls: 0.03941  loss_box_reg: 0.1344  loss_mask: 0.09031  loss_rpn_cls: 0.001726  loss_rpn_loc: 0.05137    time: 1.0241  last_time: 0.9882  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:47:19 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 4099  total_loss: 0.4695  loss_cls: 0.05897  loss_box_reg: 0.1817  loss_mask: 0.1199  loss_rpn_cls: 0.00707  loss_rpn_loc: 0.07903    time: 1.0240  last_time: 1.0316  data_time: 0.0012  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:47:40 d2.utils.events]: \u001b[0m eta: 0:15:17  iter: 4119  total_loss: 0.4554  loss_cls: 0.06549  loss_box_reg: 0.1866  loss_mask: 0.1108  loss_rpn_cls: 0.004314  loss_rpn_loc: 0.07558    time: 1.0240  last_time: 0.9647  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:48:00 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 4139  total_loss: 0.4925  loss_cls: 0.06087  loss_box_reg: 0.1894  loss_mask: 0.1089  loss_rpn_cls: 0.007926  loss_rpn_loc: 0.09923    time: 1.0239  last_time: 1.1590  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:48:20 d2.utils.events]: \u001b[0m eta: 0:14:33  iter: 4159  total_loss: 0.3429  loss_cls: 0.03812  loss_box_reg: 0.1428  loss_mask: 0.1079  loss_rpn_cls: 0.003325  loss_rpn_loc: 0.06176    time: 1.0237  last_time: 0.9803  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:48:39 d2.utils.events]: \u001b[0m eta: 0:14:09  iter: 4179  total_loss: 0.526  loss_cls: 0.06994  loss_box_reg: 0.2053  loss_mask: 0.1381  loss_rpn_cls: 0.009771  loss_rpn_loc: 0.1034    time: 1.0235  last_time: 0.9850  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:49:01 d2.utils.events]: \u001b[0m eta: 0:13:49  iter: 4199  total_loss: 0.3898  loss_cls: 0.05647  loss_box_reg: 0.1633  loss_mask: 0.1025  loss_rpn_cls: 0.005519  loss_rpn_loc: 0.05919    time: 1.0237  last_time: 1.2733  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:49:20 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 4219  total_loss: 0.4282  loss_cls: 0.05108  loss_box_reg: 0.1478  loss_mask: 0.1228  loss_rpn_cls: 0.003784  loss_rpn_loc: 0.08329    time: 1.0234  last_time: 1.1347  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:49:40 d2.utils.events]: \u001b[0m eta: 0:13:03  iter: 4239  total_loss: 0.456  loss_cls: 0.05131  loss_box_reg: 0.1876  loss_mask: 0.1189  loss_rpn_cls: 0.006424  loss_rpn_loc: 0.07964    time: 1.0232  last_time: 0.9963  data_time: 0.0013  last_data_time: 0.0016   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:50:00 d2.utils.events]: \u001b[0m eta: 0:12:45  iter: 4259  total_loss: 0.5119  loss_cls: 0.05781  loss_box_reg: 0.1972  loss_mask: 0.1181  loss_rpn_cls: 0.008469  loss_rpn_loc: 0.09914    time: 1.0232  last_time: 0.9139  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:50:20 d2.utils.events]: \u001b[0m eta: 0:12:25  iter: 4279  total_loss: 0.51  loss_cls: 0.07406  loss_box_reg: 0.2005  loss_mask: 0.134  loss_rpn_cls: 0.004054  loss_rpn_loc: 0.06875    time: 1.0230  last_time: 1.0648  data_time: 0.0014  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:50:40 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 4299  total_loss: 0.4356  loss_cls: 0.0543  loss_box_reg: 0.1714  loss_mask: 0.117  loss_rpn_cls: 0.006799  loss_rpn_loc: 0.0803    time: 1.0229  last_time: 1.1457  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:51:00 d2.utils.events]: \u001b[0m eta: 0:11:43  iter: 4319  total_loss: 0.3919  loss_cls: 0.04609  loss_box_reg: 0.1613  loss_mask: 0.1247  loss_rpn_cls: 0.00277  loss_rpn_loc: 0.06587    time: 1.0228  last_time: 1.1537  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:51:20 d2.utils.events]: \u001b[0m eta: 0:11:23  iter: 4339  total_loss: 0.3692  loss_cls: 0.04981  loss_box_reg: 0.1503  loss_mask: 0.1154  loss_rpn_cls: 0.002828  loss_rpn_loc: 0.05369    time: 1.0228  last_time: 0.8894  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:51:41 d2.utils.events]: \u001b[0m eta: 0:11:02  iter: 4359  total_loss: 0.3631  loss_cls: 0.04504  loss_box_reg: 0.1533  loss_mask: 0.1111  loss_rpn_cls: 0.005469  loss_rpn_loc: 0.0517    time: 1.0228  last_time: 0.9809  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:52:00 d2.utils.events]: \u001b[0m eta: 0:10:41  iter: 4379  total_loss: 0.426  loss_cls: 0.06584  loss_box_reg: 0.1658  loss_mask: 0.1275  loss_rpn_cls: 0.005972  loss_rpn_loc: 0.0759    time: 1.0226  last_time: 1.0387  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:52:21 d2.utils.events]: \u001b[0m eta: 0:10:21  iter: 4399  total_loss: 0.4115  loss_cls: 0.05184  loss_box_reg: 0.185  loss_mask: 0.1141  loss_rpn_cls: 0.003271  loss_rpn_loc: 0.07328    time: 1.0226  last_time: 0.9870  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:52:41 d2.utils.events]: \u001b[0m eta: 0:10:00  iter: 4419  total_loss: 0.4605  loss_cls: 0.05194  loss_box_reg: 0.1784  loss_mask: 0.1054  loss_rpn_cls: 0.007537  loss_rpn_loc: 0.08247    time: 1.0226  last_time: 0.9200  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:53:02 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 4439  total_loss: 0.4948  loss_cls: 0.06689  loss_box_reg: 0.179  loss_mask: 0.1203  loss_rpn_cls: 0.004216  loss_rpn_loc: 0.09672    time: 1.0227  last_time: 1.0590  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:53:21 d2.utils.events]: \u001b[0m eta: 0:09:19  iter: 4459  total_loss: 0.3816  loss_cls: 0.0554  loss_box_reg: 0.1441  loss_mask: 0.107  loss_rpn_cls: 0.005199  loss_rpn_loc: 0.06035    time: 1.0224  last_time: 0.9801  data_time: 0.0012  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:53:41 d2.utils.events]: \u001b[0m eta: 0:08:58  iter: 4479  total_loss: 0.4098  loss_cls: 0.06308  loss_box_reg: 0.1643  loss_mask: 0.1132  loss_rpn_cls: 0.002895  loss_rpn_loc: 0.08065    time: 1.0223  last_time: 1.1582  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 09:54:02 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 4499  total_loss: 0.3924  loss_cls: 0.04337  loss_box_reg: 0.1719  loss_mask: 0.1089  loss_rpn_cls: 0.004182  loss_rpn_loc: 0.06705    time: 1.0223  last_time: 0.9983  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:54:21 d2.utils.events]: \u001b[0m eta: 0:08:16  iter: 4519  total_loss: 0.4597  loss_cls: 0.05299  loss_box_reg: 0.1891  loss_mask: 0.1245  loss_rpn_cls: 0.004594  loss_rpn_loc: 0.0963    time: 1.0222  last_time: 0.9320  data_time: 0.0013  last_data_time: 0.0010   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:54:41 d2.utils.events]: \u001b[0m eta: 0:07:56  iter: 4539  total_loss: 0.4192  loss_cls: 0.04896  loss_box_reg: 0.1587  loss_mask: 0.1123  loss_rpn_cls: 0.004075  loss_rpn_loc: 0.05351    time: 1.0221  last_time: 1.1362  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:55:02 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 4559  total_loss: 0.4652  loss_cls: 0.0702  loss_box_reg: 0.1974  loss_mask: 0.1114  loss_rpn_cls: 0.005218  loss_rpn_loc: 0.07477    time: 1.0221  last_time: 1.0649  data_time: 0.0014  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:55:22 d2.utils.events]: \u001b[0m eta: 0:07:13  iter: 4579  total_loss: 0.4649  loss_cls: 0.05826  loss_box_reg: 0.1911  loss_mask: 0.1294  loss_rpn_cls: 0.005916  loss_rpn_loc: 0.0733    time: 1.0220  last_time: 0.9469  data_time: 0.0014  last_data_time: 0.0017   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:55:44 d2.utils.events]: \u001b[0m eta: 0:06:52  iter: 4599  total_loss: 0.388  loss_cls: 0.04839  loss_box_reg: 0.1513  loss_mask: 0.0944  loss_rpn_cls: 0.00316  loss_rpn_loc: 0.07998    time: 1.0222  last_time: 1.1239  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:56:04 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 4619  total_loss: 0.372  loss_cls: 0.04568  loss_box_reg: 0.1561  loss_mask: 0.1063  loss_rpn_cls: 0.00297  loss_rpn_loc: 0.0623    time: 1.0222  last_time: 0.9248  data_time: 0.0013  last_data_time: 0.0018   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:56:24 d2.utils.events]: \u001b[0m eta: 0:06:12  iter: 4639  total_loss: 0.4296  loss_cls: 0.05947  loss_box_reg: 0.1903  loss_mask: 0.1146  loss_rpn_cls: 0.002878  loss_rpn_loc: 0.07802    time: 1.0221  last_time: 0.8877  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:56:45 d2.utils.events]: \u001b[0m eta: 0:05:51  iter: 4659  total_loss: 0.3243  loss_cls: 0.03986  loss_box_reg: 0.1274  loss_mask: 0.09491  loss_rpn_cls: 0.006694  loss_rpn_loc: 0.0353    time: 1.0223  last_time: 0.9064  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:57:06 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 4679  total_loss: 0.4569  loss_cls: 0.05811  loss_box_reg: 0.1936  loss_mask: 0.1215  loss_rpn_cls: 0.005833  loss_rpn_loc: 0.07052    time: 1.0223  last_time: 1.0497  data_time: 0.0013  last_data_time: 0.0018   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:57:27 d2.utils.events]: \u001b[0m eta: 0:05:10  iter: 4699  total_loss: 0.4526  loss_cls: 0.0634  loss_box_reg: 0.1882  loss_mask: 0.112  loss_rpn_cls: 0.003405  loss_rpn_loc: 0.06937    time: 1.0224  last_time: 0.9091  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:57:47 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 4719  total_loss: 0.4001  loss_cls: 0.04987  loss_box_reg: 0.1695  loss_mask: 0.1066  loss_rpn_cls: 0.006159  loss_rpn_loc: 0.0692    time: 1.0223  last_time: 0.9930  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:58:07 d2.utils.events]: \u001b[0m eta: 0:04:28  iter: 4739  total_loss: 0.3903  loss_cls: 0.04986  loss_box_reg: 0.1632  loss_mask: 0.1022  loss_rpn_cls: 0.004107  loss_rpn_loc: 0.05222    time: 1.0223  last_time: 0.8950  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:58:28 d2.utils.events]: \u001b[0m eta: 0:04:08  iter: 4759  total_loss: 0.4305  loss_cls: 0.05163  loss_box_reg: 0.1807  loss_mask: 0.1221  loss_rpn_cls: 0.003744  loss_rpn_loc: 0.06383    time: 1.0225  last_time: 1.0464  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:58:48 d2.utils.events]: \u001b[0m eta: 0:03:47  iter: 4779  total_loss: 0.3989  loss_cls: 0.05334  loss_box_reg: 0.1548  loss_mask: 0.09309  loss_rpn_cls: 0.002149  loss_rpn_loc: 0.06981    time: 1.0223  last_time: 0.9878  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:59:08 d2.utils.events]: \u001b[0m eta: 0:03:26  iter: 4799  total_loss: 0.4199  loss_cls: 0.06043  loss_box_reg: 0.1604  loss_mask: 0.1187  loss_rpn_cls: 0.002594  loss_rpn_loc: 0.08751    time: 1.0222  last_time: 0.9760  data_time: 0.0014  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:59:28 d2.utils.events]: \u001b[0m eta: 0:03:05  iter: 4819  total_loss: 0.4253  loss_cls: 0.05064  loss_box_reg: 0.1718  loss_mask: 0.1158  loss_rpn_cls: 0.003238  loss_rpn_loc: 0.07205    time: 1.0222  last_time: 0.9835  data_time: 0.0013  last_data_time: 0.0011   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 09:59:49 d2.utils.events]: \u001b[0m eta: 0:02:45  iter: 4839  total_loss: 0.4194  loss_cls: 0.05902  loss_box_reg: 0.1637  loss_mask: 0.1159  loss_rpn_cls: 0.002436  loss_rpn_loc: 0.06148    time: 1.0222  last_time: 1.1202  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:00:10 d2.utils.events]: \u001b[0m eta: 0:02:24  iter: 4859  total_loss: 0.4474  loss_cls: 0.0582  loss_box_reg: 0.1865  loss_mask: 0.1308  loss_rpn_cls: 0.002872  loss_rpn_loc: 0.08827    time: 1.0224  last_time: 1.1500  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:00:31 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 4879  total_loss: 0.4461  loss_cls: 0.05608  loss_box_reg: 0.1842  loss_mask: 0.1138  loss_rpn_cls: 0.005064  loss_rpn_loc: 0.06934    time: 1.0224  last_time: 1.1630  data_time: 0.0013  last_data_time: 0.0015   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:00:51 d2.utils.events]: \u001b[0m eta: 0:01:43  iter: 4899  total_loss: 0.439  loss_cls: 0.05402  loss_box_reg: 0.158  loss_mask: 0.1096  loss_rpn_cls: 0.002695  loss_rpn_loc: 0.07192    time: 1.0223  last_time: 0.8968  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:01:11 d2.utils.events]: \u001b[0m eta: 0:01:22  iter: 4919  total_loss: 0.3857  loss_cls: 0.04781  loss_box_reg: 0.1326  loss_mask: 0.1179  loss_rpn_cls: 0.003704  loss_rpn_loc: 0.07205    time: 1.0223  last_time: 0.9943  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:01:31 d2.utils.events]: \u001b[0m eta: 0:01:02  iter: 4939  total_loss: 0.5068  loss_cls: 0.06846  loss_box_reg: 0.2105  loss_mask: 0.136  loss_rpn_cls: 0.006027  loss_rpn_loc: 0.08808    time: 1.0222  last_time: 1.1527  data_time: 0.0014  last_data_time: 0.0017   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:01:52 d2.utils.events]: \u001b[0m eta: 0:00:41  iter: 4959  total_loss: 0.3586  loss_cls: 0.04346  loss_box_reg: 0.1451  loss_mask: 0.102  loss_rpn_cls: 0.006677  loss_rpn_loc: 0.06937    time: 1.0223  last_time: 0.7686  data_time: 0.0013  last_data_time: 0.0013   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:02:13 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 4979  total_loss: 0.4436  loss_cls: 0.05799  loss_box_reg: 0.184  loss_mask: 0.127  loss_rpn_cls: 0.006844  loss_rpn_loc: 0.08502    time: 1.0223  last_time: 1.1409  data_time: 0.0013  last_data_time: 0.0014   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:02:36 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4999  total_loss: 0.4119  loss_cls: 0.04809  loss_box_reg: 0.1669  loss_mask: 0.1148  loss_rpn_cls: 0.003995  loss_rpn_loc: 0.07083    time: 1.0224  last_time: 1.0702  data_time: 0.0013  last_data_time: 0.0012   lr: 0.001  max_mem: 5940M\n",
      "\u001b[32m[01/23 10:02:36 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 1:25:09 (1.0224 s / it)\n",
      "\u001b[32m[01/23 10:02:36 d2.engine.hooks]: \u001b[0mTotal training time: 1:25:19 (0:00:09 on hooks)\n"
     ]
    }
   ],
   "source": [
    "# train the model \n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07780b4f",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "I personally restart the kernel here to empty the memory and rerun everything except the trainer cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "481834eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables and constants for the evaluation\n",
    "IOU_THRESHOLD = 0.5\n",
    "data_csv = pd.read_csv(os.path.join(datasets_dir, 'data_complete.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78edc2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/25 13:24:22 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "# Inference should use the config with parameters that are used in training\n",
    "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold (in this case the same as the training threshold)\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d647ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gold_standard_masks(input_image_path):\n",
    "    '''\n",
    "    Create a separate mask for every annotated region of an image\n",
    "    @param  string      The path to the image\n",
    "    @return np.array    The numpy array representation of the masks with the \n",
    "                        dimensions of the image and the golden \n",
    "                        standard region drawn on it. Only the golden standard\n",
    "                        region coordinates have the value True, the rest \n",
    "                        is False.\n",
    "    '''\n",
    "    \n",
    "    # load the image\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    \n",
    "    # get the golden standard for the image\n",
    "    gold_standard_image = data_json[os.path.split(input_image_path)[-1]]\n",
    "    \n",
    "    # make sure that we have the golden standard for the image\n",
    "    if not gold_standard_image: return None\n",
    "    \n",
    "    # get the golden standard regions for the image\n",
    "    gold_standard_regions = gold_standard_image['regions']\n",
    "    \n",
    "    # extract the polygons from the regions\n",
    "    polygons = [r['shape_attributes'] for r in gold_standard_regions]\n",
    "    \n",
    "    # array holding all masks\n",
    "    masks = []\n",
    "    \n",
    "    # construct the polygon arrays and add them to the mask\n",
    "    for polygon in polygons:\n",
    "        \n",
    "        # create the initial mask (black) with the dimensions of the original image\n",
    "        mask = np.zeros(np.array(input_image).shape, dtype = \"uint8\")\n",
    "        \n",
    "        if polygon['name'] == 'rect':\n",
    "            bottom_left = [polygon['x'], polygon['y']]\n",
    "            bottom_right = [polygon['x']+polygon['width'], polygon['y']]\n",
    "            top_right = [polygon['x']+polygon['width'], polygon['y']+polygon['height']]\n",
    "            top_left = [polygon['x'], polygon['y']+polygon['height']]\n",
    "            \n",
    "            gold_standard_polygon_xy = [bottom_left, bottom_right, top_right, top_left]\n",
    "        else:\n",
    "            # If not a rectangle we have a more complex shape and we just add all points to it\n",
    "            gold_standard_polygon_xy  = [[polygon['all_points_x'][i], polygon['all_points_y'][i]] for i in range(0, len(polygon['all_points_x']))]\n",
    "\n",
    "        # add the polygon (white) to the mask\n",
    "        mask = cv2.fillPoly(mask, [np.array(gold_standard_polygon_xy, np.int32)], (255,255,255))   \n",
    "        \n",
    "        # save the mask with a single channel with boolean values\n",
    "        masks.append(np.array(mask).astype(bool)[:, :, 0])\n",
    "\n",
    "    # return the masks\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c267170b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_calculation(dataframe):\n",
    "    '''\n",
    "    The metric calculations as done in https://github.com/irlabamsterdam/TPDLTextRedaction/blob/main/notebooks/Experiments.ipynb\n",
    "    @param  pd.DataFrame    The dataframe for one class with the following columns { IOU, TP, FN, FP }\n",
    "                            where the IOU is the sum of IOU scores and the others a total count.\n",
    "    @return dict            The metric scores for this class\n",
    "    '''\n",
    "    \n",
    "    SQ = dataframe['IOU'].sum() / dataframe['TP'].sum() if dataframe['TP'].sum() > 0 else 0\n",
    "    RQ = dataframe['TP'].sum() / (dataframe['TP'].sum() + 0.5*dataframe['FN'].sum() + 0.5*dataframe['FP'].sum())\n",
    "    PQ = SQ*RQ\n",
    "    P = dataframe['TP'].sum() / (dataframe['TP'].sum() + dataframe['FP'].sum())\n",
    "    R = dataframe['TP'].sum() / (dataframe['TP'].sum() + dataframe['FN'].sum())\n",
    "    \n",
    "    return { 'PQ': round(PQ, 2), 'SQ': round(SQ, 2), 'RQ': round(RQ, 2), 'P': round(P, 2), 'R': round(R, 2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3132f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the overlap between predicted masks\n",
    "# this should also speed up the calculation of the overall PQ score\n",
    "def remove_box_overlap(predicted_masks, scores, score_t: float=0.5, iou_t: float= 0.5):\n",
    "    '''\n",
    "    Remove the overlap between predicted masks\n",
    "    @param  list    The predicted masks\n",
    "    @param  list    The confidence scores of the predicted masks\n",
    "    @param  float   The prediction confidence score threshold\n",
    "    @param  float   The interval-over-intersection threshold to consider\n",
    "                    an annotated region and predicted region a true positive\n",
    "    @return\n",
    "    '''\n",
    "    \n",
    "    # Filter out boxes with a low confidence score\n",
    "    filtered_masks = [predicted_masks[i].numpy() for i in range(len(predicted_masks)) if scores[i] > score_t]\n",
    "    filtered_scores = [scores[i] for i in range(len(scores)) if scores[i] > score_t]\n",
    "    \n",
    "    # Sort boxes based on their confidence scores\n",
    "    sorted_masks = np.array(filtered_masks)[np.argsort(filtered_scores)]\n",
    "    \n",
    "    # The list was sorted from worst to best score so we have to reverse the list\n",
    "    sorted_masks = sorted_masks[::-1]\n",
    "    \n",
    "    # after the first step, we have to remove overlaps by looping through and calculating iou\n",
    "    if not len(sorted_masks):\n",
    "        return None\n",
    "    \n",
    "    # By definition we always include the first mask in the output\n",
    "    output_masks = [sorted_masks[0]]\n",
    "    mask_overlap = np.copy(sorted_masks[0])\n",
    "    \n",
    "    # evaluate all masks\n",
    "    for i in range(1, len(sorted_masks)):\n",
    "        \n",
    "        # get the mask and copy it to make sure we don't overwrite it\n",
    "        mask = np.copy(sorted_masks[i])\n",
    "        \n",
    "        # get the mask size\n",
    "        mask_size = (mask > 0).sum()\n",
    "        \n",
    "        # check if the current mask has any overlap with previously evaluated masks\n",
    "        only_mask = np.logical_and((mask == 1), (mask_overlap == 0))\n",
    "        \n",
    "        # only keep masks that do not overlap for more\n",
    "        # than the given IoU threshold with the previous masks\n",
    "        if (only_mask.sum() / mask_size) > iou_t:\n",
    "            output_masks.append(np.copy(only_mask))\n",
    "            mask_overlap += only_mask\n",
    "            mask_overlap = mask_overlap > 0\n",
    "            \n",
    "    # only return the masks if we have them\n",
    "    if len(output_masks): return np.stack(output_masks)\n",
    "    else: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb11c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_PQ_score(ground_truth, prediction):\n",
    "    '''\n",
    "    Get the values that are needed to calculate the PQ-score\n",
    "    @param  np.array    The ground truth masks\n",
    "    @param  np.array    The predicted masks\n",
    "    @return dict        The values needed for the PQ-score (TP, FP, FN, IOU)\n",
    "    '''\n",
    "    \n",
    "    # make sure that the prediction\n",
    "    # is always numpy array by default\n",
    "    if prediction is None: prediction = np.array([])\n",
    "        \n",
    "    # get the initial values\n",
    "    TP = []\n",
    "    IOU = []\n",
    "    \n",
    "    # get the indices of the ground truth and prediction masks\n",
    "    gt_indices = list(range(ground_truth.shape[0]))\n",
    "    pred_indices = list(range(prediction.shape[0]))\n",
    "\n",
    "    # iterate over the ground truth and prediction \n",
    "    # masks to calculate the iou between all combinations\n",
    "    for i in range(ground_truth.shape[0]):\n",
    "        for j in range(prediction.shape[0]):\n",
    "            \n",
    "            # calculate the iou between this ground truth\n",
    "            # and predicted mask\n",
    "            ground_truth_mask = ground_truth[i, :, :]\n",
    "            predicted_mask = prediction[j, :, :]\n",
    "            union = ((ground_truth_mask + predicted_mask) > 0).sum()\n",
    "            intersection = (predicted_mask * ground_truth_mask).sum()\n",
    "            iou = intersection / union\n",
    "            \n",
    "            # add this combination of masks as a true positive if\n",
    "            # the iou exceeds the threshold and keep track of the\n",
    "            # iou score for the segmentation quality metric\n",
    "            if iou > 0.5:\n",
    "                TP.append((i, j))\n",
    "                IOU.append(iou)\n",
    "                    \n",
    "    # every unused predicted mask is a false positive\n",
    "    FP = set(pred_indices)-set([item[1] for item in TP])\n",
    "    \n",
    "    # every unused ground truth maks is a false negative\n",
    "    FN = set(gt_indices)-set([item[0] for item in TP])\n",
    "    \n",
    "    # return the values needed for the panoptic quality metric\n",
    "    return {'TP': len(TP), 'FP': len(FP), 'FN': len(FN), 'IOU': sum(IOU)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6073ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_panoptic_evaluation_values(image_path, score_t: float=0.5, iou_t: float= 0.5):\n",
    "    '''\n",
    "    Function to evaluate how well the detection is for an image\n",
    "    @param  string  The path to the image\n",
    "    @param  float   The prediction confidence score threshold\n",
    "    @param  float   The interval-over-intersection threshold to consider\n",
    "                    an annotated region and predicted region a true positive\n",
    "    @return dict    The dict with the evaluation scores:\n",
    "                        - iou:float  The sum of the intersection over union values of all true positive regions\n",
    "                        - tp:int     The number of true positives\n",
    "                        - fp:int     The number of false positives\n",
    "                        - fn:int     The number of false negatives\n",
    "    '''\n",
    "    \n",
    "    # get the golden standard masks for the image\n",
    "    im = cv2.imread(image_path)\n",
    "    g_masks = create_gold_standard_masks(image_path)\n",
    "    \n",
    "    # get the filename from the path\n",
    "    filename = os.path.split(image_path)[-1]\n",
    "    \n",
    "    # get the label\n",
    "    label = data_csv[data_csv['File'] == filename].type.item()\n",
    "    \n",
    "    # get the prediction masks for the image\n",
    "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "    p_masks = outputs['instances'].pred_masks.cpu()\n",
    "    scores = outputs['instances'].scores.cpu()\n",
    "    \n",
    "    # filter the prediction masks by removing the overlap between them\n",
    "    filtered_p_masks = remove_box_overlap(p_masks, scores, score_t, iou_t)\n",
    "    \n",
    "    # get the PQ score\n",
    "    pq = get_PQ_score(np.array(g_masks), filtered_p_masks)\n",
    "    \n",
    "    # add the label to the score\n",
    "    pq['Label'] = label\n",
    "    \n",
    "    #return the pq score\n",
    "    return pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1a4862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataframe(dataset: list, score_t: float=0.5, iou_t: float= 0.5):\n",
    "    '''\n",
    "    Function to get the panoptic quality\n",
    "    @param  list    A dataset in the DatasetCatalog format \n",
    "    @param  float   The prediction confidence score threshold\n",
    "    @param  float   The interval-over-intersection threshold to consider\n",
    "                    an annotated region and predicted region a true positive\n",
    "    '''\n",
    "    \n",
    "    # create a dataframe to store the panoptic quality values in\n",
    "    values = {}\n",
    "    \n",
    "    # iterate over the samples\n",
    "    for sample in tqdm(dataset):\n",
    "        \n",
    "        # get the values for the panoptic quality evaluation for this sample\n",
    "        values[sample['file_name']] = extract_panoptic_evaluation_values(sample['file_name'], score_t, iou_t)\n",
    "\n",
    "    # return put all values in a dataframe \n",
    "    # with the file_name as the index\n",
    "    return pd.DataFrame(values).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ab002aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [00:19, 14.78it/s]\n"
     ]
    }
   ],
   "source": [
    "# get the validation dicts\n",
    "test_dir = os.path.join(datasets_dir, 'test')\n",
    "test_dicts = get_redacted_dicts(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228cb12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/284 [00:00<?, ?it/s]C:\\Users\\kdmei\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "  8%|         | 23/284 [04:46<58:25, 13.43s/it]  "
     ]
    }
   ],
   "source": [
    "# get the dataframe with the evaluation scores\n",
    "test_df = evaluate_dataframe(test_dicts, 0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "test_df.to_csv(os.path.join('results', 'maskrcnn_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083185e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculates the panoptic quality metrics\n",
    "results = {}\n",
    "for label, label_df in test_df.groupby('Label'): results[label] = metric_calculation(label_df)\n",
    "results['total'] = metric_calculation(test_df)\n",
    "\n",
    "# show the metrics in a pandas dataframe\n",
    "pd.DataFrame.from_dict(results).T[['PQ', 'SQ', 'RQ', 'P', 'R']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac7a69",
   "metadata": {},
   "source": [
    "# Time the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee17eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/23 11:36:41 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./output\\model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "# the test dir\n",
    "test_dir = os.path.join(datasets_dir, 'test')\n",
    "\n",
    "# load the trained model\n",
    "# !NOTE!: Make sure that the cfg is loaded in a previous cell\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold (in this case the same as the training threshold)\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "041fea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_algorithm(input_image_path):\n",
    "    '''\n",
    "    Time the image loading and model prediction\n",
    "    @param  string    The path to the image\n",
    "    @return dict      The times of the individual parts and total time\n",
    "    '''\n",
    "    \n",
    "    # time the image loading\n",
    "    load_start = time.time()\n",
    "    input_image = cv2.imread(input_image_path)\n",
    "    load_end = time.time()\n",
    "    \n",
    "    # time the prediction\n",
    "    predict_start = time.time()\n",
    "    outputs = predictor(input_image)\n",
    "    predict_end = time.time()\n",
    "    \n",
    "    # add the separate time differences\n",
    "    times = {\n",
    "        'loading': load_end-load_start,\n",
    "        'predicting': predict_end-predict_start\n",
    "    }\n",
    "    \n",
    "    # add the total time (sum of the individual parts)\n",
    "    times['total'] = sum(times.values())\n",
    "    \n",
    "    # return the times\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64a44d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/284 [00:00<?, ?it/s]C:\\Users\\kdmei\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3527.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|| 284/284 [01:21<00:00,  3.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# do this over all the images and average\n",
    "load_times = []\n",
    "predicting_times = []\n",
    "total_times = []\n",
    "\n",
    "# time the model for all test images\n",
    "for filename in tqdm(os.listdir(test_dir)):\n",
    "    image_path = os.path.join(test_dir, filename)\n",
    "    times = time_algorithm(image_path)\n",
    "    load_times.append(times['loading'])\n",
    "    predicting_times.append(times['predicting'])\n",
    "    total_times.append(times['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "290a64a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loading time is 0.064 seconds\n",
      "Average predicting time is 0.220 seconds\n",
      "Average total time is 0.284 seconds\n"
     ]
    }
   ],
   "source": [
    "# print the average times\n",
    "print(\"Average loading time is %.3f seconds\" % np.mean(load_times))\n",
    "print(\"Average predicting time is %.3f seconds\" % np.mean(predicting_times))\n",
    "print(\"Average total time is %.3f seconds\" % np.mean(total_times))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
